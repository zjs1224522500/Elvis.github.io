<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://blog.shunzi.tech</id>
    <title>Elvis Zhang</title>
    <updated>2021-01-16T15:04:09.024Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://blog.shunzi.tech"/>
    <link rel="self" href="https://blog.shunzi.tech/atom.xml"/>
    <subtitle>The easy way or the right way.</subtitle>
    <logo>https://blog.shunzi.tech/images/avatar.png</logo>
    <icon>https://blog.shunzi.tech/favicon.ico</icon>
    <rights>All rights reserved 2021, Elvis Zhang</rights>
    <entry>
        <title type="html"><![CDATA[Dostoevsky: Better Space-Time Trade-Offs for LSM-Tree Based Key-Value Stores via Adaptive Removal of Superfluous Merging]]></title>
        <id>https://blog.shunzi.tech/post/Dostoevsky/</id>
        <link href="https://blog.shunzi.tech/post/Dostoevsky/">
        </link>
        <updated>2021-01-12T14:50:15.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li></li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li></li>
</ul>
</blockquote>
<!-- more -->
<h2 id="abstract">Abstract</h2>
<ul>
<li>无论是学术界还是工业界，所有主流的基于 LSM 树的键值存储都在更新的 I/O 成本和查询和存储空间的 I/O 成本之间进行了权衡。因为在所有的 LSM Tree 的级别上都需要执行 Compaction 操作来限制查询遍历的 runs，并删除 obsolete 的数据项来腾出存储空间。即便是最先进的 LSM Tree 设计，来自 LSM Tree 所有层此的合并操作（除了最大的层此）减少的点查询成本、大范围查询成本和存储空间，减少的效果可以忽略不计；与此同时还增加了更新操作的平摊开销。</li>
<li>为了解决这个问题，我们提出了 Lazy Leveling，一种新的设计，从除开最大层以外的所有 level 中删除合并操作。同时提出了 Fluid LSM-tree，一种可以涵盖整个 LSM-tree 设计领域的通用设计，可以参数化以假设任何现有的设计。相对于 Lazy level, Fluid LSM-tree 可以通过在最大级别上合并更少的内容来优化更新，或者通过在所有其他级别上合并更多内容来优化小范围查询。</li>
<li>Dostoevsky，一种键值存储，通过基于应用程序工作负载和硬件来动态调整的弹性的 LSM-tree 设计，自适应地消除多余的合并。基于 RocksDB 实现，测试表明无论是性能还是存储空间方面都优于目前最先进的设计。</li>
</ul>
<h2 id="introduction">Introduction</h2>
<ul>
<li>LSM-tree 将要插入/更新的条目缓冲在内存中，并在缓冲区填满时将缓冲区作为 sorted run 刷新到次要存储。LSM-tree 稍后对这些 runs 进行排序合并，以限制查找必须扫描的run 数量，并删除过时的条目。LSM-tree 将运行组织成指数级增长的容量，更大的级别包含更老的运行。当条目被替换更新时，点查找通过从最小到最大的级别查找条目的最新版本，并在查找目标键时终止查找。另一方面，范围查找必须在所有级别的所有 run 中访问相关的键范围，并从结果集中删除过时的条目。为了提高单个 run 的查询速度，设计中常常包含了两个额外的内存中的数据结构。首先，对于每个 run，都有一组包含每个 run 块的第一个键的 fence 指针，这允许查找在一个 run 中只使用一个 I/O 就可以访问特定的键；第二，每个 run 会有一个 BoolmFilter，这允许点查询跳过不包含目标键的 runs。这个设计被应用到了大量的现代 KV 存储中，如 LevelDB、BigTable 等。</li>
<li><strong>问题</strong>：LSM-tree 中的合并操作的频率控制了在 更新的 I/O 成本 和 查询和存储空间放大的 I/O 成本之间的 trade-off，另外的问题就是现有的设计在这些指标之间的 trade-off 并不理想。下图表示了指标之间的权衡关系，虽然这些 y 轴指标具有不同的单位，但它们相对于 x 轴的权衡曲线具有相同的形状。两个极端分别是 log 和 sorted array。LSM-tree在完全不合并或尽可能多地合并时，分别退化为这些边缘点。我们将主流系统放置在这些边缘点之间的顶部曲线上，基于它们的默认合并频率，我们为 Monkey 绘制了一个优越的权衡曲线，我们证明了存在一个甚至比Monkey更好的权衡曲线。现有的设计放弃了大量的性能和/或存储空间，因为没有沿着这条底部曲线设计。</li>
<li><strong>问题来源</strong>：通过分析最先进的 LSM 树的设计空间，我们指出了问题的根源，即最坏情况下的更新代价、点查询代价、范围查询代价和空间放大在不同的层次上产生不同的结果。
<ul>
<li>Update: 更新的 I/O 成本稍后通过更新条目参与的合并操作来分担。虽然较大级别的合并操作需要成倍地增加工作，但它们发生的频率却成倍地减少。因此，更新从所有级别的合并操作中同等地获得它们的 I/O 成本。</li>
<li>Point lookups：虽然 图1 中沿顶部曲线的主流设计将跨 LSM-tree 所有级别的 Bloom flters 假阳性率设置为相同，但目前最先进的 Monkey 为更小的层此设置更低的假阳性率。他被证明可以最小化所有筛选器的误报率之和，从而最小化点查找的 I/O。与此同时，这意味着进入较小层此的可能性呈指数级下降，因此大多数点查询 I/O 将直接命中最大的层次。</li>
<li>Long range lookup：因为 LSM Tree 的容量呈指数级增长，最大曾通常包含绝大部分数据，所以该层更可能包含给定键范围内的数据，因此大多数由大范围查询引起的 I/O 都将对最大层进行操作。</li>
<li>Short range lookup： 使用极小键范围的范围查找在每次 run 中只能访问大约一个块，而不管 run 的大小，因为每一层 run 的最大个数是固定的，因此小范围查询在所有曾中是相当的。</li>
<li>Space-Amplifcation：空间放大最差的情况就是较低层次的数据被更新到最大层此，因此在最大层中老旧的数据项比例最大。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210112173749.png" alt="20210112173749" loading="lazy"></li>
</ul>
</li>
<li>因为最坏情况下的点查询开销、大范围查询开销、空间放大都主要来源于最大层，LSM-tree 中所有级别的合并操作，除开最大层(即大多数合并操作)在这些指标上几乎没有改进，同时显著增加了更新的平摊成本。这导致了次优的权衡。我们用三个步骤从头开始解决这个问题：
<ul>
<li><strong>Solution 1: Lazy Leveling to Remove Superﬂuous Merging</strong>：
<ul>
<li>我们使用 Lazy level 拓展了 LSM-tree 设计思路，这种新设计除去了 LSM-tree 最大级别之外的所有合并。Lazy Leveling 改进了最坏情况下更新的成本复杂性，同时在点查找成本、大范围查找成本和空间放大上保持相同的限制，同时在小范围查找成本上提供具有竞争力的限制。我们证明改进的更新开销可以用来降低点查找开销和空间放大。这生成了 图1 中的底部曲线，它提供了更丰富的时空权衡，这是迄今为止最先进的设计无法实现的。</li>
</ul>
</li>
<li><strong>Solution 2: Fluid LSM-Tree for Design Space Fluidity.</strong>
<ul>
<li>我们引入了 Fluid LSM-tree 作为新一代的 LSM Tree 支持在整个 LSM-tree 设计思路中流畅地切换。Fluid LSM-tree 通过分别控制最大级别和所有其他级别合并操作的频率，相对于 Lazy leveling, Fluid LSM-tree 可以通过在最大级别上合并更少的内容来优化更新，或者通过在所有其他级别上合并更多内容来优化小范围查询。</li>
</ul>
</li>
<li><strong>Solution 3: Dostoevsky to Navigate the Design Space</strong>
<ul>
<li>Dostoevsky: Space-Time Optimized Evolvable Scalable Key-Value Store。Dostoevsky 分析地找到了Fluid LSM-tree 的调优方法，以最大限度地提高特定应用程序工作负载和硬件在空间放大方面的用户约束，通过精简搜索空间来快速找到最佳调优，并在运行时对其进行物理调整。因为 Dostoevsky 跨越了所有现有的设计，并能够针对给定的应用程序 navigate 到最佳的设计，因此它在性能和空间放大方面严格控制了现有的键值存储。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="background">BACKGROUND</h2>
<ul>
<li>如下图所示，为了优化写操作，LSM-Tree 初始时缓冲了所有的更新、插入和删除操作到内存中，当 Buffer 满了之后，LSM Tree 将 Buffer 以 Sorted Run 刷回到了第二层存储，LSM Tree 归并排序 runs 是为了：限制查询操作必须访问的 runs 的数量，以及删除老旧的数据项以回收空间。runs 被组织成 L 个呈指数级增长的层此，Level 0 是主存中的 Buffer，其他层次都位于二级存储。</li>
<li>在合并的 I/O 开销和查询 I/O 开销以及空间放大之前的权衡可以由两个参数来控制，第一个是相邻两个层次之间的比例 T，T 控制了层级的个数因此决定了一个数据能够在层级之间合并多少次。第二个参数是合并策略，决定了数据项在一个 level 内的合并次数。所有的现有设计都使用了 tiering 或 leveling 两种策略。
<ul>
<li>tiering：当一个 level 到达容量时合并该 level 内的 runs</li>
<li>leveling: 当一个新的 run 出现，就会在 level 中执行合并</li>
</ul>
</li>
<li>如下图所示，size ratio 为 4，buffer 大小为一个 entry 的大小。在两种策略中，当 buffer flushing 造成 Level 1 到达容量时触发合并操作。对于 tiering，Level 1 的所有 runs 都被合并成同一个新的 run 放置在 Level 2。而对于 Leveling，合并操作还会包含 Level2 原有的 run。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210114224107.png" alt="20210114224107" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210115172909.png" alt="20210115172909" loading="lazy"></li>
<li><strong>Number of Levels</strong>：Level 0 拥有的数据项个数 <em>B * P</em>。$$L = [log_T(\frac{N}{B<em>P}</em>\frac{T-1}{T})]$$。层级之间的大小比例 T 被限制到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mo>≤</mo><mi>T</mi><mo>≤</mo><msub><mi>T</mi><mrow><mi>l</mi><mi>i</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">2 ≤ T ≤ T_{lim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.78041em;vertical-align:-0.13597em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.13597em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>l</mi><mi>i</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{lim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 被定义成 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>N</mi><mrow><mi>B</mi><mo>∗</mo><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{N}{B*P}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，当 size ratio 达到上界时，levels 的数量减少到接近 1，超过上界之后将无结构性的变化。大于下界就表明 第 i 级合并操作的结果运行永远不会大到超过第 i + 1 级。换句话说就是确保了 runs 不会跨多个 levels。</li>
<li><strong>Finding Entries</strong>：因为数据项是异地更新，相同 key 的数据的多个版本可能出现在多个 level 中，甚至对于 tiering 策略可能存在于一个 level 的多个 runs 中，为了确保查询操作总是能够找到最新版本的数据，LSM Tree 采用了如下措施：1. 当数据项被插入到 buffer 中且 buffer 中包含相同 key 对应的数据时，新的数据项将代替老的数据；2. 当两个包含相同 key 的数据项的 runs 被合并的时候，只有最新版本的数据将被保留；3. 为了能够获取到来自不同 runs 的相同 key 的不同数据项的插入顺序，一个单独的 run 只能够和相邻时间的 run 进行合并。从而保证当有两个 runs 包含不同版本的相同 key 对应的数据时，younger run 包含的是最新版本的数据。</li>
<li><strong>Point Lookups</strong>：点查询通过从最小到最大层次进行遍历来查询最新版本的数据，对于 tiering 则是在一个 level 中从最新到最老的 runs 中遍历进行查询。当找到一个匹配当前 key 的数据时则终止。</li>
<li><strong>Range Lookups</strong>：范围查询需要查找指定范围的键对应的所有最新的数据，通过对所有 levels 所有 runs 的相关键范围进行排序合并。当 sort-merging 时，识别出来自不同 runs 具有相同 key 的数据，然后丢弃掉老版本的数据。</li>
<li><strong>Deletes</strong>：通过给每个数据项添加一位 flag 来实现。如果查询操作找到了该数据想的最新版本，且该数据项上有该 flag 那么将不会返回对应的 value 给应用。当一个删除的数据项和 最老的 run 合并的时候，该数据将被删除，因为该数据项已经代替了之前所有插入的具有当前 key 的数据。</li>
<li><strong>Fragmented Merging</strong>：为了换接较大级别上由于长时间合并操作而导致的性能下降，主流设计把 runs 分区成了文件，也叫 Sorted String Tables，然后一次合并一个 SSTable 和下一个 older run 中具有重叠键范围的多个 SSTables，该技术不会影响最坏情况下的合并 I/O 开销，而只会影响这种开销如何调度。在整篇文章中，为了便于阅读，我们将合并操作讨论为具有 runs 的粒度，尽管它们也可以具有 sstables 的粒度。</li>
<li><strong>Space-Amplifcation</strong>：过时条目的存在使存储空间增大的因素称为空间放大。由于磁盘的可承受性，空间放大传统上并不是数据结构设计的主要关注点。然而，SSD 的出现使空间放大成为一个重要的成本问题。我们将空间放大作为成本指标，以提供我们所引入和评估的设计的完整描述。</li>
<li><strong>Fence Pointers</strong>：所有主要的基于 LSM 树的键值存储都在主存中对每次运行的每个块的第一个键建立索引，也就是图 2 所示的 fence pointer，通常这些指针占据内存空间大小为 O(N/B)，但是让查询操作中找到每个 runs 的 key 范围变成了只需要一次 I/O。</li>
<li><strong>Bloom Filters</strong>：为了加速点查找，只需要在主存中为每个 run 维护一个 BloomFilter，点查找在访问存储中相应的 runs 之前首先检查 Bloom flter。如果 filter 返回 true positive，那么查询操作配合 fence pointer 只需要一次 I/O 就能访问对应的 run，从而找到对应的数据项并终止。如果返回 negative，那么将跳过该 run 并节省一次 I/O 操作。但还有 false positive 的情况，浪费一次 I/O 然后再去下一个 run 继续查找该 key。</li>
<li>Bloom flter 有一个有用的特性，如果它被分割成较小的等大小的 Bloom flter，其中的条目也被等分，每一个新的分区布隆滤片的 FPR 渐近与原滤片的 FPR 相同(虽然实际略高)。为了便于讨论，我们将Bloom flters称为非分区的，尽管它们也可以按照工业中的某些设计进行分区（比如每个 run 的每个 block），从而为空间管理提供更大的灵活性。(例如，对于那些不经常被点查询读取的块，可以将其 offload 到存储器中以节省内存)</li>
<li><strong>Applicability Beyond Key-Value Stores</strong>：根据工业上的设计，我们的讨论假设一个键在运行过程中与它的值相邻存储。为了便于阅读，本文中的所有图形都将条目描述为键，但它们表示键-值对。我们的工作也适用于没有 value 的应用程序(例如，LSM-tree 被用来回答关于键的集合成员查询)，其中的值是指向存储在 LSM-tree 之外的数据对象的指针，或者 LSM-tree 被用作解决更复杂算法问题的构建块(例如，图分析)， FTL 设计等)。我们将分析的范围限制在基本操作和 LSM-tree 的大小上，以便它可以很容易地应用于这些其他情况。</li>
</ul>
<h2 id="design-space-and-problem-analysis">DESIGN SPACE AND PROBLEM ANALYSIS</h2>
<ul>
<li>现在，我们分析更新和查找的最差情况下的空间放大和 I/O 成本是如何从不同的级别派生出与合并策略和大小比例相关的。为了分析更新和查找，我们使用磁盘访问模型来计算每个操作的 I/O 数量，其中 I/O 是从二级存储读取或写入一个块。</li>
<li>分析结果如下所示：
<ul>
<li><strong>Updates</strong>：更新成本通常都是由更新条目参与的后续合并操作产生的，分析假设最坏情况的工作负载，其中所有更新的目标条目都在最大级别。这意味着一个过时的条目不会被删除，直到它相应的更新的条目达到最大级别。因此，每个条目都会在所有级别上合并(即，而不是在某个更小的级别上被最近的条目丢弃，从而减少以后合并操作的开销)。
<ul>
<li>tiering：每层合并 O(1) 次，每个合并过程中的 I/O 操作从原始的 run 中拷贝 B 个数据项到新的 run，因此每个数据项平均的更新操作成本开销如图所示。填满 level i，需要 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi><mo separator="true">⋅</mo><mi>P</mi><mo separator="true">⋅</mo><msup><mi>T</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">B · P · T^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span> 次更新，导致合并操作拷贝 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi><mo separator="true">⋅</mo><mi>P</mi><mo separator="true">⋅</mo><msup><mi>T</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">B · P · T^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span> 个数据项。</li>
<li>leveling：到达 level i 的第 j 个 run 触发了一个合并操作，合并操作包括 level i 现有的 runs，这些 runs 是自上次 level i 为空以来到达的前 T−j 个 runs 的合并操作产生的。因此平均每个数据项在该层数据到达容量之前合并了 T/2 次，可以表示为 O(T)，同样需要除以一个块对应的 B 个数据项。每 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi><mo separator="true">⋅</mo><mi>P</mi><mo separator="true">⋅</mo><msup><mi>T</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">B · P · T^{i-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 次更新（每次有一个新的 run come in）之后执行一次合并操作，然后拷贝平均 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>B</mi><mo separator="true">⋅</mo><mi>P</mi><mo separator="true">⋅</mo><msup><mi>T</mi><mi>i</mi></msup></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{B · P · T^i}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3704599999999998em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0254599999999998em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="mpunct mtight">⋅</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mpunct mtight">⋅</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9020857142857143em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 项数据，通过将复制的条目数除以级别 i 的合并操作的频率，<strong>我们观察到，在长期运行中，每个级别上的合并操作所做的工作量是相同的，直觉是，虽然合并操作在更大的级别上以指数方式完成更多的工作，但它们的频率也以指数方式降低</strong></li>
</ul>
</li>
<li><strong>Analyzing Point Lookups</strong>：为了分析最坏情况下的点查找代价，我们将重点放在 zero-result 点查找（例如查询不存在的 Key）上，因为它们最大化了浪费的 I/O 的平均值。这种分析对于插入前判断是否存在的操作就很有用。开销最大的情况即为所有的 BloomFilter 返回 false positive，此时点查询操作会对每一个 run 发起一次 I/O，<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210116202849.png" alt="20210116202849" loading="lazy"></li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CRaft: An Erasure-coding-supported Version of Raft for Reducing Storage Cost and Network Cost]]></title>
        <id>https://blog.shunzi.tech/post/CRaft/</id>
        <link href="https://blog.shunzi.tech/post/CRaft/">
        </link>
        <updated>2020-12-16T03:40:00.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>FAST2020 CRaft: An Erasure-coding-supported Version of Raft for Reducing Storage Cost and Network Cost</li>
<li>主要是利用纠删码基于 Raft 进行优化，降低一致性开销</li>
<li>本篇在介绍文章内容的同时，也会拓展一些 Raft/Paxo 的相关资料</li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>FAST2020 CRaft: An Erasure-coding-supported Version of Raft for Reducing Storage Cost and Network Cost</li>
<li>主要是利用纠删码基于 Raft 进行优化，降低一致性开销</li>
<li>本篇在介绍文章内容的同时，也会拓展一些 Raft/Paxo 的相关资料</li>
</ul>
</blockquote>
<!-- more -->
<h2 id="abstract">Abstract</h2>
<ul>
<li>一致性协议主要是在分布式系统中用于保证可靠性和可用性的，现有的一致性协议大多都是要将日志项给备份到所有的服务器中，这种全量的副本的策略在存储和网络上的开销都很大，严重影响性能，所以后来出现了纠删码，即在保证相同的容错能力的条件下减少存储和网络的开销。</li>
<li>RS-Paxos 是第一个支持 EC 数据的一致性协议，但是比起通用的一致性协议，如 Paxos/Raft，可用性都相对更差。我们指出了RSPaxos的活性问题，并试图解决，基于 Raft 提出了 CRaft，既能使用 EC 码像 RS-Paxos 一样降低存储和网络开销，也能保证如 Raft 一样的 liveness。</li>
<li>基于 CRaft 实现了一个 KVs，实验表明相对于 Raft 节省了 66% 的存储空间，写吞吐量提升了 250%，写延迟减少了 60.8%</li>
</ul>
<h2 id="introduction">Introduction</h2>
<ul>
<li><strong>共识算法介绍</strong>：共识协议协议通常保证安全性和活动性，这意味着它们总是返回正确的结果，并且在大多数服务器都没有发生故障的情况下可以完全正常工作。
<ul>
<li>Google’s Chubby 会使用 Paxos 对 metadata 做副本</li>
<li>Gaios(NSDI2011) 表明一致性协议可以被用于所有数据的 replicated</li>
<li>现如今大量应用如 etcd, TinyKV, FSS 等大规模系统都使用了 Raft/Paxos 来 replicated TB 数量级的数据，并提供更好的可用性</li>
</ul>
</li>
<li><strong>多副本介绍</strong>：数据操作通常在分布式系统中被转换为一系列的日志指令，然后使用一致性协议在所有的服务器之间进行备份，所以数据需要经过网络传输到所有的服务器，然后还要刷会到磁盘持久化保存。一致性问题中，容错率如果为 F，那么则至少需要 N = (2F + 1) 的服务器，否则就可能因为分组的原因出现不一致的情况。因此传统的副本策略往往就意味值原始数据量的 N 倍的网络和存储开销，而且随着这些协议在大规模存储系统中得到了越来越多的应用，N 倍的网络和存储开销带来的则是延迟的增加和吞吐量的下降。<strong>所以出现了 Erasure Coding</strong></li>
<li><strong>纠删码介绍</strong>：纠删码相比于全量拷贝的副本策略，极大地减小了存储和网络的开销。通过将数据进行分片，编码分片后的数据并生成一些校验的分片，原始的数据就能从足够数量的分片子集中恢复出来，这时候每个服务器只存储一个分片，而不是数据的全量拷贝，开销极大减小。FSS 中就使用了纠删码来减少存储开销，但是 FSS 在编码之前使用了一个 5 way 流水线 Paxos 来备份完整的用户数据和元数据，因此额外的网络开销还是有 4 倍数据量大小。</li>
<li><strong>RS-Paxos</strong> 是第一个结合了 Paxos 和 EC 的共识协议，虽然减少了存储和网络的开销，但是在可用性上比 Paxos 还是更差，RA-Paxos 牺牲了 liveness 来使用 EC 提升性能，换句话说就是 RS-Paoxs 如果有 N = (2F + 1) 的服务器不再能容忍 F 个错误，即容错率下降了，主要是因为 RS-Paxos 中的提交要求越来越严格。</li>
<li>作者提出了 erasure-coding-supported version of Raft <strong>CRaft</strong> (Coded Raft)。该方案中，一个 leader 有两种方法备份日志项到 followers，如果 leader 能够和足够数量的 followers 通信，那么 leader 将使用分片后的日志项进行备份，即传统纠删码的方式，否则将备份完整的数据以保证可用性。相比于 RS-Paxos，CRaft 最大的不同是拥有和 Paxos/Raft 相同级别的 liveness，而 RS-Paxos 没有，但是两个方案都节省了网络和存储的成本。</li>
</ul>
<h2 id="background">Background</h2>
<h3 id="raft">Raft</h3>
<ul>
<li>https://raft.github.io/</li>
<li>Raft 原始论文：https://raft.github.io/raft.pdf</li>
<li>Raft 中主要有三个角色/三种状态。Candidate 收到了来自大多数 servers 的选票后成为 Leader，一个 Server 只会给 和该 Server 日志同步的 Candidate 投票。每个 Server 每一轮最多投一次，所以 Raft 保证每一轮最多就一个 leader。
<ul>
<li>Leader: 处理所有客户端交互，日志复制等，一般一次只有一个Leader。</li>
<li>Follower: 类似选民，完全被动</li>
<li>Candidate候选人: 类似Proposer，可以被选为一个新的 Leader</li>
</ul>
</li>
<li>leader 从客户端接收日志条目，并试图将它们复制到其他服务器，迫使其他服务器的日志与自己的日志一致。当 leader 发现这一轮中有日志被被分到了大多数 servers，该日志项和之前的日志将被安全地应用到状态机中。Leader 将提交并应用这些日志项，然后告诉 followers 也 apply 他们。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201216220445.png" alt="20201216220445" loading="lazy"></li>
<li>用于实际系统的共识协议通常具有以下特性：
<ul>
<li>Safety：它们不会在所有非拜占庭条件下返回错误的结果</li>
<li>Liveness：只要大多数服务器都处于活动状态，并且能够相互通信和与客户端通信，它们就能完全发挥作用。我们称这组服务器是健康的</li>
</ul>
</li>
<li>Raft 中的 Safety 是由 Leader Completeness Property 来保证的， 如果在给定 term 提交了日志条目，那么该条目将出现在所有编号较高的 term 的 leader 日志中。</li>
<li>Liveness 由 Raft 规则保证，通常使用了一致性协议的系统的服务器的数量常常为奇数，假设 N = 2F + 1，Raft 可以容忍 F 个错误，我们定义一个一致性协议可以容忍的失败数量作为 liveness level，所以此时的 liveness level 为 F，更高的 liveness level 意味着更好的 liveness，没有一个协议的 liveness level 可以达到 F+1，因为如果存在这样的协议，则可能存在两个分裂的 F 个健康服务器组，这两个组可以分别就不同的内容达成一致，这是违反安全特性的。</li>
</ul>
<h3 id="erasure-coding">Erasure Coding</h3>
<ul>
<li>擦除编码是存储系统和网络传输中容忍错误的常用技术。们已经提出了大量的编码，其中最常用的是Reed-Solomon (RS)编码。RS 码中有两个可配置的正整数参数 k 和 m，数据被分成了相同大小的 k 个分片，然后使用这 k 个原始的数据分片计算出 m 个类似的校验分片，也就是编码过程，此时总共将有 k+m 个分片，(k,m)-RS 码就意味着所有分片中的任意 k 个分片就能恢复出原始数据，这就是 RS 码的容错原理。（类似于解方程的过程）</li>
<li>当引入一致性协议，k + m = N，N 为服务器的总数量，存储和网络开销将被见效的全拷贝的 1/k，然而如何保证 safety 和 liveness 不容忽视</li>
</ul>
<h3 id="rs-paxos">RS-Paxos</h3>
<ul>
<li>RS-Paxos 是将纠删编码与 Paxos 相结合的一种 Paxos 的改革版本，可以节省存储和网络成本。在 Paxos 中，命令被完全传输。然而，在 RS-Paxos 中，命令是通过代码片段传输的。根据这一变化，服务器在 RS-Paxos 中只能存储和传输片段，从而降低了存储和网络成本。</li>
<li>为了保证安全性和活动性，Paxos和Raft基于以下包容-排斥原则。</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">∣</mi><mi>A</mi><mo>∪</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mo>=</mo><mi mathvariant="normal">∣</mi><mi>A</mi><mi mathvariant="normal">∣</mi><mo>+</mo><mi mathvariant="normal">∣</mi><mi>B</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">−</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo>∩</mo><mi>B</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|A∪B| = |A|+|B| −|A∩B|
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord">−</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span></span></span></span></span></p>
<p>包含排除原则保证在两个不同的服务器组合中至少有一个服务器的数量差距，这样安全性就可以得到保证。</p>
<ul>
<li>RS-Paxos 的想法是增加交集集的大小。具体来说，在选择了一个 (k,m)-RS 代码后，读quorum QR、写 quorum QW 和服务器数量 N 应该符合以下公式。</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>Q</mi><mi>R</mi></msub><mo>+</mo><msub><mi>Q</mi><mi>W</mi></msub><mi mathvariant="normal">−</mi><mi>N</mi><mo>≥</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">Q_R +Q_W −N ≥ k
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">−</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span></span></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alluxio]]></title>
        <id>https://blog.shunzi.tech/post/Alluxio/</id>
        <link href="https://blog.shunzi.tech/post/Alluxio/">
        </link>
        <updated>2020-12-10T02:21:17.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>Alluxio 简单介绍，测试报告，然后会结合一些实际体验。</li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>Alluxio 简单介绍，测试报告，然后会结合一些实际体验。</li>
</ul>
</blockquote>
<!-- more -->
<h1 id="alluxio">Alluxio</h1>
<ul>
<li>Alluxio（之前名为 Tachyon），是一个开源的具有内存级速度的虚拟分布式存储系统， 使得应用程序可以以内存级速度与任何存储系统中的数据进行交互。</li>
<li>源码：https://github.com/Alluxio/alluxio</li>
<li>论文：https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-29.pdf</li>
</ul>
<h2 id="架构">架构</h2>
<ul>
<li>文档：https://docs.alluxio.io/os/user/stable/cn/Overview.html</li>
<li>初衷：建立底层存储和大数据计算框架之间的存储系统，为大数据应用提供一个数量级的加速，同时它还提供了通用的数据访问接口。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201210191906.png" alt="20201210191906" loading="lazy"></li>
<li>主要分为两层：UFS 和 Alluxio
<ul>
<li>UFS：底层文件存储，该存储空间代表不受Alluxio管理的空间。
<ul>
<li>UFS存储可能来自外部文件系统，包括如HDFS或S3。 Alluxio可能连接到一个或多个UFS并在一个命名空间中统一呈现这类底层存储。</li>
<li>通常，UFS存储旨在相当长一段时间持久存储大量数据。</li>
</ul>
</li>
<li>Alluxio 存储：
<ul>
<li>Alluxio 做为一个分布式缓存来管理 Alluxio workers 本地存储，包括内存。这个在用户应用程序与各种底层存储之间的快速数据层带来的是显著提高的I/O性能。</li>
<li>Alluxio存储主要用于存储热的、暂时的数据，而不关注长期的持久性。</li>
<li>要管理的每个Alluxio工作节点的存储数量和类型由用户配置决定。</li>
<li><strong>即使数据当前不在Alluxio存储中，通过Alluxio连接的UFS​​中的文件仍然 对Alluxio客户可见。当客户端尝试读取仅可从UFS获得的文件时数据将被复制到Alluxio存储中。</strong></li>
</ul>
</li>
</ul>
</li>
<li>和其他常见的分布式文件系统对比：<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201211095549.png" alt="20201211095549" loading="lazy"></li>
</ul>
<h3 id="角色">角色</h3>
<ul>
<li>Alluxio的设计使用了单Master和多Worker的架构。从高层的概念理解，Alluxio可以被分为三个部分，Master，Worker和Client。
<ul>
<li>Master和Worker一起组成了Alluxio的服务端，它们是系统管理员维护和管理的组件。</li>
<li>Client通常是应用程序，如Spark或MapReduce作业，或者Alluxio的命令行用户。</li>
</ul>
</li>
<li>以前的版本需要借助 ZooKeeper 进行高可用选主，后续的 Alluxio 自己实现了高可用机制。（注：Tachyon 为 Alluxio 旧称）<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201211093448.png" alt="20201211093448" loading="lazy"></li>
</ul>
<h4 id="master">Master</h4>
<ul>
<li>
<p>主从模式：主Master主要负责处理全局的系统元数据，从Master不断的读取并处理主Master写的日志。同时从Master会周期性的把所有的状态写入日志。从Master不处理任何请求。</p>
<ul>
<li>主从之间心跳检测</li>
<li>主Master不会主动发起与其他组件的通信，它只是以回复请求的方式与其他组件进行通信。一个Alluxio集群只有一个主Master。</li>
</ul>
</li>
<li>
<p>简单模式：最多只会有一个从Master，而且这个从Master不会被转换为主Maste。</p>
</li>
<li>
<p>高可用模式：可以有零个或者多个从Master。 当主Master异常的时候，系统会选一个从Master担任新的主Master。</p>
</li>
</ul>
<h4 id="worker">Worker</h4>
<ul>
<li>类似于 OSD</li>
<li>Alluxio的Worker负责管理分配给Alluxio的本地资源。这些资源可以是本地内存，SSD 或者硬盘，其可以由用户配置。</li>
<li>Alluxio的Worker以块的形式存储数据，并通过读或创建数据块的方式处理来自Client读写数据的请求。但Worker只负责这些数据块上的数据；文件到块的实际映射只会存储在Master上。</li>
</ul>
<h2 id="features">Features</h2>
<h3 id="全局命名空间">全局命名空间</h3>
<ul>
<li>Alluxio通过使用透明的命名机制和挂载API来实现有效的跨不同底层存储系统的数据管理。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201210220101.png" alt="20201210220101" loading="lazy"></li>
<li>https://www.alluxio.io/resources/whitepapers/unified-namespace-allowing-applications-to-access-data-anywhere/</li>
</ul>
<h3 id="智能多层级缓存">智能多层级缓存</h3>
<ul>
<li>Alluxio支持分层存储，以便管理内存之外的其它存储类型。目前Alluxio支持这些存储类型(存储层)：MEM (内存)，SSD (固态硬盘)，HDD (硬盘驱动器)</li>
<li><strong>单层/多层 区别？</strong></li>
</ul>
<h4 id="单层存储">单层存储</h4>
<ul>
<li>启动时默认分配一个 ramdisk，Alluxio将在每个worker节点上默认发放一个ramdisk并占用一定比例的系统的总内存。 此ramdisk将用作分配给每个Alluxio worker的唯一存储介质。</li>
<li>可以显示地设置每个 Worker 的 ramdisk 大小</li>
</ul>
<pre><code class="language-shell">alluxio.worker.ramdisk.size=16GB
</code></pre>
<ul>
<li>可以指定多个存储介质共同组成一个 level，也可以自定义添加存储介质类型</li>
</ul>
<pre><code class="language-shell">alluxio.worker.tieredstore.level0.dirs.path=/mnt/ramdisk,/mnt/ssd1,/mnt/ssd2
alluxio.worker.tieredstore.level0.dirs.mediumtype=MEM,SSD,SSD
</code></pre>
<ul>
<li>所提供的路径应该指向安装适当存储介质的本地文件系统中的路径。要启用短路操作，这些路径的权限应该允许客户端用户对该路径进行读、写和执行。例如，启动Alluxio服务的同一用户组中的客户端用户需要770权限。</li>
<li>在更新存储媒体之后，我们需要指出为每个存储目录分配了多少存储空间。例如，如果我们想在ramdisk上使用 16GB，在每个 SSD 上使用 100GB:</li>
</ul>
<pre><code class="language-shell">alluxio.worker.tieredstore.level0.dirs.quota=16GB,100GB,100GB
</code></pre>
<h4 id="多层存储">多层存储</h4>
<ul>
<li>通常建议使用具有异构存储介质的单一存储层。在某些环境中，工作负载将受益于基于I/O速度的存储介质显式排序。Alluxio假设层是根据I/O性能从上到下排序的。例如，用户经常指定以下层:
<ul>
<li>MEM</li>
<li>SSD</li>
<li>HDD</li>
</ul>
</li>
<li><strong>写策略</strong>：用户写新的数据块时，默认情况下会将其写入顶层存储。如果顶层没有足够的可用空间， 则会尝试下一层促成。如果在所有层上均未找到存储空间，因Alluxio的设计是易失性存储，Alluxio会释放空间来存储新写入的数据块。会基于  block annotation policies 尝试从 worker 中驱逐数据，如果不能释放出新的空间，那么该写入将会失败。
<ul>
<li>eviction model 是同步的且是代表客户端来执行空间的释放的，主要是为要写入的客户端的数据腾出一块空闲空间，这种同步模式预计不会导致性能下降，因为在 block annotation policies 下有序的一组数据块通常都是可用的。</li>
</ul>
</li>
<li><strong>读策略</strong>：如果数据已经存在于Alluxio中，则客户端将简单地从已存储的数据块读取数据。 如果将Alluxio配置为多层，则不一定是从顶层读取数据块， 因为数据可能已经透明地挪到更低的存储层。有两种数据读取策略：<code>ReadType.CACHE</code> and <code>ReadType.CACHE_PROMOTE</code>。
<ul>
<li>用 <code>ReadType.CACHE_PROMOTE</code> 读取数据将在从worker读取数据前尝试首先将数据块挪到 顶层存储。也可以将其用作为一种数据管理策略 显式地将热数据移动到更高层存储读取。</li>
<li><code>ReadType.CACHE</code> Alluxio将块缓存到有可用空间的最高层。因此，如果该块当前位于磁盘(SSD/HDD)上，您将以磁盘速度读取该缓存块。</li>
</ul>
</li>
</ul>
<pre><code class="language-shell"># configure 2 tiers in Alluxio
alluxio.worker.tieredstore.levels=2
# the first (top) tier to be a memory tier
alluxio.worker.tieredstore.level0.alias=MEM
# defined `/mnt/ramdisk` to be the file path to the first tier
alluxio.worker.tieredstore.level0.dirs.path=/mnt/ramdisk
# defined MEM to be the medium type of the ramdisk directory
alluxio.worker.tieredstore.level0.dirs.mediumtype=MEM
# set the quota for the ramdisk to be `100GB`
alluxio.worker.tieredstore.level0.dirs.quota=100GB
# configure the second tier to be a hard disk tier
alluxio.worker.tieredstore.level1.alias=HDD
# configured 3 separate file paths for the second tier
alluxio.worker.tieredstore.level1.dirs.path=/mnt/hdd1,/mnt/hdd2,/mnt/hdd3
# defined HDD to be the medium type of the second tier
alluxio.worker.tieredstore.level1.dirs.mediumtype=HDD,HDD,HDD
# define the quota for each of the 3 file paths of the second tier
alluxio.worker.tieredstore.level1.dirs.quota=2TB,5TB,500GB
</code></pre>
<h5 id="block-allocation-policies">Block Allocation Policies</h5>
<ul>
<li>Alluxio使用块分配策略来定义如何跨多个存储目录(在同一层或不同层中)分配新块。分配策略定义将新块分配到哪个存储目录中。这是通过 worker 属性 <code>alluxio.worker.allocate.class</code> 配置的。
<ul>
<li><code>MaxFreeAllocator</code>：从 0 层开始尝试到最低层，尝试将块分配到当前最具有可用性的存储目录。这是默认行为。</li>
<li><code>RoundRobinAllocator</code>：从 0 层到最低层开始尝试。在每一层上，维护存储目录的循环顺序。尝试按照轮询顺序将新块分配到一个目录中，如果这不起作用，就转到下一层。</li>
<li><code>GreedyAllocator</code>：这是 Allocator 接口的一个示例实现。它从顶层循环到最低层，尝试将新块放入可以包含该块的第一个目录中。</li>
</ul>
</li>
</ul>
<h5 id="experimental-block-allocation-review-policies">[Experimental] Block Allocation Review Policies</h5>
<ul>
<li>这是在Alluxio 2.4.1中增加的一个实验特性。在未来的版本中，接口可能会发生变化。</li>
<li>Alluxio 使用块分配审查策略来补充分配策略。与定义分配应该是什么样子的分配策略相比，分配审查过程验证分配决策，并防止那些不够好的分配决策。评审者与分配器一起工作</li>
<li>这是由worker属性 <code>alluxio.worker.review.class</code> 配置的。
<ul>
<li><code>ProbabilisticBufferReviewer</code>：基于每个存储目录对应的可用的空间，概率性低拒绝把新的数据块写入对应目录的请求。这个概率由 <code>alluxio.worker.reviewer.probabilistic.hardlimit.bytes</code> 和 <code>alluxio.worker.reviewer.probabilistic.softlimit.bytes</code> 来决定。
<ul>
<li>当可用空间低于 hardlimit，默认是 64MB，新的块将被拒绝</li>
<li>当可用空间大于 softlimit，默认 256MB，新的数据块将不会被拒绝</li>
<li>当可用空间介于上下限之间时，接受新的块的写入的概率将会随着可用容量的下降而线性低下降，我们选择在目录被填满之前尽早拒绝新的块，因为当我们读取块中的新数据时，目录中的现有块会扩大大小。在每个目录中留下缓冲区可以减少 eviction 的机会。</li>
</ul>
</li>
<li><code>AcceptingReviewer</code>：此审阅者接受每个块分配。和 v2.4.1 之前的行为完全一样</li>
</ul>
</li>
</ul>
<h5 id="block-annotation-policies">Block Annotation Policies</h5>
<ul>
<li>Alluxio使用块注释策略(从v2.3开始)来保持存储中块的严格顺序。Annotation策略定义了跨层块的顺序，并在以下过程中被参考:
<ul>
<li>Eviction</li>
<li>Dynamic Block Placement.</li>
</ul>
</li>
<li>与写操作一起发生的 Eviction 操作将尝试根据块注释策略执行的顺序删除块。按注释顺序排列的最后一个块是驱逐的第一个候选者，无论它位于哪一层。</li>
<li>可配置对应的 Anotator 类型，<code>alluxio.worker.block.annotator.class</code>。有如下 annotation 实现：
<ul>
<li><code>LRUAnnotator</code>：根据最近最少使用的顺序注释块。这是Alluxio的默认注释器。</li>
<li><code>LRFUAnnotator</code>：使用可配置的权重，根据最近最不常用和最不常用的顺序注释块。
<ul>
<li>如果权重完全偏向最近最少使用的，行为将与LRUAnnotator相同。</li>
<li>使用 <code>alluxio.worker.block.annotator.lrfu.step.factor</code> 和 <code>alluxio.worker.block.annotator.lrfu.attenuation.factor</code> 来配置。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="managing-data-replication-in-alluxio">Managing Data Replication in Alluxio</h4>
<h5 id="passive-replication">Passive Replication</h5>
<ul>
<li>与许多分布式文件系统一样，Alluxio中的每个文件都包含一个或多个分布在集群中存储的存储块。默认情况下，Alluxio可以根据工作负载和存储容量自动调整不同块的复制级别。例如，当更多的客户以类型CACHE或CACHE_PROMOTE请求来读取此块时Alluxio可能会创建此特定块更多副本。当较少使用现有副本时，Alluxio可能会删除一些不常用现有副本 来为经常访问的数据征回空间(块注释策略)。 在同一文件中不同的块可能根据访问频率不同而具有不同数量副本。</li>
<li>默认情况下，此复制或征回决定以及相应的数据传输 对访问存储在Alluxio中数据的用户和应用程序完全透明。</li>
</ul>
<h5 id="active-replication">Active Replication</h5>
<ul>
<li>除了动态复制调整之外，Alluxio还提供API和命令行 界面供用户明确设置文件的复制级别目标范围。 尤其是，用户可以在Alluxio中为文件配置以下两个属性:
<ul>
<li><code>alluxio.user.file.replication.min</code> 是此文件的最小副本数。 默认值为0，即在默认情况下，Alluxio可能会在文件变冷后从Alluxio管理空间完全删除该文件。 通过将此属性设置为正整数，Alluxio 将定期检查此文件中所有块的复制级别。当某些块 的复制数不足时，Alluxio不会删除这些块中的任何一个，而是主动创建更多 副本以恢复其复制级别。</li>
<li><code>alluxio.user.file.replication.max</code> 是最大副本数。一旦文件该属性 设置为正整数，Alluxio将检查复制级别并删除多余的 副本。将此属性设置为-1为不设上限(默认情况)，设置为0以防止 在Alluxio中存储此文件的任何数据。注意，<code>alluxio.user.file.replication.max</code> 的值 必须不少于 <code>alluxio.user.file.replication.min</code>。</li>
</ul>
</li>
</ul>
<h2 id="evaluation">Evaluation</h2>
<h3 id="testing-alluxio-for-memory-speed-computation-on-ceph-objects">Testing Alluxio for Memory Speed Computation on Ceph Objects</h3>
<ul>
<li>https://blog.zhaw.ch/icclab/testing-alluxio-for-memory-speed-computation-on-ceph-objects/#more-12747</li>
<li>4th SEPTEMBER 2020</li>
</ul>
<h4 id="环境介绍">环境介绍</h4>
<ul>
<li>底层存储：Ceph mimic
<ul>
<li>6 OpenStack VMs
<ul>
<li>one Ceph monitor</li>
<li>three storage devices running Object Storage Devices (OSDs)</li>
<li>one Ceph RADOS Gateway (RGW) node</li>
<li>one administration node</li>
</ul>
</li>
<li>total storage size of 420GiB was spread over 7 OSD volumes attached to the three OSD nodes</li>
</ul>
</li>
<li>Alluxio 2.3， Java8 (换成 Java11 即升级 Alluxio 后会有后续提升)</li>
<li>Spark 3.0.0</li>
<li>两种模式：
<ul>
<li>单 VM 运行 Alluxio 和 Spark （16vCPU，40GB of memory）</li>
<li>集群模式：two additional Spark and Alluxio worker nodes are configured (with 16vCPUs and 40GB of memory).</li>
</ul>
</li>
<li>对比测试：
<ul>
<li>直接访问 Ceph RGW 和 通过 Alluxio 访问
<ul>
<li>通过 Alluxio 访问时，第一次访问文件的话，Alluxio 会将文件上传到内存中，后续的文件访问将直接命中内存，从而带来显著的性能提升。</li>
</ul>
</li>
<li>不同文件大小： 1GB, 5GB and 10GB，记录第一层和第二次访问文件需要的时间。
<ul>
<li>平均会运行超过 10 次</li>
<li>然后再次启动相同的应用程序，以再次测量相同的文件访问时间。这样做的目的是展示内存中的 Alluxio 缓存如何为以后访问相同数据的应用程序带来好处。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="测试结果">测试结果：</h4>
<ul>
<li>如下为单节点测试测试结果，Ceph 上第二次访问该文件相比于 Alluxio 在 1GB,5GB,10GB 时的执行时间分别为 75x，111x，107x<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201211113435.png" alt="20201211113435" loading="lazy"></li>
<li>如下为集群模式下的测试结果，所有情况的整体时间比单机的时候少了很多，Ceph 相比于 Alluxio 的第二次访问时间为 35x, 57x, 65x<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201211114027.png" alt="20201211114027" loading="lazy"></li>
</ul>
<h3 id="accelerate-and-scale-big-data-analytics-with-alluxio-and-inteloptanetm-persistent-memory">Accelerate And Scale Big Data AnAlytics with Alluxio And intel®optane™ persistent Memory</h3>
<ul>
<li>https://www.alluxio.io/app/uploads/2020/05/Intel-Alluxio-DCPMM-Whitepaper-200507.pdf</li>
</ul>
<h3 id="reliability-testing">Reliability Testing</h3>
<ul>
<li>TODO</li>
</ul>
<h2 id="install-deploy">Install &amp; Deploy</h2>
<h3 id="single-server">Single Server</h3>
<h4 id="download">Download</h4>
<ul>
<li>Download Binary: https://www.alluxio.io/download/</li>
<li>Choose Version. (eg. Alluxio 2.4.1 Release. 1.4GB)</li>
<li>Tar file: <code>tar -xzf alluxio-2.4.1-bin.tar.gz</code></li>
</ul>
<h4 id="initial-config">Initial Config</h4>
<ul>
<li><code>cd alluxio-2.4.1/conf &amp;&amp; cp alluxio-site.properties.template alluxio-site.properties</code></li>
<li><code>echo &quot;alluxio.master.hostname=localhost&quot; &gt;&gt; conf/alluxio-site.properties</code></li>
<li>[Optional] If use local file system, you can specific configuration in conf files like this: <code>echo &quot;alluxio.master.mount.table.root.ufs=/root/shunzi/Alluxio/tmp&quot; &gt;&gt; conf/alluxio-site.properties</code></li>
<li>Validate env: <code>./bin/alluxio validateEnv local</code></li>
</ul>
<pre><code class="language-cmd">2 Errors:
ValidateRamDiskMountPrivilege
ValidateHdfsVersion
</code></pre>
<h4 id="start-alluxio">Start Alluxio</h4>
<ul>
<li>Format journal and storage directory: <code>./bin/alluxio format</code>
<ul>
<li>It may throw exceptions <code>java.nio.file.NoSuchFileException: /mnt/ramdisk/alluxioworker</code> in <code>log/task.log</code>. So you need to <code>mkdir -p /mnt/ramdisk/alluxioworker</code></li>
</ul>
</li>
<li>Start alluxio (with a master and a worker): <code>./bin/alluxio-start.sh local SudoMount</code></li>
<li>Stop local server: <code>./bin/alluxio-stop.sh local</code>
<ul>
<li><code>./bin/alluxio-stop.sh all</code></li>
</ul>
</li>
</ul>
<h5 id="verify">Verify</h5>
<ul>
<li>Access website <code>http://localhost:19999</code> to check the master server status.</li>
<li>Access website <code>http://localhost:30000</code> to check the worker server status.</li>
<li>For internal network, you can use reverse proxy like this: (And you can access website <strong>master</strong> <code>http://114.116.234.136:19999</code> and <strong>worker</strong> <code>http://114.116.234.136:30000</code>)
<ul>
<li><code>autossh -M 1999 -fNR 19999:localhost:19999 root@114.116.234.136</code></li>
<li><code>autossh -M 3000 -fNR 30000:localhost:30000 root@114.116.234.136</code></li>
</ul>
</li>
</ul>
<h5 id="run-tests">Run tests</h5>
<ul>
<li>Verify run status and run test cases: <code>./bin/alluxio runTests</code></li>
<li>The runTests command runs end-to-end tests on an Alluxio cluster to provide a comprehensive sanity check.</li>
<li>It will generate directory <code>/default_tests_files</code> and use different cache policy to upload files.
<ul>
<li>BASIC_CACHE_ASYNC_THROUGH</li>
<li>BASIC_CACHE_CACHE_THROUGH</li>
<li>BASIC_CACHE_MUST_CACHE</li>
<li>BASIC_CACHE_PROMOTE_ASYNC_THROUGH</li>
<li>BASIC_CACHE_PROMOTE_CACHE_THROUGH</li>
<li>BASIC_CACHE_PROMOTE_MUST_CACHE</li>
<li>BASIC_CACHE_PROMOTE_THROUGH</li>
<li>BASIC_CACHE_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_CACHE_ASYNC_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_CACHE_CACHE_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_CACHE_MUST_CACHE</li>
<li>BASIC_NON_BYTE_BUFFER_CACHE_PROMOTE_ASYNC_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_CACHE_PROMOTE_CACHE_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_CACHE_PROMOTE_MUST_CACHE</li>
<li>BASIC_NON_BYTE_BUFFER_CACHE_PROMOTE_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_CACHE_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_NO_CACHE_ASYNC_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_NO_CACHE_CACHE_THROUGH</li>
<li>BASIC_NON_BYTE_BUFFER_NO_CACHE_MUST_CACHE</li>
<li>BASIC_NON_BYTE_BUFFER_NO_CACHE_THROUGH</li>
<li>BASIC_NO_CACHE_ASYNC_THROUGH</li>
<li>BASIC_NO_CACHE_CACHE_THROUGH</li>
<li>BASIC_NO_CACHE_MUST_CACHE</li>
<li>BASIC_NO_CACHE_THROUGH</li>
</ul>
</li>
</ul>
<h4 id="simple-example">Simple Example</h4>
<h5 id="upload-files-from-local-server">Upload files from local server</h5>
<ul>
<li>Show fs command help: <code>./bin/alluxio fs</code></li>
<li>List the files in Alluxio: <code>./bin/alluxio fs ls /</code></li>
<li>Copy files from local server: <code>./bin/alluxio fs copyFromLocal LICENSE /LICENSE</code></li>
<li>List again: <code>./bin/alluxio fs ls /</code></li>
<li>Cat the file: <code>./bin/alluxio fs cat /LICENSE</code></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li><a href="https://docs.alluxio.io/os/user/stable/cn/overview/Getting-Started.html">[1] Alluxio 快速上手指南</a></li>
<li><a href="https://blog.csdn.net/baichoufei90/article/details/107322069">[2] CSDN - Alluxio学习</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/127118960">[3] 知乎 - 路云飞：Alluxio 技术分析</a></li>
<li><a href="https://www.zhihu.com/column/alluxio">[4] 知乎 - Alluxio 专栏</a></li>
<li><a href="https://www.jianshu.com/p/481675971727">[5] 简书 - Alluxio：架构及数据流</a></li>
<li><a href="https://www.infoq.cn/article/q58xagobiioimqeem-a9">[6] InfoQ - Alluxio在多级分布式缓存系统中的应用</a></li>
<li><a href="https://pdf.dfcfw.com/pdf/H3_AP201912181371929557_1.pdf?1596649255000.pdf">[7] Alluxio 开源 AI 和大数据存储编排平台-顾荣</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocksDB Write Amplification Optimazation]]></title>
        <id>https://blog.shunzi.tech/post/RocksDB-Write-Amp/</id>
        <link href="https://blog.shunzi.tech/post/RocksDB-Write-Amp/">
        </link>
        <updated>2020-12-10T02:21:17.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>The write amplification is severe in RocksDB and results in significant performance degradation. And we will summarize the main reasons for write amplification.</li>
<li>A lot of researchers dedicate to reduce write amplification whether in academia or industry. And we will summarize the solutions and try to classfify solutions.</li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>The write amplification is severe in RocksDB and results in significant performance degradation. And we will summarize the main reasons for write amplification.</li>
<li>A lot of researchers dedicate to reduce write amplification whether in academia or industry. And we will summarize the solutions and try to classfify solutions.</li>
</ul>
</blockquote>
<!-- more -->
<h1 id="introduction">Introduction</h1>
<h2 id="rocksdb">RocksDB</h2>
<h3 id="references">References</h3>
<ul>
<li>official site: https://rocksdb.org/</li>
<li>doc: https://github.com/facebook/rocksdb/wiki</li>
<li>src: https://github.com/facebook/rocksdb/</li>
</ul>
<h3 id="brief-intro">Brief Intro</h3>
<ul>
<li>RocksDB is a storage engine with key/value interface, where keys and values are arbitrary byte streams. It is a C++ library. It was developed at Facebook based on LevelDB and provides backwards-compatible support for LevelDB APIs.
<ul>
<li>RocskDB Features that are not in LevelDB: https://github.com/facebook/rocksdb/wiki/Features-Not-in-LevelDB</li>
</ul>
</li>
</ul>
<h3 id="architecture">Architecture</h3>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201228165114.png" alt="20201228165114" loading="lazy"></figure>
<h4 id="components">Components</h4>
<h5 id="memtable">MemTable</h5>
<ul>
<li>
<p><strong>MemTable</strong> is an in-memory data-structure holding data before they are flushed to SST files. It serves both read and write - new writes always insert data to memtable, and reads has to query memtable before reading from SST files, because data in memtable is newer. Once a memtable is full, it becomes immutable and replace by a new memtable. A background thread will flush the content of the memtable into a SST file, after which the memtable can be destroyed.</p>
<ul>
<li><strong>Skiplist MemTable</strong>: Skiplist-based memtable provides general good performance to both read and write, random access and sequential scan. Besides, it provides some other useful features that other memtable implementations don't currently support, like Concurrent Insert and Insert with Hint.
<blockquote>
<ul>
<li><strong>InsertWithHint</strong>: Inserts a key allocated by AllocateKey with a hint of last insert position in the skip-list. If hint points to nullptr, a new hint will be populated, which can be used in subsequent calls. Friendly for sequential inserts</li>
</ul>
</blockquote>
</li>
<li><strong>HashSkiplist MemTable</strong>: As their names imply, HashSkipList organizes data in a hash table with each hash bucket to be a skip list, while HashLinkList organizes data in a hash table with each hash bucket as a sorted single linked list. Both types are built to reduce number of comparisons when doing queries. One good use case is to combine them with PlainTable SST format and store data in RAMFS.</li>
</ul>
</li>
<li>
<p><strong>Mutable/Immutable</strong>: When mutable memtable is full, the memtable becomes immutable and can not be moddfied.</p>
</li>
<li>
<p><strong>Flush</strong>: <strong>MemTable -&gt; SSTable</strong></p>
<ol>
<li>
<p>Memtable size exceeds <code>write_buffer_size</code> after a write.</p>
<ul>
<li><code>write_buffer_size</code>: Size of a single memtable.</li>
</ul>
</li>
<li>
<p>Total memtable size across all column families exceeds <code>db_write_buffer_size</code>, or <code>write_buffer_manager</code> signals a flush. In this scenario the largest memtable will be flushed.</p>
<ul>
<li><code>db_write_buffer_size</code>: Total size of memtables across column families. This can be used to manage the total memory used by memtables.</li>
<li><code>write_buffer_manager</code>: Instead of specifying a total size of memtables, user can provide their own write buffer manager to control the overall memtable memory usage. Overrides <code>db_write_buffer_size</code>.</li>
</ul>
</li>
<li>
<p>Total WAL file size exceeds <code>max_total_wal_size</code>. In this scenario the memtable with the oldest data will be flushed, in order to allow the WAL file with data from this memtable to be purged.</p>
</li>
</ol>
</li>
<li>
<p><strong>Comparison</strong></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>Mem Table Type</th>
<th>SkipList</th>
<th>HashSkipList</th>
<th>HashLinkList</th>
<th>Vector</th>
</tr>
</thead>
<tbody>
<tr>
<td>Optimized Use Case</td>
<td>General</td>
<td>Range query within a specific key prefix</td>
<td>Range query within a specific key prefix and there are only a small number of rows for each prefix</td>
<td>Random write heavy workload</td>
</tr>
<tr>
<td>Index type</td>
<td>binary search</td>
<td>hash + binary search</td>
<td>hash + linear search</td>
<td>linear search</td>
</tr>
<tr>
<td>Support totally ordered full db scan?</td>
<td>naturally</td>
<td>very costly (copy and sort to create a temporary totally-ordered view)</td>
<td>very costly (copy and sort to create a temporary totally-ordered view)</td>
<td>very costly (copy and sort to create a temporary totally-ordered view)</td>
</tr>
<tr>
<td>Memory Overhead</td>
<td>Average (multiple pointers per entry)</td>
<td>High (Hash Buckets + Skip List Metadata for non-empty buckets + multiple pointers per entry)</td>
<td>Lower (Hash buckets + pointer per entry)</td>
<td>Low (pre-allocated space at the end of vector)</td>
</tr>
<tr>
<td>MemTable Flush</td>
<td>Fast with constant extra memory</td>
<td>Slow with high temporary memory usage</td>
<td>Slow with high temporary memory usage</td>
<td>Slow with constant extra memory</td>
</tr>
<tr>
<td>Concurrent Insert</td>
<td>Support</td>
<td>Not support</td>
<td>Not support</td>
<td>Not support</td>
</tr>
<tr>
<td>Insert with Hint</td>
<td>Support (in case there are no concurrent insert)</td>
<td>Not support</td>
<td>Not support</td>
<td>Not support</td>
</tr>
</tbody>
</table>
<h5 id="block-cache">Block Cache</h5>
<ul>
<li><strong>Block cache</strong> is where RocksDB caches data in memory for reads. User can pass in a Cache object to a RocksDB instance with a desired capacity (size). A Cache object can be shared by multiple RocksDB instances in the same process, allowing users to control the overall cache capacity. The block cache stores uncompressed blocks. Optionally user can set a second block cache storing compressed blocks. Reads will fetch data blocks first from uncompressed block cache, then compressed block cache. The compressed block cache can be a replacement of OS page cache, if Direct-IO is used.</li>
<li>There are two cache implementations in RocksDB, namely <code>LRUCache</code> and <code>ClockCache</code>. Both types of the cache are sharded to mitigate lock contention. Capacity is divided evenly to each shard and shards don't share capacity. By default each cache will be sharded into at most 64 shards, with each shard has no less than 512k bytes of capacity.</li>
<li><strong>In default, RocksDB will use LRU-based block cache implementation with 8MB capacity</strong>.</li>
<li><code>LRUCache</code> vs <code>ClockCache</code> in RocksDB: https://github.com/facebook/rocksdb/wiki/Block-Cache#clock-cache</li>
<li>If the data block is not found in block cache, RocksDB reads it from file using buffered IO. That means it also uses the OS's page cache for raw file blocks, usually containing compressed data. In a way, RocksDB's cache is two-tiered: block cache and page cache. Counter-intuitively, decreasing block cache size will not increase IO. The memory saved will likely be used for page cache, so even more data will be cached. However, CPU usage might grow because RocksDB needs to decompress pages it reads from page cache.</li>
</ul>
<h5 id="indexes-and-filter-blocks">Indexes and filter blocks</h5>
<ul>
<li><strong>Indexes and filter blocks</strong> can be big memory users and by default they don't count in memory you allocate for block cache. This can sometimes cause confusion for users: you allocate 10GB for block cache, but RocksDB is using 15GB of memory. The difference is usually explained by index and bloom filter blocks.</li>
<li>If you set <code>cache_index_and_filter_blocks</code> to <code>true</code>, index and filter blocks will be stored in block cache, together with all other data blocks.</li>
</ul>
<h5 id="blocks-pinned-by-iterators">Blocks pinned by iterators</h5>
<ul>
<li>Blocks pinned by iterators usually don't contribute much to the overall memory usage. However, in some cases, when you have 100k read transactions happening simultaneously, it might put a strain on memory. Memory usage for pinned blocks is easy to calculate. Each iterator pins exactly one data block for each L0 file plus one data block for each L1+ level.</li>
</ul>
<h5 id="sst-file-index">SST File Index</h5>
<ul>
<li><a href="https://github.com/facebook/rocksdb/wiki/Indexing-SST-Files-for-Better-Lookup-Performance">Indexing SST Files for Better Lookup Performance</a></li>
</ul>
<h5 id="wal">WAL</h5>
<ul>
<li><strong>Write Ahead Log</strong>: Every update to RocksDB is written to two places: 1) an in-memory data structure called memtable (to be flushed to SST files later) and 2) write ahead log(WAL) on disk. In the event of a failure, write ahead logs can be used to completely recover the data in the memtable, which is necessary to restore the database to the original state. In the default configuration, RocksDB guarantees process crash consistency by <strong>flushing the WAL after every user write</strong>.</li>
<li>A WAL is created when 1) a new DB is opened, 2) a column family is flushed. A WAL is deleted (or archived if archival is enabled) when all column families have flushed beyond the largest sequence number contained in the WAL, or in other words, all data in the WAL have been persisted to SST files. Archived WALs will be moved to a separate location and purged from disk later on. The actual deletion might be delayed due to replication purposes</li>
<li><strong>Write ahead log (WAL)</strong> serializes memtable operations to persistent medium as log files. In the event of a failure, WAL files can be used to recover the database to its consistent state, by reconstructing the memtable from the logs. When a memtable is flushed out to persistent medium safely, the corresponding WAL log(s) become obsolete and are archived. Eventually the archived logs are purged from disk after a certain period of time. https://github.com/facebook/rocksdb/wiki/Write-Ahead-Log</li>
<li><strong>Log File Format</strong>：Log file consists of a sequence of variable length records. Records are grouped by <code>kBlockSize</code>(32k). If a certain record cannot fit into the leftover space, then the leftover space is padded with empty (null) data. The writer writes and the reader reads in chunks of <code>kBlockSize</code>. https://github.com/facebook/rocksdb/wiki/Write-Ahead-Log-File-Format</li>
</ul>
<pre><code>       +-----+-------------+--+----+----------+------+-- ... ----+
 File  | r0  |        r1   |P | r2 |    r3    |  r4  |           |
       +-----+-------------+--+----+----------+------+-- ... ----+
       &lt;--- kBlockSize ------&gt;|&lt;-- kBlockSize ------&gt;|

  rn = variable size records
  P = Padding
</code></pre>
<ul>
<li><strong>Record Format</strong>：The record layout format is as shown below. There are two kinds of record format, Legacy and Recyclable:
<ul>
<li><strong>The Legacy Record Format</strong>：</li>
</ul>
</li>
</ul>
<pre><code>+---------+-----------+-----------+--- ... ---+
|CRC (4B) | Size (2B) | Type (1B) | Payload   |
+---------+-----------+-----------+--- ... ---+

CRC = 32bit hash computed over the payload using CRC
Size = Length of the payload data
Type = Type of record
       (kZeroType, kFullType, kFirstType, kLastType, kMiddleType )
       The type is used to group a bunch of records together to represent
       blocks that are larger than kBlockSize
Payload = Byte stream as long as specified by the payload size
</code></pre>
<ul>
<li><strong>The Recyclable Record Format</strong></li>
</ul>
<pre><code>+---------+-----------+-----------+----------------+--- ... ---+
|CRC (4B) | Size (2B) | Type (1B) | Log number (4B)| Payload   |
+---------+-----------+-----------+----------------+--- ... ---+
Same as above, with the addition of
Log number = 32bit log file number, so that we can distinguish between
records written by the most recent log writer vs a previous one.
</code></pre>
<ul>
<li>
<p><strong>WAL Perfoemance # Write Amplification</strong>: Note that for some use cases, synchronous WAL can introduce non-trivial write amplification. When writes are small, because complete block/page might need to be updated, we may end up with two 4KB writes (one for data and one for metadata) even if the write is very small. If write is only 40 bytes, 8KB is updated, the write amplification is 8 KB/40 bytes ~= 200. It can easily be even larger than the write amplification by LSM-tree.</p>
</li>
<li>
<p><strong>SST</strong>: Sorted String Table.</p>
<ul>
<li><strong>BlockBasedTable</strong> is the default SST table format in RocksDB. https://github.com/facebook/rocksdb/wiki/Rocksdb-BlockBasedTable-Format</li>
</ul>
<pre><code>  &lt;beginning_of_file&gt;
  [data block 1]
  [data block 2]
  ...
  [data block N]
  [meta block 1: filter block]                  (see section: &quot;filter&quot; Meta Block)
  [meta block 2: index block]
  [meta block 3: compression dictionary block]  (see section: &quot;compression dictionary&quot; Meta Block)
  [meta block 4: range deletion block]          (see section: &quot;range deletion&quot; Meta Block)
  [meta block 5: stats block]                   (see section: &quot;properties&quot; Meta Block)
  ...
  [meta block K: future extended block]  (we may add more meta blocks in the future)
  [metaindex block]
  [Footer]                               (fixed size; starts at file_size - sizeof(Footer))
  &lt;end_of_file&gt;
</code></pre>
<ul>
<li><strong>PlainTable Format</strong>: PlainTable is a RocksDB's SST file format optimized for low query latency on pure-memory or really low-latency media. https://github.com/facebook/rocksdb/wiki/PlainTable-Format</li>
<li><strong>CuckooTable Format</strong>: We introduce a new SST file format based on Cuckoo Hashing which is optimized for very high point lookup rates. Applications which don't use range scan but require very fast point lookups can use this new table format. https://github.com/facebook/rocksdb/wiki/CuckooTable-Format</li>
<li><strong>Index Block Format</strong>: An index block contains one entry per data block, where the key is a string &gt;= last key in that data block and before the first key in the successive data block. The value is the BlockHandle (file offset and length) for the data block. https://github.com/facebook/rocksdb/wiki/Index-Block-Format</li>
<li><strong>Bloom Filter</strong>: In RocksDB, when the filter policy is set, every newly created SST file will contain a Bloom filter, which is used to determine if the file may contain the key we're looking for. The filter is essentially a bit array. Multiple hash functions are applied to the given key, each specifying a bit in the array that will be set to 1. At read time also the same hash functions are applied on the search key, the bits are checked, i.e., probe, and the key definitely does not exist if at least one of the probes return 0. https://github.com/facebook/rocksdb/wiki/RocksDB-Bloom-Filter</li>
<li><strong>Data Block Hash Index</strong>: RocksDB does a binary search when performing point lookup the keys in data blocks. However, in order to find the right location where the key may reside, multiple key parsing and comparison are needed. Each binary search branching triggers CPU cache miss, causing much CPU utilization. We have seen that this binary search takes up considerable CPU in production use-cases. A hash index is designed and implemented in RocksDB data blocks to improve the CPU efficiency of point lookup. Benchmarks with db_bench show the CPU utilization of one of the main functions in the point lookup code path, DataBlockIter::Seek(), is reduced by 21.8%, and the overall RocksDB throughput is increased by 10% under purely cached workloads, at an overhead of 4.6% more space. https://github.com/facebook/rocksdb/wiki/Data-Block-Hash-Index</li>
</ul>
</li>
<li>
<p><strong>MANIFEST</strong>: MANIFEST refers to the system that keeps track of RocksDB state changes in a transactional log. RocksDB has a built-in mechanism to overcome these limitations of POSIX file system by keeping a transactional log of RocksDB state changes using Version Edit Records in the Manifest log files. MANIFEST is used to restore RocksDB to the latest known consistent state on a restart. https://github.com/facebook/rocksdb/wiki/MANIFEST</p>
</li>
</ul>
<h4 id="main-operations">Main Operations</h4>
<ul>
<li>Get</li>
<li>Put</li>
<li>Delete</li>
<li>NewIterator</li>
</ul>
<h4 id="readwrite-processes">Read/Write Processes</h4>
<h5 id="read">Read</h5>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210102164947.png" alt="20210102164947" loading="lazy"></figure>
<ul>
<li>Mutable Memtable -&gt; Immutable Memtable -&gt; All SSTable files in L0 -&gt; Some SSTable files in Ln.</li>
<li>For memtables and SSTables files, look up bloom filter firstly to determine if the file may contain the key. If contains, search this file and look up.</li>
<li>For file internal search operation
<ul>
<li>Memtable: Use Skiplist to find the value.</li>
<li>SSTable files: Use Hash Index and Binary Search Index to find the data block. Load the data block to memory and search the value.</li>
</ul>
</li>
<li>For SSTable files search, use SST File Index to determine which files contains the given key and only search these files.</li>
</ul>
<pre><code>
                                         file 1                                          file 2
                                      +----------+                                    +----------+
level 1:                              | 100, 200 |                                    | 300, 400 |
                                      +----------+                                    +----------+
           file 1     file 2      file 3      file 4       file 5       file 6       file 7       file 8
         +--------+ +--------+ +---------+ +----------+ +----------+ +----------+ +----------+ +----------+
level 2: | 40, 50 | | 60, 70 | | 95, 110 | | 150, 160 | | 210, 230 | | 290, 300 | | 310, 320 | | 410, 450 |
         +--------+ +--------+ +---------+ +----------+ +----------+ +----------+ +----------+ +----------+

</code></pre>
<h5 id="write">Write</h5>
<ul>
<li>WAL -&gt; Mutable Memtable -&gt; Immutable Memtable -&gt; SSTable in L0 (unordered in different SST file but ordered in the file) -&gt; SSTable in Ln</li>
</ul>
<h3 id="core-concepts">Core Concepts</h3>
<h4 id="compaction">Compaction</h4>
<ul>
<li>https://github.com/facebook/rocksdb/wiki/Compaction</li>
<li><a href="https://smalldatum.blogspot.com/2018/08/name-that-compaction-algorithm.html">Name that compaction algorithm</a></li>
<li>Here we present a taxonomy of compaction algorithms: Classic Leveled, Tiered, Tiered+Leveled, Leveled-N, FIFO. Out of them, Rocksdb implements Tiered+Leveled, termed Level Compaction in the code, Tiered termed Universal in the code, and FIFO.</li>
<li><strong>Some concepts you must learn</strong>:
<ul>
<li>read/write/space amplification
<ul>
<li>read amplification</li>
<li>write amplification</li>
<li>space amplification</li>
</ul>
</li>
<li>Run: The on-disk data is organized into sorted runs of data. Each run contains data <strong>sorted</strong> by the index key. A run can be represented on disk as a single file, or alternatively as a collection of files with <strong>non-overlapping key ranges</strong>.</li>
</ul>
</li>
</ul>
<h5 id="leveled">Leveled</h5>
<ul>
<li><strong>Leveled compaction minimizes space amplification at the cost of read and write amplification.</strong>
<ul>
<li>https://rocksdb.org.cn/doc/Leveled-Compaction.html</li>
<li>https://github.com/facebook/rocksdb/wiki/Leveled-Compaction</li>
<li>https://www.scylladb.com/2018/01/31/compaction-series-leveled-compaction/</li>
<li>While write amplification is usually worse with leveled than with tiered, there are a few cases where leveled is competitive. The first is key-order inserts and a RocksDB optimization greatly reduces write-amp in that case. The second one is skewed writes where only a small fraction of the keys are likely to be updated. With the right value for compaction priority in RocksDB compaction should stop at the smallest level that is large enough to capture the write working set -- it won't go all the way to the max level. When leveled compaction is some-to-some then compaction is only done for the slices of the LSM tree that overlap the written keys, which can generate less write amplification than all-to-all compaction.<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210103155949.png" alt="20210103155949" loading="lazy"></li>
<li>When the amount of files in L0 exceeds <code>level0_file_num_compaction_trigger</code>, compactions will be triggered and must choose <strong>all files in L0</strong> because of unordered data for different files.<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210103160027.png" alt="20210103160027" loading="lazy"></li>
<li>After merging to L1, the size of L1 may exceed the target size and need to execute new compactions. For L1, choose at least 1 file and merge with overlapped key range files in L2.<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210103160042.png" alt="20210103160042" loading="lazy"></li>
<li>If necessary, multiple compaction operations can be executed concurrently with the control of param <code>max_background_compactions</code>.<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210103160142.png" alt="20210103160142" loading="lazy"></li>
<li>However for L0-&gt;L1 compaction operation, it can not be executed concurrently. And it may become bottlenech for compaction speed, <code>max_subcompactions</code> can be used to partion the data in L0 and execute compactions with multi threads.<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210103161012.png" alt="20210103161012" loading="lazy"></li>
</ul>
</li>
<li><strong>The job of Leveled compaction strategy is to maintain this structure while keeping L0 empty</strong>
<ul>
<li>When we have enough (e.g., 4) sstables in L0, we compact them into L1 by <strong>compacting all the sstables in L0 together with all the sstables in L1</strong>.</li>
<li>The new run in L1 may have more than the desired 10 sstables. If that happens, we pick one sstable from L1 and compact it into L2</li>
<li>After we compacted a table from L1 into L2, now L2 may have more than the desired number of sstables, so we compact sstables from L2 into L3. Again, this involves compacting one sstable from L2 and about 10 sstables from L3<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20210108104335.png" alt="20210108104335" loading="lazy"></li>
</ul>
</li>
</ul>
<h5 id="leveled-n">Leveled-N</h5>
<ul>
<li><strong>Leveled-N compaction is like leveled compaction but with less write and more read amplification.</strong> It allows <strong>more than one sorted run per level</strong>. Compaction merges all sorted runs from Ln-1 into one sorted run from Ln, which is leveled. And then &quot;-N&quot; is added to the name to indicate there can be n sorted runs per level. The Dostoevsky paper defined a compaction algorithm named Fluid LSM in which the max level has 1 sorted run but the non-max levels can have more than 1 sorted run. Leveled compaction is done into the max level.</li>
</ul>
<h5 id="tiered">Tiered</h5>
<ul>
<li><strong>Tiered compaction minimizes write amplification at the cost of read and space amplification.</strong></li>
</ul>
<h2 id="write-amplification-in-rocksdb">Write Amplification in RocksDB</h2>
<h1 id="solutions">Solutions</h1>
<h2 id="industry">Industry</h2>
<h3 id="case-one-pingcap-titan">CASE ONE: PingCAP - Titan</h3>
<h3 id="case-two-toshiba-toshibamemory">CASE TWO: Toshiba - ToshibaMemory</h3>
<h3 id="case-three-bytedance">CASE THREE: ByteDance</h3>
<h2 id="academia">Academia</h2>
<h2 id="references-2">References</h2>
<ul>
<li><a href="https://en.pingcap.com/blog/titan-storage-engine-design-and-implementation">[1] PingCAP - Titan</a></li>
<li><a href="https://www.snia.org/sites/default/files/SDC/2019/presentations/NVMe/Brasga_Remington_Enhancing_RocksDB_for_SSD_Endurance_and_Performance.pdf">[2] ToshibaMemory - Toshiba</a></li>
<li><a href="https://www.infoq.cn/article/u3leu3emgjjwflqltjhs">[3] InfoQ - ByteDance Practice</a></li>
<li><a href="https://xie.infoq.cn/article/279e0ad88fe7b0e293adce7fb">[4] InfoQ - TiDB 原理解析</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/141186118">[5] 知乎 - 叶提：深入探讨LSM Compaction机制</a></li>
<li><a href="https://www.jianshu.com/p/e89cd503c9ae">[6] 简书 - LittleMagic：LSM Tree-Based存储引擎的compaction策略（feat. RocksDB）</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/112574579">[7] 知乎 - 张睿：LSM Tree的Leveling 和 Tiering Compaction</a></li>
<li><a href="https://scholar.harvard.edu/files/stratos/files/dostoevskykv.pdf">[8] Dostoevsky: Better Space-Time Trade-Offs for LSM-Tree Based Key-Value Stores via Adaptive Removal of Superfluous Merging</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees]]></title>
        <id>https://blog.shunzi.tech/post/osdi-Bourbon/</id>
        <link href="https://blog.shunzi.tech/post/osdi-Bourbon/">
        </link>
        <updated>2020-11-06T08:37:41.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>该篇文章来自于 OSDI2020 From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees</li>
<li>很久没看 LSM tree 的文章了，恰好这几天 OSDI2020 开了，果不其然还是有 LSM-tree 相关的，而且是和学习索引结合的，之前对  Learned Index 也是一知半解，所以拜读了一下。</li>
<li>这篇文章从写作和行文的角度讲写的特别的清楚，实验做的可能是我见过的最充分的，从一开始发现问题就开始用了大量实验来证明，后续的负载测试也极其丰富，回答了读者可能会有的各种各样的问题。值得一读。</li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>该篇文章来自于 OSDI2020 From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees</li>
<li>很久没看 LSM tree 的文章了，恰好这几天 OSDI2020 开了，果不其然还是有 LSM-tree 相关的，而且是和学习索引结合的，之前对  Learned Index 也是一知半解，所以拜读了一下。</li>
<li>这篇文章从写作和行文的角度讲写的特别的清楚，实验做的可能是我见过的最充分的，从一开始发现问题就开始用了大量实验来证明，后续的负载测试也极其丰富，回答了读者可能会有的各种各样的问题。值得一读。</li>
</ul>
</blockquote>
<!--more-->
<h2 id="abstract">Abstract</h2>
<ul>
<li>Bourbon，一个利用了机器学习来提供快速查询的 LSM-tree</li>
<li>Bourbon 使用贪婪的分段线性回归来学习 key 分布，以最小的计算代价实现快速查找，并根据成本和收益来决定何时学习是值得的。实验表明，查询性能相比于最先进的 LSMs 提升了 1.23x-1.78x</li>
</ul>
<h2 id="introduction">Introduction</h2>
<h4 id="学习索引是个啥">学习索引是个啥？</h4>
<ul>
<li>作者上来先简要介绍了一波机器学习，当然是为了引出重点 <strong>学习索引</strong>，简单地讲，学习索引就是指当你查询一个 key 的时候，系统使用该索引（或者该函数）预测出你要查询的 key 所对应的位置，相比于传统的数据结构中的查找性能有比较大的提升，某些场景下可能提升可能更为明显，同时一定程度上因为不直接构建具体的数据结构节省了空间开销。基于这项工作，很多人提出了更好的模型、更好的树结构来减少对基于树的索引结构的访问和开销。</li>
</ul>
<h4 id="学习索引和-lsms-能擦出啥火花">学习索引和 LSMs 能擦出啥火花？</h4>
<h5 id="两者理论上的矛盾">两者理论上的矛盾</h5>
<ul>
<li>现有的学习索引大多是基于数据库场景中的 B 树来做的，很少有人提出说将学习索引应用到 LSM-tree 上，所以作者就尝试着把学习索引的想法应用到 LSM-tree 上（LSM-tree 的应用就不再具体介绍）。那么问题来了，为什么其他人没想到说把学习索引用到 LSM-Tree 上呢？<strong>主要是因为学习索引主要针对只读设置而量身定做的，而 LSMs 则主要是针对写进行了优化。</strong></li>
<li>听着很抽象？那先简单解释一下。LSM tree 是对写比较友好的，但是写操作会影响学习索引，因为学习索引通常是基于原有的数据学习出来的，现在数据都变了，那你索引肯定得需要做出相应的改变才能保证你索引的准确性，最直接的办法当然是直接再学习。</li>
<li><strong>然而，作者发现 LSMs 非常适合用于学习索引</strong>，虽然写操作修改了 LSM，但树的大多数部分是不可变的；因此，学习一个预测键/值位置的函数只需要完成一次，并且只要不可变数据存在就可以使用它。然而也有别的问题，可变的键或值大小使学习预测位置的函数变得更加困难，过早地执行模型构建可能导致大量的资源浪费。</li>
</ul>
<h5 id="bourbon-做了啥">Bourbon 做了啥</h5>
<ul>
<li>作者研究了 WiscKey，得出了几条 guidelines
<ul>
<li>虽然学习 LSM 中稳定的低级别是有用的，但是学习更高级别也会带来好处，因为查找必须始终先搜索更高级别</li>
<li>并不是所有的文件都是相同的：一些文件即使在较低的级别也是非常短暂的：系统必须避免学习这些文件，否则会浪费资源</li>
<li>工作负载和数据感知非常重要：根据工作负载和数据加载方式，了解树的某些部分可能比了解其他部分更有益</li>
</ul>
</li>
<li>Bourbon 基于 WiscKey 实现，WiscKey 原本大约 20K 行代码，Bourbon 增加了大约 5K 行，使用分段线性回归，这是一种简单但有效的模型，能够在很小的空间开销下实现快速训练(即学习)和推理(即查找)，使用文件学习:模型建立在文件之上，假设一个LSM文件一旦创建，就不会被修改。实现了一个成本效益分析器，它动态地决定是否学习一个文件，在最大化收益的同时减少了不必要的学习。</li>
</ul>
<h2 id="background">Background</h2>
<h3 id="lsm-leveldb">LSM &amp; LevelDB</h3>
<ul>
<li>如下图所示是 LevelDB 和 WiscKey 的原理示意图。具体的介绍请参考其他资料，此处不再详细展开。本文中提到的 higher level 是指存放了更新的数据的 level，lower level 是指存放了更老的数据的 level。</li>
<li>简要介绍查询步骤，如图所示，便于后文引入学习索引：
<ul>
<li>step1. FindFiles：如果 key 在内存中的 tables 中没有找到，LevelDB 将会查找到一组候选的来自磁盘的可能包含键 k 的 sstables。最坏的情况是 k 可能出现在所有 L0 文件中(因为重叠的范围)，并在每个连续级别的一个文件中</li>
<li>step2. LoadIB+FB：对于每一个候选的 SSTable，其索引块和布隆过滤器块首先被加载</li>
<li>step3. SearchIB：对索引块进行二分查找，从而找到可能包含 k 的数据块</li>
<li>step4. SearchFB：查询过滤器判断 k 是否存在对应的 datablock 中</li>
<li>step5. ReadValue：如果 k 在对应的 datablock 中，相应地读取出对应的 value，然后查询结束。如果上一步的 filter 显示该 key 不存在或者对 datablock 查询时没有找到相应的 key，搜索操作将继续在下一个候选文件中执行</li>
<li>NOTICE：blocks 不一定总是从磁盘中加载出来的，index block 和 filter block，以及经常访问的 data blocks 很有可能就在内存中可以被直接访问（文件系统缓存）。</li>
</ul>
</li>
<li>作者对于索引的步骤和数据访问的步骤做了简单区分。 本文目标即为减少索引过程中的开销。
<ul>
<li>FindFiles, SearchIB, SearchFB, and SearchDB 都是通过文件和 blocks 找到对应的键，也就是所谓的 indexing steps</li>
<li>LoadIB+FB, LoadDB, and ReadValue 从存储中读取数据就是所谓的 data-access steps<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201106165224.png" alt="20201106165224" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="wisckey">WiscKey</h3>
<ul>
<li>WiscKey 是为了解决 LSM-Tree 中比较严峻的写放大问题而提出的，架构如上图所示，主要是讲 Key Value 分离，只是对 Key 使用 LSM 存储，Value 直接使用 Value Log 进行存储，因为数据量小了，写放大也就得到了缓解，同时因为比较小就可以缓存在内存中，因此一个查询操作可能最终只涉及到一次 IO 操作来读取 Value Log 上指定位置的 Value</li>
</ul>
<h3 id="optimizing-lookups-in-lsms">Optimizing Lookups in LSMs</h3>
<ul>
<li>因为 LSM Tree 本身结构的原因，对于 LSM Tree 的查询可能需要对多个 level 进行查询，而且 LSM Tree 本能就是以写性能见长的，在读性能方面表现较差，所以对 LSM Tree 的读操作进行优化就很有必要。</li>
<li>受学习索引的启发，现在有很多工作考虑使用机器学习模型来替代传统的索引结构，核心思想是针对输入训练一个模型（使用如线性回归或者神经网络的方法）从而预测出输入对应的记录子啊排序好了的数据集中的具体地址。模型可能有误差，因此预测有一个相关的误差界。在查找过程中，如果模型预测的键的位置是正确的，则返回记录;如果错误，则在错误范围内执行本地搜索。例如，如果预测的位置是 pos，而最小和最大的误差范围是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>m</mi></msub><mi>i</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">α_min</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>m</mi></msub><mi>a</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">α_max</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span></span></span></span>，那么根据错误的预测，在 pos - <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>m</mi></msub><mi>m</mi><mi>i</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">α_mmin</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span></span></span></span> 和 pos + <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>m</mi></msub><mi>a</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">α_max</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span></span></span></span> 之间进行局部搜索。</li>
<li>学习的索引可以大大加快查找速度。直观地说，一个学习过的索引将 b 树的 O(log-n) 查找变成 O(1) 操作。根据实际的经验表明，学习索引提升 B 树的查询性能约 1.5x-3x</li>
<li>传统的学习索引不支持更新，因为在现有数据上学习的模型会随着修改而改变。但是，LSMs 在写密集型工作负载中的高性能很有吸引力，因为它们只按顺序执行写操作。因此提出了关键问题给：如何实现学习索引同时保证 LSM 对写性能带来的提升？</li>
</ul>
<h2 id="learned-indexes-a-good-match-for-lsms">Learned Indexes: a Good Match for LSMs?</h2>
<h3 id="learned-indexes-beneficial-regimes">Learned Indexes: Beneficial Regimes</h3>
<ul>
<li>LSM-Trees 中的查询操作包含索引和数据访问两个方面的操作，如前面章节所述。优化后的索引如学习索引可以减少索引的一些步骤的开销，但是对于数据访问的开销没什么影响。在 WiscKey 中，学习索引可以减少如 FindFiles, SearchIB, and SearchDB 的开销。因此如果索引在总查找延迟中占相当大的比例，学习索引就可以显著提升查询的性能。</li>
<li>首先，当数据集或它的一部分缓存在内存中时，数据访问成本很低，因此索引成本就变得很重要。下图展示了在 WiscKey 中的延迟分解情况。柱状图的第一条显示了全部缓存在内存中的情况，第二条显示了数据存储在 SATA SSD 上的情况。其实第一条就相当于有缓存的情况，数据访问和索引成本对延迟的贡献几乎是相等的，优化索引部分可以将查找延迟降低约 2 倍，当不缓存数据集时，数据访问成本占主导地位，因此优化索引可能产生较小的好处，大约只有 20%。</li>
<li>然而，学习索引并不局限于数据缓存在内存中的场景。它们为当前流行的快速存储设备提供了优势，并且可以在正在出现的更快的设备上发挥更大的作用，如图所示随着设备的升级，即便延迟大大降低，但是索引结构的操作所占的延迟比重越来越大，如在 Optane SSD 中，索引结构的操作占据了大约 44% 的比例，因此优化索引结构的相关操作可以将性能提升约 1.8x。<strong>随着存储器件的发展，学习索引能够发挥的效果也越来越显著</strong>。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201106175207.png" alt="20201106175207" loading="lazy"></li>
</ul>
<h3 id="learned-indexes-with-writes">Learned Indexes with Writes</h3>
<ul>
<li>与传统索引相比，学习索引为只读分析工作负载提供了更高的查找性能。：然而，学习索引的一个主要缺点是它们不支持诸如插入和更新之类的修改，因为修改操作改变了数据的分布，所以模型就必须重新学习，对于写密集型的负载就常常需要重建模型，频繁的重建就会导致比较高的开销。</li>
<li>乍一看，学习索引似乎并不适合那些 LSMs 优化的写密集的负载，然而，我们观察到 LSMs 的设计很适合学习索引。我们的关键认识是，<strong>尽管更新可以改变 LSM 树的一部分，但大部分仍然是不变的</strong>。具体来说，新修改的项缓冲在内存结构中，或者存在于树的较高级别中，而稳定的数据驻留在较低级别。考虑到数据集的很大一部分位于稳定的、较低的级别，对这一部分的查找可以更快，而无需或只需进行少量的重新学习。相比之下，在更高层次的学习可能没有那么有效果，它们变化的速度更快，因此必须经常重新学习。</li>
<li>我们还认识到，<strong>SStable 文件的不可变特性使它们成为理想的学习单元</strong>。一旦学习之后，这些文件就再也不会被更新，因此一个模型可以一直被使用，除非该文件被替换。除此以外，SSTable 内的数据还是有序的，有序的数据就可以采用更简单的模型学习，一个级别是许多不可变文件的集合，也可以使用简单的模型作为一个整体来学习。一个级别中的数据也进行了排序：对各个sstable进行了排序，并且在sstable之间不存在重叠的键范围。</li>
<li>进行了一些实验来证明上述结论，实验的目标是确定一个模型在多长时间内是有用的，以及模型使用的频率。只要SSTable 文件存在，为该文件建立的模型就有用，因此，我们首先测量和分析 SSTable 的寿命。一个模型被使用的额频率将由内部查询的次数决定，因此只需要测试每个文件的内部查询次数即可，因为模型也可以基于整个 level 构建，所以作者也测试了 level 的 lifetimes，实验是基于 WiscKey 做的，但作者认为对应的实验结论也应该适用于大多数 LSM 的实现。</li>
</ul>
<h4 id="sstable-lifetimes">SSTable Lifetimes</h4>
<ul>
<li>下图 a 显示了不同层级的 SSTables 文件的平均寿命（寿命通过使用文件的创建时间和删除时间来衡量）。
<ul>
<li>较低级别的 SSTable 文件的平均寿命大于较高级别的。</li>
<li>在较低的写比例的负载下，即使是较高级别的文件也有相当长的生存期，但较低级别的寿命此时更长</li>
<li>即便随着更高的写比例导致文件的寿命下降，但是对于低级别的文件而言，寿命还是很长</li>
</ul>
</li>
<li>图 b 展示了 5% 的写比例的情况下 L1 和 L4 的寿命的分布情况， 可以发现有的文件寿命非常短，有的文件寿命非常长。如 L1 的大约 50% 的寿命只有 2.5s，如果过了该临界值，寿命就会变得特别长，超过五分钟。而对于 L4，只有很少的文件寿命很短，大约有 2% 的寿命不超过 1s，造成该现象的原因可能是：
<ul>
<li>压缩一个 Li 层的文件会在 Li+1 中创建一个新文件，该文件会被立即选择用于压缩到下一个级别</li>
<li>压缩一个 Li 层的文件会在 Li+1 中创建一个新文件，该文件与从 Li 压缩的下一个文件有重叠的键范围</li>
</ul>
</li>
<li>图 c 展示了不同写请求比例下 L1 和 L4 的寿命分布，规律和 5% 时大体相同。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107111926.png" alt="20201107111926" loading="lazy"></li>
<li>于是乎总结出了两条 guidelines：
<ul>
<li>Favor learning files at lower levels：学习索引最好用于较低层次的文件，因为这些文件的寿命通常比较长</li>
<li>Wait before learning a file：学习索引最好在某个文件存活的时间达到一定阈值之后才开始学习，因为有的文件寿命可能很短，即便是在一些较低层次的文件，因为存活持续了一段时间之后该文件才可能存活的比较长时间。</li>
</ul>
</li>
</ul>
<h4 id="number-of-internal-lookups-per-file">Number of Internal Lookups Per File</h4>
<ul>
<li>为了测试模型的使用频率，就分析了 SSTables 对应的内部查询次数。如下图所示，图 a 显示了数据集以一个随机顺序加载的情况，较高层次对应的总的内部查询次数更多，即便是很大一部分数据驻留在较低的级别上（图 (a)(ii) 则显示了查询不命中的情况），而如图(a)(iii)所示的查询命中的情况时候，低级别的文件的查询次数更多。结果表明更高级别的文件通常服务于一些不命中也就是 negative 的查询操作，虽然采用了 BloomFilter 来尽可能加速 negative lookup 的过程，但是 index block 在查询 filter block 之前还是会被查询。</li>
<li>同时还针对 zipfian 的负载（大多数请求都是针对一小组键的）下进行了同样的测试，结果表明大多数情况下都和随机加载的负载是相似的，除了 positive lookup，如图 (a)(iv)，在 zipfian 负载下，更高层级的文件处理更多的 positive lookups，因为负载经常访问一小组常被更新的键，因此这组键被常常存储在更高的 level 上。</li>
<li>图 b 显示了数据集被顺序加载（keys 按照升序或者降序的方式被插入）的情况，相比于随机加载的情况，就没有了 negative lookups，因为不同 SSTable 的键不会重叠，即便是在不同的 level 上也不会重叠，FindFiles 步骤可以直接找到可能包含该 key 的唯一的文件。因此，较低的级别提供更多的查找，并可以从学习索引中获得更多好处。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107113529.png" alt="20201107113529" loading="lazy"></li>
<li>从上述的实验观察中也得到了两个 guidelines：
<ul>
<li>Do not neglect files at higher levels：即便更底层次的文件寿命更长，处理的查询也更多，但是更高层次的文件在某些负载下也是可能处理很多 negative 甚至 positive 的查询请求的，因此学习索引在高层次的文件中也能让内部查询更快</li>
<li>Be workload- and data-aware：尽管大多数数据位于较低的级别，但如果工作负载不查找这些数据，那么学习这些级别带来的收益就很悠闲；因此，学习索引必须能够感知工作负载的情况。除此以外，数据被加载的顺序性也会影响那些层处理更多的内部查询请求，即会影响请求处理的层级分布情况，因此学习索引还需要感知数据的情况。内部查询请求次数可以同时代表工作负载和数据加载顺序，所以基于请求次数就可以动态地决定是否要学习某个文件。</li>
</ul>
</li>
</ul>
<h4 id="lifetime-of-levels">Lifetime of Levels</h4>
<ul>
<li>前面章节有描述过一整个层级也是可以被学习的，所以作者测试分析了整个层级的寿命。</li>
<li>因为 L0 层无序，L0 层的文件可能有重叠的键范围，所以不能应用层级学习的策略。一旦一个层级被学习了之后，任何对于该层级的更新都可能导致重学习，而层级更新则是指新的 SSTable 文件在该层次被创建，或者一个已经存在的被删除，因此，一个层级的的寿命与单个 SSTable 相同或更短。在层级的粒度上进行学习的好处是不需要在单独的步骤中找到候选 SSTables，而是在查询时候模型直接输出对应的 SSTable 和文件内的偏移。</li>
<li>下图 a 展示了在 5% 的写比例下不同层级的文件变化情况，纵轴上的 0 表示当前时间该层级没有发生变化，此时则可以进行学习。如果大于 0 则表示该层级发生了变化，因此就需要进行重新学习。更高层次对应的文件变化频率更高。随着级别的下降，更改的文件的比例会减少，因为较低的级别在许多文件中包含大量数据</li>
<li>对层级文件的更改通常是突发性的。该突发通常是由压缩引起的该层级中的很多文件同时被修改，因此这些突发的时机在不同层次表现的时间基本相同。这背后的原因是，对于我们使用的数据集，级别 L0 到 L3 已经满了，因此任何在一层上的压缩都会导致<strong>级联压缩</strong>，最终在未满的 L4 级别上存放。在这些突发情况之间层级的文件基本会保持平稳不会发生变化。</li>
<li>但是随着写请求比例的上升，突发间隔会逐渐减小，如图 b 所示，层级的平稳周期将大幅减小。如图所示 5% 时，大约有 5 分钟的周期，在 50% 的时候，就只有大约 25s 了。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107115847.png" alt="20201107115847" loading="lazy"></li>
<li>基于上述实验，又总结了一条 guidelines
<ul>
<li>Do not learn levels for write-heavy workloads：当写请求比例较低的时候，学习一整个层级还算比较合适，但是写密集型的负载，因为层级寿命变得很短就可能导致很频繁的重新学习。</li>
</ul>
</li>
</ul>
<h3 id="summary">Summary</h3>
<ul>
<li>通过对 WiscKey 的实验分析，总结了五条 guidelines:
<ul>
<li>Favor learning files at lower levels</li>
<li>Wait before learning a file</li>
<li>Do not neglect files at higher levels</li>
<li>Be workload- and data-aware</li>
<li>Do not learn levels for write-heavy workloads</li>
</ul>
</li>
</ul>
<h2 id="bourbon-design">Bourbon Design</h2>
<h3 id="learning-the-data">Learning the Data</h3>
<ul>
<li>回顾学习索引的目标：预测 key 在一个有序的数据集中的位置。</li>
<li>本文设计了两种学习索引，对应学习的粒度不同。
<ul>
<li>File Learning：预测 key 对应的在文件内的偏移</li>
<li>Level Learning：预测出对应的 SSTable 文件和文件内的偏移</li>
</ul>
</li>
<li>对于学习索引的要求：无论是学习过程还是查询过程，开销都需要很低才能真正优化整个系统。除此以外，因为优化的是磁盘上的数据结构对应的存储系统，空间的开销也需要尽可能的小。作者发现分段线性回归（PLR）能够同时满足上面的要求。PLR 的本质是用一些线段来表示有序的数据集，PLR 构造了一个有误差限制的模型，每个数据点 d 必须在范围 [<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{pos}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> − δ, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{pos}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> + δ] 内，其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{pos}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 数据集中的 d 预测的位置，δ 是提前定义好的误差限制。</li>
<li>为了训练 PLR 模型，Bourbon 方案使用了 Greedy-PLR 算法，一次处理一个数据点，如果数据点不能在不超出定义的误差限制的情况下被添加到当前的线段中，那么将创建一个新的线段，并将数据点添加到其中，最终 Greedy-PLR 生成了一组代表数据的线段。Greedy-PLR 的运行时间与数据点的数量呈线性关系。</li>
<li>一旦模型学习完成，推理就会很快。首先，找到包含键的正确线段(使用二分查找)。在该线段内，目标键的位置是通过将键与直线的斜率相乘并加上截距得到的。如果键不在预测的位置，在误差范围内进行局部查询。因此查询操作除了常数时间做局部搜索，只需要花费 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>s</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(logs)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">s</span><span class="mclose">)</span></span></span></span> 的时间，其中 s 是线段的数量。PLR 的空间开销很小：每个线段只有几十个字节。</li>
<li>其他模型诸如 RMI，PGMIndex，splines 等可能更适合 LSMs 且提供比 PLR 更好的表现，未来可以采用这些模型来进行实现。</li>
</ul>
<h3 id="supporting-variable-size-values">Supporting Variable-size Values</h3>
<ul>
<li>如果 KV 对大小相同的话，学习索引预测 KV 对的偏移量将会很容易，模型可以将 key 的预测位置乘以 KV 对的大小，从而产生最终的偏移量。但是对于许多系统而言，往往允许任意大小的 KV 对。</li>
<li>Bourbon 要求 Key 是固定大小的，但是 Value 可以是不固定的。作者认为这是一个合理的设计，因为大多数数据集有确定大小的 key，比如 user-id 通常有 16bytes，但是 value 的大小就不固定了。即使 keys 大小不同，可以填充使所有 keys 的大小相同。Bourbon 通过借鉴WiscKey的键值分离思想来支持可变长度的 value。</li>
<li>Key Value 分离的方式，Bourbon 中的 SSTables 就只会包含 key 和对应的指向 value 的指针，value 被单独维护在 value log 中，在这样的模式下，Bourbon 通过从模型中得到预测的位置，然后乘以对应的记录大小（通常是 keySize  + pointerSize），从而获取要访问的 KV 对的偏移量，Value 指针用作 Value Log 的偏移量，最终从该日志读取值。</li>
</ul>
<h3 id="level-vs-file-learning">Level vs. File Learning</h3>
<ul>
<li>前面的分析表明文件的寿命比层级的寿命通常更长，特别是在写密集的负载下，也就意味着以文件的粒度进行学习可能是更好的选择。作者为了在 file 和 level 之间进行权衡测试了不同负载下对应的性能，初始化的时候都加载一个数据集并构建模型，对于只读负载，模型不需要重新学习，在混合负载中，因为数据的改变模型需要重新学习。</li>
<li>如下表所示，混合负载下，Level 明显不如 File，因为有稳定的写入流，系统无法对 Level 进行学习。只有 1.5% 的内部查找采用模型路径；这些查找是在加载数据之后以及初始的 Level 模型可用时执行的。作者观察到所有尝试的 66 次 level 学习都失败了因为在学习完成之前 level 已经发生了改变。由于重新学习的额外成本，level 学习的性能甚至比 50% 写操作的基线还要差.而使用 file model，大比例的查询操作都能从学习索引中获益，因此 file model 相比于基线性能有所提升。</li>
<li>对于读敏感的负载（ 5% 的写），尽管 level model 相比于基线有一定的提升，但还是比 file model 性能表现要差，原因还是因为重新学习的额外成本和仅作用了有限的查询操作，带来的提升有限。</li>
<li>只有在只读负载下，Level 学习才能带来比较大的提升，甚至比起 file learning 都提升了 10%，因此，只有只读工作负载的部署可以从层级学习中获益。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107155836.png" alt="20201107155836" loading="lazy"></li>
<li>鉴于 Bourbon 的目标是在支持写操作的同时提供更快的查找，对于学习粒度来说，level 并不是一个合适的选择，所以 Bourbon 默认使用文件学习，但同时也会支持 level 学习以便适应只读负载。</li>
</ul>
<h3 id="cost-vs-benefit-analyzer">Cost vs. Benefit Analyzer</h3>
<ul>
<li>因为还是有部分文件的寿命较短，对这类文件的学习可能是对资源的浪费，所以需要开销和收益的分析机制来决定是否要对某一个文件进行学习。</li>
</ul>
<h4 id="wait-before-learning">Wait Before Learning</h4>
<ul>
<li>从前文的 Guidelines 中了解到，需要设定一个等待时间的阈值 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>w</mi><mi>a</mi><mi>i</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{wait}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，即在学习一个文件之前，需要等待相应的时间，该系数的具体值体现了开销和收益的权衡。值太小，导致一些寿命较短的文件也被学习，引入了较大的开销，值太大导致执行大量的查询的时候，因为模型还未学习构建，导致大量的查询不能通过学习索引来进行优化，导致性能下降。</li>
<li>BOURBON 将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>w</mi><mi>a</mi><mi>i</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{wait}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 设置为学习一个文件大概所需要的时间。测试发现学习一个文件（最大 4MB）的最长时间大约为 40ms，作者保守地将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>w</mi><mi>a</mi><mi>i</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{wait}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 设置为 50ms</li>
</ul>
<h4 id="to-learn-a-file-or-not">To Learn a File or Not</h4>
<ul>
<li>虽然现在有了 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>w</mi><mi>a</mi><mi>i</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{wait}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，但是一个文件即便是存活了很长时间但是可能也不是特别有益的。作者实验发现更低级别的文件通常寿命更长，对于有的工作负载和数据集，他们服务的查询操作比更高级别的文件要少得多，更高级别的文件尽管寿命较短，但是在有的场景下服务了大量的 negative lookups。因此除了考虑模型对应的开销以外，还需要考虑模型可能带来的收益。如果一个模型的收益（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>B</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">B_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）大于构建该模型的开销（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）那么该模型就是有利的。</li>
</ul>
<h5 id="estimating-c_model">Estimating <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></h5>
<ul>
<li>评估开销的一种方式是假设学习过程完全是在后台完成的且不会影响系统其他部分，那么开销就为 0，如果有很多空闲的 core，学习线程可以利用它们，这样就不会干扰前台任务（工作负载的处理或者压缩过程等）。但是 Bourbon 采用了一种比较保守的办法并且假设学习线程会干扰和减慢系统的其他部分，所以，Bourbon 假设开销等于为单个文件构建 PLR 模型的时间 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>b</mi><mi>u</mi><mi>i</mi><mi>l</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{build}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">b</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，我们发现，这个时间与文件中的数据点数量成线性比例，因此可以通过将训练一个数据点的平均时间和该文件中包含的点的数量相乘从而得到该时间。</li>
</ul>
<h5 id="estimating-b_model">Estimating <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>B</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">B_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></h5>
<ul>
<li>评估模型带来的收益相对比较复杂，直观地说，模型为内部查找提供的好处由 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mi>b</mi></msub><mi mathvariant="normal">−</mi><msub><mi>T</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">T_b−T_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">−</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 给出，其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">T_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">T_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 分别是基线和模型路径中查找的平均时间。如果一个文件在生命周期中服务了 N 个查询请求，那么该模型的净收益即为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><msub><mi>T</mi><mi>b</mi></msub><mi mathvariant="normal">−</mi><msub><mi>T</mi><mi>m</mi></msub><mo>)</mo><mo>∗</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">(T_b−T_m) * N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">−</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>。作者将查询操作又划分成了 negative 和 positive，因为大多数 negative 的查询操作在 filter 处就终止了，所以最终的收益模型为：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>B</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>=</mo><mo>(</mo><mo>(</mo><msub><mi>T</mi><mrow><mi>n</mi><mi mathvariant="normal">.</mi><mi>b</mi></mrow></msub><mi mathvariant="normal">−</mi><msub><mi>T</mi><mrow><mi>n</mi><mi mathvariant="normal">.</mi><mi>m</mi></mrow></msub><mo>)</mo><mi mathvariant="normal">∗</mi><msub><mi>N</mi><mi>n</mi></msub><mo>)</mo><mo>+</mo><mo>(</mo><mo>(</mo><msub><mi>T</mi><mrow><mi>p</mi><mi mathvariant="normal">.</mi><mi>b</mi></mrow></msub><mi mathvariant="normal">−</mi><msub><mi>T</mi><mrow><mi>p</mi><mi mathvariant="normal">.</mi><mi>m</mi></mrow></msub><mo>)</mo><mi mathvariant="normal">∗</mi><msub><mi>N</mi><mi>p</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">B_{model} = ((T_{n.b} −T_{n.m}) ∗N_n)+((T_{p.b} −T_{p.m}) ∗N_p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mord mtight">.</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">−</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mord mtight">.</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∗</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">(</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mtight">.</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">−</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mtight">.</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∗</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">N_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">N_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 则是 negative lookup 和 positive lookup 的数量，T 为对应分类下的时间。</li>
<li>如果不知道文件将执行的查找次数或查找将花费的时间，则无法计算文件的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>B</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">B_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。因此分析器为了预估这些指标，维护了这些文件在他们生命周期内的统计信息，为了估计文件 F 的这些指标，分析器使用与 F 处于同一级别的其他文件的统计数据，我们只在同一层次上考虑统计数据，因为这些统计数据在不同层次上差异很大。</li>
<li>Bourbon 在学习一个文件之前的等待时间里，查询操作可能在 baseline 的路劲中被服务处理，Bourbon 将把该过程的处理时间作为基线的查询处理时间 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>n</mi><mi mathvariant="normal">.</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{n.b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mord mtight">.</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>p</mi><mi mathvariant="normal">.</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{p.b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mtight">.</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>n</mi><mi mathvariant="normal">.</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{n.m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mord mtight">.</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mrow><mi>p</mi><mi mathvariant="normal">.</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{p.m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mtight">.</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 将使用同一层级的其他文件的平均模型查询时间来进行估计。对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">N_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">N_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，分析器首先获取该级别中其他文件的平均 negative 查找和 positive 查找，然后，将其按 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>=</mo><mi>s</mi><mi mathvariant="normal">/</mi><msub><mi>s</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">f = s/s_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mord">/</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的倍数进行缩放，其中 s 是文件的大小，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">s_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是该层级的文件的平均大小。在估计上述数量的时候，Bourbon 将会过滤掉寿命较短的文件。</li>
<li>当模型开始引导时，分析器可能还没有足够的统计信息，所以，初始化的时候，Bourbon 以 always-learn 的模式来运行，一旦足够的统计信息收集到了之后，分析器就可以开始执行开销和收益的权衡，来判断 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>B</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">B_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>C</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的大小关系来决定是否学习某一个文件。如果同时选中了多个文件进行学习，Bourbon 则把多个文件放在一个最大优先级队列中，按照 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>B</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>−</mo><msub><mi>C</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">B_{model} - C_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的顺序进行排序，因此优先级最高的文件对应的收益也就最大。</li>
</ul>
<h4 id="bourbon-putting-it-all-together">Bourbon: Putting it All Together</h4>
<ul>
<li>总体的流程如下图所示，主要分为两条路径：model exist 和 no model 对应的 baseline。baseline 和前文描述的 LevelDB 的检索方式基本相同，只是此处采用了 WiscKey 的方式来布局。</li>
<li>对于学习索引的查询方式，步骤如下：
<ul>
<li>step1. FindFiles：因为使用了文件学习，所以该步骤需要执行，即找到候选的 SSTables 文件</li>
<li>step2. LoadIB+FB：BOURBON 加载了 filter 和 index block，这些块可能已经被缓存在内存中了</li>
<li>step3. Model Lookup：FB： BOURBON 在候选的 SSTables 文件中对要查询的 Key 进行检索，模型相应地输出键 k 对应的文件内偏移 pos 和误差边界 δ。然后 BOURBON 计算包含记录 pos−δ 到 pos+δ 的数据块</li>
<li>step4. SearchFB：首先检查该数据块对应的 filter block 来判断 k 是否存在，如果存在，则 BOURBON 计算要加载的块对应的字节范围（因为 keys 和 pointers 大小固定，计算相对简单）</li>
<li>step5. LoadChunk：加载对应的字节范围</li>
<li>step6. LocateKey：键位于加载的块中，那么该 key 将位于预测的位置上（加载的 chunk 的中点）；如果不在，BOURBON 将会对该 chunk 执行二分查找</li>
<li>step7. ReadValue：使用相应的 Value Pointer 从 ValueLog 中读取对应的 Value<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107165512.png" alt="20201107165512" loading="lazy"></li>
</ul>
</li>
</ul>
<h5 id="possible-improvements">Possible improvements</h5>
<ul>
<li>BOURBON 少了一些 features，现有的实现中，不支持字符串 keys 以及 keys 的压缩
<ul>
<li>对于字符串键，我们计划探索的一种方法是将字符串视为base-64整数，并将它们转换为64位整数，然后可以采用本文描述的相同学习方法。虽然这种方法可以很好地用于小 keys，但是大 keys 可能需要更大的整数(大于64位)，因此高效的大整数数学可能是必不可少的。</li>
</ul>
</li>
<li>BOURBON 暂时不支持 level 和 file model 的切换，目前只是一个静态配置。</li>
</ul>
<h2 id="evaluation">Evaluation</h2>
<ul>
<li>测试之前抛出了几个关键问题：
<ul>
<li>BOURBON 究竟优化了查询的哪些部分？</li>
<li>BOURBON 在有模型但没有写的情况下表现如何？性能会随着数据集、加载顺序以及请求分布的变化发生什么样的变化？</li>
<li>BOURBON 范围查询表现如何？</li>
<li>在有写的情况下，BOURBON 的开销-收益分析器和其他从不重新学习的方法相比表现如何？</li>
<li>BOURBON 在真实负载下的性能也能表现得和预期一致吗？</li>
<li>数据存储在存储设备上时（不再在内存） BOURBON 是否有用？</li>
<li>有限的内存的情况下，BOURBON 是否有用？</li>
<li>BOURBON 在误差范围和空间开销上的权衡是怎么样的？</li>
</ul>
</li>
</ul>
<h3 id="测试环境">测试环境</h3>
<h4 id="硬件环境">硬件环境</h4>
<ul>
<li>20-core Intel Xeon CPU E5-2660</li>
<li>160-GB memory</li>
<li>a 480GB SATA SSD</li>
</ul>
<h4 id="系统参数">系统参数</h4>
<ul>
<li>16B integer keys and 64B values</li>
<li>error bound - 8</li>
<li>Unless specified, our workloads perform 10M operations.</li>
</ul>
<h4 id="负载">负载</h4>
<ul>
<li>构造了四个合成数据集，64M key-value pairs
<ul>
<li>linear, 键都是连续的</li>
<li>segmented-1%, 在连续的100个键之后有一个间隙</li>
<li>segmented-10% , 在10个连续的键之后会有一个间隙</li>
<li>normal，从标准正态分布 N(0,1) 中抽样 64M 个唯一值，并按比例缩放到整数</li>
</ul>
</li>
<li>真实负载：Amazon reviews (AR) &amp; New York OpenStreetMaps (OSM)</li>
</ul>
<h3 id="测试结果">测试结果</h3>
<ul>
<li>
<p><strong>BOURBON 究竟优化了查询的哪些部分？</strong></p>
<ul>
<li>减少了索引花费的时间。图中标记为 Search 的部分对应基线中的 SearchIB 和 SearchDB</li>
<li>还降低了数据访问成本，因为 BOURBON 加载的字节范围比基线加载的整个块要小。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107172404.png" alt="20201107172404" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>BOURBON 在有模型但没有写的情况下表现如何？性能会随着数据集、加载顺序以及请求分布的变化发生什么样的变化？</strong> 无论哪种情况 BOURBON 都可以提供显著的加速</p>
<ul>
<li>对于所有数据集， BOURBON 比 WiscKey 更快；根据数据集的不同，提升也不同(1.23倍到1.78倍)。
<ul>
<li>BOURBON 对线性数据集提升最大，因为它有最小的片段数(每个模型一个)；使用更少的段，找到目标需要检索的段也就更少。</li>
<li>延迟随着段数的增加而增加</li>
</ul>
</li>
<li>level learning 适用于只读负载，BOURBON-level 比基线快1.33 - 1.92倍，比 BOURBON 更好，因为 level 学习查找对应的 SSTables 更快。
<ul>
<li>由于 level 模型只对只读工作负载提供好处，并且与文件模型相比最多提高10%，所以后续测试主要针对 file learning。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107172755.png" alt="20201107172755" loading="lazy"></li>
</ul>
</li>
<li>负载加载顺序的差异，使用顺序加载，sstable 甚至在不同的级别上都不会有重叠的键范围;然而，在随机加载的情况下，某个级别的 sstable 可能会与其他级别的 sstable 重叠。
<ul>
<li>无论负载顺序如何，BOURBON 都比基线有显著的优势（1.47× – 1.61×）。</li>
<li>与顺序加载情况相比，随机加载情况下的平均查找延迟有所增加。这是因为，虽然在顺序情况下没有 negative 的内部查找（10M），但在随机情况下有很多 negative 的查找（23M）</li>
<li>在随机情况下，对基线的加速比顺序情况下要小。虽然 BOURBON 同时优化了 positive 查找和 negative 查找，但 negative 查找的收益较小，因为 negative 的查询路径比较短，在 filter 处可能就终止了，没有加载或搜索数据块，而且 negative 的查询比 positive 的查询多。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107173423.png" alt="20201107173423" loading="lazy"></li>
</ul>
</li>
<li>请求的分布情况，测试了六种请求分布下的延迟，sequential, zipfian, hotspot, exponential, uniform, and latest。
<ul>
<li>BOURBON 使查找速度比基线快1.54倍- 1.76倍。总的来说，无论请求分布如何，BOURBON 都减少了延迟。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107174316.png" alt="20201107174316" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>BOURBON 范围查询表现如何？</strong></p>
<ul>
<li>如图展示了 BOURBON 的吞吐量标准化到了 WiscKey 之后的结果。对于较短的范围，索引开销(即查找范围的第一个键的开销)占主导地位，BOURBON 优化效果比较明显，但随着范围的增大，其效果就不再那么明显，这是因为BOURBON 可以加速索引部分，但它遵循与 WiscKey 类似的路径来扫描后续键。因此，在大范围查询时，索引查询占较少的总性能，性能提升就不明显了。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107174537.png" alt="20201107174537" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>在有写的情况下，BOURBON 的开销-收益分析器和其他从不重新学习的方法相比表现如何？</strong></p>
<ul>
<li>首先了解三种策略：
<ul>
<li>BOURBON-offline 在写发生时不执行学习，模型仅针对最初加载的数据而存在</li>
<li>BOURBON-always 只要写发生了就会重新学习，不考虑成本</li>
<li>BOURBON-cba 会使用开销-收益分析器来决定是否学习</li>
</ul>
</li>
<li>图 a 显示了在前端查询和插入花费的时间，图 b 显示了学习过程花费的时间，图 c 显示了总的时间开销，图 d 显示了采用基线路径的内部查找的比例</li>
<li>结果表明：
<ul>
<li>所有的策略都相比于 WiscKey 减少了前台任务的时间开销，随着写比例的增加，查询比例的减小，优化的效果就减弱。offline 的策略表现最差，即便是在只有 1% 的写的情况下，这时候大多都是通过基线的索引查询方式（如图 d 所示的比例）来进行，所以对于数据改变之后的重新学习十分关键</li>
<li>BOURBON-always 在前台任务的时间开销上表现最好，几乎不会退化成基线的查询方式，但是对应的学习时间就特别长，在 50% 时候就大概花费 134s 进行学习，所以总的时间开销当写请求的比例较大的时候，可能比基线的时间开销还大</li>
<li>写请求比例较低的时候，BOURBON-cba 几乎会学习所有的文件，所以此时和 always 的表现比较相近，当写请求比例增大时，BOURBON-cba 不再学习特别多的文件，学习时间开销只有 13.9s，相比于 always 大大减小，因此这时候的很多查询都是按照基线对应的路径，因为此时数据变化迅速，查找次数较少，学习的收益较小。</li>
</ul>
</li>
<li>总结：积极学习策略提供快速查找，但代价高昂；没有 re-learning 的话几乎不能加快速度。也不理想。相比之下，BOURBON 提供了与积极学习类似的高收益，同时显著降低了总成本<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107183741.png" alt="20201107183741" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>BOURBON 在真实负载下的性能也能表现得和预期一致吗？</strong></p>
<ul>
<li>YCSB：BOURBON 提高了读操作的性能;同时，波旁威士忌并不影响写的表现。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107185902.png" alt="20201107185902" loading="lazy"></li>
<li>SOSD<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107185921.png" alt="20201107185921" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>数据存储在存储设备上时（不再在内存） BOURBON 是否有用？</strong></p>
<ul>
<li>即使数据存在存储设备上，BOURBON 也有一定程度的提升(查询速度比WiscKey快1.25倍到1.28倍)。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107191601.png" alt="20201107191601" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107191738.png" alt="20201107191738" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>有限的内存的情况下，BOURBON 是否有用？</strong></p>
<ul>
<li>如下表所示，使用了 SATA SSD 和大小只有数据量的 25% 的内存，BOURBON 速度只有 WiscKey 的 1.04 倍，因为大部分时间都花在了将数据加载到内存上。</li>
<li>相比之下，在 zipfian 工作负载中，索引时间（而不是数据访问时间）占主导地位，因为大量请求访问已经缓存在内存中的一小部分数据，所以能够提供 1.25x 的加速和低得多的延迟。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107191910.png" alt="20201107191910" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>BOURBON 在误差范围和空间开销上的权衡是怎么样的？</strong></p>
<ul>
<li>随着误差范围增大，更少的线段被创建，从而需要检索的线段就更少，延迟也就相应减小，然而当 δ 超过 8，尽管需要检索的分段更少，但是延迟增加了，对于其他数据集也是 δ = 8 是转折点。还显示了空间开销，因为创建的线段更少了，空间开销也就更小了。</li>
<li>对于各种数据集，开销与数据集的总大小相比是很小的(0% - 2%)。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201107192311.png" alt="20201107192311" loading="lazy"></li>
</ul>
</li>
</ul>
<h2 id="related-work">Related Work</h2>
<ul>
<li><strong>Learned Index</strong>:
<ul>
<li>XIndex</li>
<li>FITingTree</li>
<li>AIDEL</li>
<li>Alex</li>
<li>SageDB</li>
</ul>
</li>
<li><strong>LSM optimizations</strong>:
<ul>
<li>Monkey</li>
<li>Dostoevsky</li>
<li>HyperLevelDB</li>
<li>bLSM</li>
<li>cLSM</li>
<li>RocksDB</li>
</ul>
</li>
<li><strong>Model choices</strong>:
<ul>
<li>Greedy-PLR</li>
<li>Neural networks</li>
<li>one-pass learning algorithm based on splines</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[intelligent cache research]]></title>
        <id>https://blog.shunzi.tech/post/intelligent-cache-research/</id>
        <link href="https://blog.shunzi.tech/post/intelligent-cache-research/">
        </link>
        <updated>2020-10-25T15:59:49.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>本篇为智能缓存相关的研究调研，可能涉及 AI for System 以及相关缓存策略的设计</li>
<li>智能缓存顾名思义为不同的负载下提供相应的缓存策略来保证缓存的高效，主要包含多种缓存策略执行和 IO 负载的捕捉两个方面，同时可能结合不同的缓存层级需要进行动态调整。</li>
<li>缓存策略本身很难有普适的，现有做法和方案常常需要根据 IO 负载来进行决策，而对于 IO 负载的建模往往采用统计或者机器学习的方法</li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>本篇为智能缓存相关的研究调研，可能涉及 AI for System 以及相关缓存策略的设计</li>
<li>智能缓存顾名思义为不同的负载下提供相应的缓存策略来保证缓存的高效，主要包含多种缓存策略执行和 IO 负载的捕捉两个方面，同时可能结合不同的缓存层级需要进行动态调整。</li>
<li>缓存策略本身很难有普适的，现有做法和方案常常需要根据 IO 负载来进行决策，而对于 IO 负载的建模往往采用统计或者机器学习的方法</li>
</ul>
</blockquote>
 <!-- more -->
<h2 id="smart-ssd-cache">Smart SSD Cache</h2>
<h3 id="oceanstor-v5-系列-v500r007-smartcache">OceanStor V5 系列 V500R007 SmartCache</h3>
<ul>
<li>参考 https://support.huawei.com/enterprise/zh/doc/EDOC1000181455/1064ba78</li>
</ul>
<h4 id="定义">定义</h4>
<ul>
<li>华为技术有限公司开发的 SmartCache 特性又叫智能数据缓存特性。</li>
<li><strong>缓存池化</strong>：利用 SSD 盘对随机小I/O读取速度快的特点，将 SSD 盘组成智能缓存池，将访问频率高的随机小I/O读热点数据从传统的机械硬盘移动到由 SSD 盘组成的高速智能缓存池中。由于 SSD 盘的数据读取速度远远高于机械硬盘，所以 SmartCache 特性可以缩短热点数据的响应时间，从而提升系统的性能。</li>
<li><strong>多粒度</strong>：SmartCache 将智能缓存池划分成多个分区，为业务提供细粒度的SSD缓存资源，不同的业务可以共享同一个分区，也可以分别使用不同的分区，各个分区之间互不影响。从而向关键应用提供更多的缓存资源，保障关键应用的性能。</li>
</ul>
<h4 id="场景">场景</h4>
<ul>
<li>SmartCache特性对LUN（块业务）和文件系统（文件业务）均有效。</li>
<li>SmartCache特性可以提高业务的<strong>读性能</strong>。尤其是存在热点数据，且读操作多于写操作的随机小I/O业务场景。例如：OLTP（Online Transaction Processing ）应用、数据库、Web服务、文件服务应用等。</li>
</ul>
<h4 id="原理">原理</h4>
<ul>
<li>SmartCache特性在对SSD盘资源进行管理上，分为智能缓存池和SmartCache分区两部分。</li>
</ul>
<h5 id="智能缓存池">智能缓存池</h5>
<ul>
<li>智能缓存池管理本控制器的所有SSD盘，用以保证每个智能缓存分区的资源来自不同SSD盘，从而避免不同SSD盘负载不均衡。</li>
<li>存储系统默认在每个控制器上生成一个智能缓存池。</li>
</ul>
<h5 id="读流程">读流程</h5>
<ul>
<li>SSD Cache 缓存命中<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201021162117.png" alt="20201021162117" loading="lazy"></li>
<li>SmartCache读未命中
<ul>
<li>当从 HDD 读取到 RAM Cache 后，RAM Cache 将数据返回给应用服务器，同时 RAM Cache 将该数据同步到智能缓存池中。当智能缓存池容量不够时，则智能缓存池根据时间顺序释放旧数据，释放数据内存，完成旧数据的淘汰。</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201021162235.png" alt="20201021162235" loading="lazy"></figure>
<h5 id="smartcache分区">SmartCache分区</h5>
<ul>
<li>SmartCache分区负责为业务提供细粒度（4KB、8KB、16KB、32KB、64KB、128KB，与前端I/O自适应，即根据前端下发的I/O大小申请不同粒度的SSD缓存资源）的SSD缓存资源。</li>
<li>每两个控制器创建一个默认的SmartCache分区。除了默认分区外，每两个控制器最多支持创建8个用户自定义分区。</li>
<li>通过SmartCache分区调控，各业务独立使用所分配的SmartCache分区，避免不同类型应用之间的相互影响，保障存储系统整体的服务质量。可以通过设置SmartCache大小，实现不同业务与性能的最佳匹配。通过限制非关键应用的缓存资源，向关键应用提供更多的缓存资源，保障关键应用的性能。</li>
<li>SmartCache分区负责为业务提供细粒度的SSD盘缓存资源，不同的业务可以共享同一个分区，也可以分别使用不同的分区，各个分区之间互不影响。</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201021162705.png" alt="20201021162705" loading="lazy"></figure>
<h3 id="machine-learning">Machine Learning</h3>
<h4 id="date20-a-machine-learning-based-write-policy-for-ssd-cache-in-cloud-block-storage">DATE20 - A Machine Learning Based Write Policy for SSD Cache in Cloud Block Storage</h4>
<ul>
<li><strong>发现</strong>：作者在腾讯云的云存储环境中（主要是块存储系统），测试统计发现大约有 47.9% 的写操作是 write-only 的，即在某一个确定的时间窗口内所写的这些块不会再次被访问。那么这些 write-only 的写操作对应的数据放置在缓存中其实并不会带来性能的提升，反而会占据缓存容量，影响其他真正需要缓存的数据来进行缓存。</li>
<li><strong>问题</strong>：现有的写策略大致分为两种：
<ul>
<li>将所有要写的数据加载到缓存中（write-back 和 write through）
<ul>
<li>write-back：在数据更新时只写入缓存Cache。只在数据被替换出缓存时，被修改的缓存数据才会被写到后端存储。此模式的优点是数据写入速度快，因为不需要写存储；缺点是一旦更新后的数据未被写入存储时出现系统掉电的情况，数据将无法找回。</li>
<li>Write-through（直写模式）在数据更新时，同时写入缓存Cache和后端存储。此模式的优点是操作简单；缺点是因为数据修改需要同时写入存储，数据写入速度较慢。</li>
</ul>
</li>
<li>不加载数据到缓存，直接写存储设备 （write-around）</li>
</ul>
</li>
<li><strong>方案</strong>：提出了一种基于机器学习的方法来识别 write-only 数据和 normal 数据，针对不同类型的数据动态应用不同的写策略。最大的挑战是怎么样才能够实时地区分数据类型<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200714201124.png" alt="image" loading="lazy"></li>
<li>使用了五种监督学习方法：Naive Bayes, Logistic Regression, Decision Tree, AdaBoost, and Random Forest。随机森林准确率最高，但是耗时最长，不满足实时性，朴素贝叶斯在准确率、召回率和预测时间上基本做到了 trade-off，所以最终选择了朴素贝叶斯。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master/img/blog/20200714201440.png" alt="image" loading="lazy"></li>
<li><strong>数据指标的选择</strong>：不同于在文件级别或者片上系统的基于机器学习的优化，在块级系统中部署机器学习算法来分类不同的数据面临很大的障碍，因为块级能提供的信息是有限的，常用的信息包括时间特征和空间特征（如最近访问时间和最近访问的地址）。本文中我们扩展了数据指标到 IO 请求，收集了如 average write size, write request ratio 等，这是由于具有类似请求级别的数据往往表现出类似的访问特征
<ul>
<li>Temporal features：这些特性包括数据块的访问近因和时间间隔。
<ul>
<li>Last Access Timestamp 在本文中被定义成了当前时间和最近访问该块的时间间隔。</li>
<li>Average Re-access Time Difference：对一个数据块进行两个相邻访问的时间间隔</li>
</ul>
</li>
<li>Spatial features：这些特性包含地址信息，例如卷 ID、偏移量等
<ul>
<li>因为地址会随着时间不断变化，对算法的效果会有显著影响，在作者实现的算法中其实没有使用空间特征。</li>
</ul>
</li>
<li>Request-level features
<ul>
<li>Average Request Size 平均请求大小，单位 KB，上界为 100KB</li>
<li>Big Request Ratio 大请求比例，请求大小大于 64KB 即为大请求</li>
<li>Small Request Ratio 小请求比例，请求小于 8KB 即为小请求</li>
<li>Write Request Ratio 写请求的比例</li>
</ul>
</li>
</ul>
</li>
<li><strong>统计粒度</strong>： 块设备的最小粒度为一个块，假设一个块为 8KB，如果我们为每一个块都统计对应的数据特征，因为块设备容量很大，那么统计这些特征就会造成巨大的开销，同时太大可能影响算法的准确率，所以实际应用过程中，作者采用了 1MB 为统计粒度（称之为 tablet），1MB 连续的数据块中所包含的最小物理块对应的数据特征相同，从而减少统计的开销。</li>
<li>整个模型的工作流程如下：
<ul>
<li>写请求的所有数据被首先被写入到内存中并顺序地记录在日志文件中，然后当脏数据的比例达到阈值则刷回到后端存储服务器，当在内存写缓冲中要执行对应的刷回操作时，进行下一步</li>
<li>分类器获取最近刷回的数据块的 tablet 特征并预测其写请求类型，如果是 write-only 跳转到下一步，如果不是（即为 normal data）跳转到第四步</li>
<li>如果该数据位于 SSD Cache 中且为脏数据，那么首先将该脏数据刷回到 HDD。对应的数据块将直接在 HDD 上进行写</li>
<li>数据块首先写入到 SSD 缓存然后使用 write-back 的策略异步刷回 HDD</li>
</ul>
</li>
<li>分类器每天训练一次用于第二天的预测，系统运行过程中收集样本数据，当 SSD cache 发生 eviction 的时候将增加一个样本，如果 evicted-data 有一次或者多次读命中，该样本将被设置为 0，也就是 normal data，否则设置为 1，write-only data。在作者的想法中，真实的实现里，write-only 的数据块是指一个在从缓存中 evict 之前不会被读的块</li>
<li><strong>效果</strong>：实验结果表明，与业界广泛部署的回写策略相比，ML-WP 减少了对 SSD 缓存的写流量 41.52%，同时提高了 2.61% 的命中率，降低了 37.52% 的平均读延迟</li>
</ul>
<h5 id="related-work">Related Work</h5>
<ul>
<li>
<p><strong>写策略优化</strong></p>
<ul>
<li>ATC15 - Request-oriented durable write caching for application performance
<ul>
<li>分析IO工作负载（判断是否会发生争用），然后部署最合适的写策略，使用了固定的写策略</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Cache Optimization Based on Machine Learning</strong>:</p>
<ul>
<li>MICRO16 Perceptron learning for reuse prediction
<ul>
<li>感知器学习用于判断 last-level cache 的重用预测 （神经网络做预测）</li>
<li>通过使用多个能够展示程序和存储器行为的特征（七个参数化特征）来从多个视角对LLC中的缓存块的未来重用进行预测。利用预测的结果，设计三种cache的管理策略：block placement，replacement，bypass</li>
<li>PC, address, reference count, etc</li>
</ul>
</li>
<li>ICPP18 Efficient ssd caching by avoiding unnecessary writes using machine learning
<ul>
<li>使用机器学习（决策树）来进行一次访问排除，能够准确地识别和过滤一次访问的照片，并阻止它们写入cache，提高社交网络照片缓存服务的效率。更多的使用照片的相关数据以及用户的登录请求数据来作为数据集</li>
<li>使用 reaccess distance 来定义是否为只访问一次的图像，被定义为从该图像进入cache 开始到下一次被访问之间的总的图像访问量</li>
<li>命中率提高了17%，缓存写操作降低了79%，平均访问延迟降低了 7.5%</li>
</ul>
</li>
<li>NSDI19 Flashield: a hybrid key-value cache that controls flash write amplification
<ul>
<li>由于键值更新会对 SSD 造成严重的有害的小随机I/O写操作，因此使用机器学习（支持向量机 SVM）的方法来选择期望读取频率更高的对象</li>
<li>Flashield这里引入了Flashiness的概念，作为一个对象被Cache价值的一个评价指标，一个高Cache价值的对象要满足两点条件
<ul>
<li>一个对象在访问之后会在不远的将来访问n次(及以上)，这里的n作为参数定义，</li>
<li>在将来的一段时间内不会被修改<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201021172230.png" alt="20201021172230" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="new-cache-policy">New Cache Policy</h3>
<h4 id="tpds20-efficient-ssd-cache-for-cloud-block-storage-via-leveraging-block-reuse-distances">TPDS20 - Efficient SSD Cache for Cloud Block Storage via Leveraging Block Reuse Distances</h4>
<ul>
<li>
<p><strong>发现</strong>：我们在一个典型云块存储的服务器端发现了这一点，有很大比例的块具有很大的重用距离，这意味着很多块只有在遥远的将来才会被重新引用。在这样的场景中，如果在每次 miss 时进行简单的替换，新访问的块会污染缓存，而不会给命中率带来任何好处，从而降低缓存效率。现有的缓存算法在存在较大的重用距离时，缓存效率往往不理想</p>
<ul>
<li>如下图所示，A 点意味着 CBS 访问中，有大约 50% 的块的重用距离大于 32GB，而对于内存和主机上的 IO 则要小得多</li>
<li>因此，如果我们使用像LRU这样的缓存算法，当缓存大小等于或小于 32gb 时，50% 的重用块不会被命中<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201021174825.png" alt="20201021174825" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>现象分析</strong>：</p>
<ul>
<li>多数具有小重用距离的数据块已经被客户端缓存设备缓存和过滤。</li>
<li>单个云磁盘的容量可以达到几十TB，这比传统磁盘高出几个数量级。因此，数据规模较大的云应用程序可能导致更大的重用距离</li>
<li>在多租户共享云环境中，来自不同租户的访问会混合在一起，导致重用距离增加</li>
</ul>
</li>
<li>
<p><strong>贡献</strong>：我们提出了一种新的缓存算法，专为 CBS 和其他类似场景设计的 LEA，LEA在缓存未命中时默认不进行替换，除非满足某些(惰性)条件。条件包含两个方面：新访问块的频率 和 缓存中的候选逐出块的值（该值是指该块对缓存的重要性或有用性）。这样，块的缓存持续时间可以大大延长。更重要的是，可以大大减少对 SSD 的写操作，延长 SSD 的生命周期</p>
</li>
<li>
<p><strong>Reuse Distance</strong>：数据块的重用距离定义为对同一块的两个连续引用之间的唯一数据量。例如 1-2-4-5-4-3-3-2 的块访问序列中，Block 2 的 reuse distance 就是三个块的大小，在有的研究中，Block 2 的 reuse distance 为 5 个块的大小。本文采用了第二种定义。</p>
</li>
<li>
<p>传统的 LRU 当缓存空间满时，对每次miss进行替换，主要遵循时间局部性原则，这些缓存替换算法的主要目标是保留重用距离较小的块，驱逐重用距离较大的块。当大部分数据重用距离小于缓存大小时，这些算法可以有效地工作。</p>
</li>
</ul>
<h5 id="lea-algorithm">LEA Algorithm</h5>
<ul>
<li>维护两个队列，Lazy Eviction List (LEL) 和 Block Identity List (BIL)。每个队列有两个端点 Insertion Point (IP) 和 Eviction Point (EP)
<ul>
<li>标识只包括块的卷号和地址信息(偏移量)。一个条目包含额外的块信息，如 last_access, reuse_distance, age, flag，等等。条目中的信息用于计算条目块的值。</li>
<li>age 表示块的当前时间和最后一次访问时间(last_access)之间的时间差，如果 age 小于 reuse_distance，它表明该块对缓存具有较高的价值。这里的时间是逻辑时间，当一个新的块请求到来时，逻辑时间增加1。这里，重用距离是最后两次访问之间的时间(而不是访问之间的平均时间)。</li>
<li>flag 也用来判断块的值，当块在 LEL 列表中命中时增加 1，当块被视为块驱逐候选，但由于懒惰替换还没有被驱逐时减少一半，如果 flag 大于 0，它表明该块对于缓存是有价值的。</li>
</ul>
</li>
<li>当发生缓存 miss 时，LEA 不进行替换，只在满足延迟条件时将丢失的块标识插入 BIL 列表，否则，它将执行替换并将丢失的块条目插入到 LEL 列表中。如果在 BIL 列表中命中了一个块，那么它进入LEL列表的概率更高。通过这样做，间接地考虑了访问频率<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201021191310.png" alt="20201021191310" loading="lazy"></li>
</ul>
<h4 id="atc20-osca-an-online-model-based-cache-allocation-scheme-in-cloud-block-storage-systems">ATC20 - OSCA: An Online-Model Based Cache Allocation Scheme in Cloud Block Storage Systems</h4>
<ul>
<li>OSCA 可以在非常低的复杂度下找到接近最佳的配置方案，从而提高缓存服务器的总体效率
<ul>
<li>部署了一个新的缓存模型来获得云基础设施块存储系统中每个存储节点的 miss ratio curve (MRC)。使用一种低开销的方法来获得一个时间窗口内从重新访问流量与总流量之比的数据重用距离。然后将得到的重用距离分布转化为 miss ratio curve (MRC)。</li>
<li>通过了解存储节点的缓存需求，将总命中流量指标定义为优化目标</li>
<li>使用动态规划方法搜索接近最优的配置，并基于此解进行缓存重新分配</li>
</ul>
</li>
<li>在实际工作负载下的实验结果表明，模型达到了一个平均值绝对误差(MAE)，可与现有的最先进的技术相媲美，但同时可以做到没有跟踪收集和处理的开销。由于命中率的提高，相对于在相同缓存内存的情况下对所有实例的等分配策略，OSCA 减少了到后端存储服务器的 IO 流量 13.2%<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201021194032.png" alt="20201021194032" loading="lazy"></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ceph FS 介绍和使用]]></title>
        <id>https://blog.shunzi.tech/post/CephFS/</id>
        <link href="https://blog.shunzi.tech/post/CephFS/">
        </link>
        <updated>2020-10-14T12:32:20.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>一个项目测试使用到了 CephFS，故简要整理 CephFS 资料和相关文档</li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>一个项目测试使用到了 CephFS，故简要整理 CephFS 资料和相关文档</li>
</ul>
</blockquote>
<!--more-->
<h2 id="cephfs">CephFS</h2>
<ul>
<li><a href="https://github.com/zjs1224522500/BlogIssue/issues/18">Ceph 常用命令</a></li>
<li><a href="https://chaosd.github.io/2020/08/17/Deploy%20a%20Ceph%20Cluster%20Manually/">Deploy a Ceph Cluster Manually</a></li>
</ul>
<h3 id="overview">Overview</h3>
<ul>
<li>CephFS 应用相比于 RBD/RGW 不够广泛主要是因为文件系统采用树状结构管理数据（文件和目录）、基于查表寻址的设计理念与 Ceph 扁平化的数据管理方式、基于计算进行寻址的设计理念有些违背；其次文件系统的支持常常需要集中的元数据管理服务器来作为树状结构的统一入口，这又与 Ceph 去中心化、追求近乎无限的横向扩展能力的设计思想冲突。</li>
<li>由于分布式文件系统的需求仍旧很大，应用场景尤为广泛，在 Ceph 不断的版本迭代中，CephFS 也取得了越来越好的支持。</li>
</ul>
<h3 id="背景">背景</h3>
<ul>
<li>要想实现分布式文件系统，那么就必须实现分布式文件系统的特点，即具有良好的横向扩展性，性能能够随着存储规模呈线性增长，为了实现这样的目标则需要对文件系统命名空间分而治之，即实现相应的负荷分担和负载均衡，采用相应的数据路由算法。</li>
</ul>
<h4 id="文件系统数据负载均衡分区">文件系统数据负载均衡分区</h4>
<h5 id="静态子树分区">静态子树分区</h5>
<ul>
<li>手工分区，数据直接分配到某个固定的服务节点，负载不均衡时再手动调整。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201013150928.png" alt="20201013150928" loading="lazy"></li>
</ul>
<h5 id="hash-计算分区">HASH 计算分区</h5>
<ul>
<li>HASH 计算数据的存储位置，保证了数据分布的均衡，但如果环境变化（集群规模变化）此时需要固定原有的数据分区而减少数据的迁移，或者根据元数据的访问频率，要想保证 MDS 负载均衡，需要重新决定元数据的分布，此时则不适合使用 HASH</li>
</ul>
<h5 id="动态子树分区">动态子树分区</h5>
<ul>
<li>通过实时监控集群节点的负载，动态调整子树分布于不同的节点。这种方式适合各种异常场景，能根据负载的情况，动态的调整数据分布，不过如果大量数据的迁移肯定会导致业务抖动，影响性能。在元数据存储、流量控制和灵活的资源利用策略方面，动态分区比其他技术有许多优势。</li>
<li>https://ceph.com/wp-content/uploads/2016/08/weil-mds-sc04.pdf<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201013151347.png" alt="20201013151347" loading="lazy"></li>
<li>动态子树分区方法的核心是将文件系统作为层次结构处理。通过将层次结构的子树的权限委托给不同的元数据服务器，对文件系统进行分区。委托可以嵌套:例如，/usr可以分配给一个MDS，而/usr/local可以分配给另一个MDS。但是，在没有显式分配子树的情况下，嵌套在某个点下的整个目录树被假定驻留在同一台服务器上。</li>
<li>这个结构中隐含着层次结构遍历的过程，以便找到并打开嵌套的索引节点，以便随后下降到文件层次结构中。这样的路径遍历对于验证POSIX语义所要求的嵌套项的用户访问权限也是必要的，对于在目录层次结构深处定位一个文件来说，这个过程可能代价很高。</li>
<li>为了允许有效地处理客户机请求(以及正确响应它们所需的路径遍历)，每个MDS都缓存缓存中所有项的前缀索引节点，以便在任何时候缓存的层次结构子集仍然是树结构。也就是说，只有叶子项可以从缓存中过期;在目录中包含的项首先过期之前，不能删除目录。这允许对所有已知项进行权限验证，而不需要任何额外的I/O成本，并保持层次一致性。</li>
<li>为了适应文件系统发展和工作负载变化的要求，MDS集群必须调整目录分区，以保持工作负载的最佳分布。动态分布是必要的，因为层次结构部分的大小和流行度都以一种不均匀和不可预测的方式随时间变化。通过允许MDS节点传输目录层次结构的子树的权限，元数据分区会随着时间的推移进行修改。MDS节点定期交换心跳消息，其中包括对其当前负载级别的描述。此时，忙碌的节点可以识别层次结构中适当流行的部分，并发起一个双重提交事务，将权限传递给非繁忙节点。在此交换过程中，所有活动状态和缓存的元数据都被转移到新的权威节点，这既是为了保持一致性，也是为了避免磁盘I/O，否则，新权威节点将需要磁盘I/O来重新读取它，而磁盘I/O会慢上几个数量级。</li>
</ul>
<h4 id="cephfs-mds-特点">CephFS MDS 特点</h4>
<ul>
<li>采用多实例消除性能瓶颈并提升可靠性</li>
<li>采用大型日志文件和延迟删除日志机制提升元数据读写性能</li>
<li>讲 Inode 内嵌至 Dentry 中来提升文件索引率</li>
<li>采用目录分片重新定义命名空间层次结构，并且目录分片可以在 MDS 实例之间动态迁移，从而实现细粒度的流控和负载均衡机制</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200831094239.png" alt="20200831094239" loading="lazy"></figure>
<h3 id="架构">架构</h3>
<ul>
<li>
<p>虽然 Ceph 文件系统中的 inode 数据存储在 RADOS 中并由客户端直接访问，但是 inode 元数据和目录信息由Ceph metadata server (MDS)管理。MDS 充当所有与元数据相关的活动的中介，将结果信息存储在与文件数据不同的RADOS 池中。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200830135706.png" alt="20200830135706" loading="lazy"></p>
</li>
<li>
<p>CephFS中的所有文件数据都存储为RADOS对象。CephFS客户端可以直接访问RADOS对文件数据进行操作。MDS只处理元数据操作。</p>
</li>
<li>
<p>要读/写CephFS文件，客户端需要有相应inode的“文件读/写”功能。如果客户端没有需要的功能 caps，它发送一个“cap消息”给MDS，告诉MDS它想要什么。MDS将在可能的情况下向客户发布功能 caps。一旦客户端有了“文件读/写”功能，它就可以直接访问 RADOS 来读/写文件数据。文件数据以 <inode number>, <object index> 的形式存储为RADOS对象。如果文件只由一个客户端打开，MDS还会向唯一的客户端提供“文件缓存/缓冲区”功能。“文件缓存”功能意味着客户端缓存可以满足文件读取要求。“文件缓冲区”功能意味着可以在客户端缓存中缓冲文件写。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200831094239.png" alt="20200831094239" loading="lazy"></p>
</li>
</ul>
<h4 id="cepgfs-client-访问示例">CepgFS Client 访问示例</h4>
<ul>
<li>Client 发送 open file 请求给 MDS</li>
<li>MDS 返回 file node, file size, capability 和 stripe 信息</li>
<li>Client 直接 READ/WRITE 数据到 OSDs（如果无 caps 信息需要先向 MDS 请求 caps）</li>
<li>MDS 管理 Client 对该 file 的 capabilities</li>
<li>Client 发送 close file 请求给 MDS，释放 file 的 capabilities，更新 file 的详细信息</li>
</ul>
<h4 id="mds-文件锁">MDS 文件锁</h4>
<ul>
<li>当客户机希望在 inode 上操作时，它将以各种方式查询 MDS，然后授予客户机一组功能。它们授予客户端以各种方式操作 inode 的权限。与其他网络文件系统(例如 NFS 或 SMB)的主要区别之一是，所授予的功能非常细粒度，多个客户机可能在同一个 inode 上拥有不同的功能。</li>
<li>CephFS 客户机可以请求MDS代表它获取或更改 inode 元数据，但是MDS还可以为每个 inode 授予客户机功能 (caps)</li>
</ul>
<pre><code class="language-C">/* generic cap bits */
#define CEPH_CAP_GSHARED     1  /* client can reads (s) */
#define CEPH_CAP_GEXCL       2  /* client can read and update (x) */
#define CEPH_CAP_GCACHE      4  /* (file) client can cache reads (c) */
#define CEPH_CAP_GRD         8  /* (file) client can read (r) */
#define CEPH_CAP_GWR        16  /* (file) client can write (w) */
#define CEPH_CAP_GBUFFER    32  /* (file) client can buffer writes (b) */
#define CEPH_CAP_GWREXTEND  64  /* (file) client can extend EOF (a) */
#define CEPH_CAP_GLAZYIO   128  /* (file) client can perform lazy io (l) */
</code></pre>
<ul>
<li>然后通过特定数量的位进行移位。这些表示 inode 的数据或元数据的一部分，在这些数据或元数据上被授予能力:</li>
</ul>
<pre><code class="language-C">/* per-lock shift */
#define CEPH_CAP_SAUTH      2 /* A */
#define CEPH_CAP_SLINK      4 /* L */
#define CEPH_CAP_SXATTR     6 /* X */
#define CEPH_CAP_SFILE      8 /* F */
</code></pre>
<ul>
<li>一个 Cap 授予客户端 缓存和操作与 inode 关联的部分数据或元数据的能力。当另一个客户机需要访问相同的信息时，MDS 将撤销该 cap，而客户机最终将返回该功能，以及 inode 元数据的更新版本(如果它在保留功能时对其进行了更改)。</li>
<li>客户机可以请求 cap，并且通常会获得这些 cap，但是当 MDS 面临竞争访问或内存压力时，这些 cap 可能会被 revoke。当一个 cap 被 revoke 时，客户端负责尽快返回它。未能及时这样做的客户端可能最终被阻塞并无法与集群通信。</li>
<li>由于缓存是分布式的，所以 MDS 必须非常小心，以确保没有客户机拥有可能与其他客户机的 cap 或它自己执行的操作发生冲突的 cap。这使得 cephfs 客户机比 NFS 这样的文件系统依赖于更大的缓存一致性，在 NFS 中，客户机可以缓存数据和元数据，而这些数据和元数据在服务器上已经更改了。</li>
<li>基于 caps，构建了 ceph 的分布式文件锁，分布式文件锁保证了多个客户端并发且细粒度访问同一文件、目录、文件系统，同时保证一致性、可靠性。ceph 实现的分布式文件系统锁，客户端可见部分是 caps，服务端可见部分包括 caps和各种 lock，每个类型的 lock 又有多种状态，根据客户端的请求、持有、释放情况，lock 转换自身状态，并和客户端同步 caps 信息。最终实现分布式锁的访问。</li>
</ul>
<h3 id="参考链接">参考链接</h3>
<ul>
<li><a href="https://www.jianshu.com/p/e7d79a0d5314">[1] CephFS 介绍及使用经验分享</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[FAST20 Some Interesting Papers Overview]]></title>
        <id>https://blog.shunzi.tech/post/fast20-some/</id>
        <link href="https://blog.shunzi.tech/post/fast20-some/">
        </link>
        <updated>2020-10-12T01:53:00.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>最近进入了一个怠惰期，一是苦于没有明确的研究方向，二是沉湎于琐碎小事，所以科研上很多事情都被搁置</li>
<li>遇到了问题就总得寻找解决的办法，所以决定还是好好看几篇论文，看看能不能找到感兴趣的点，再深入挖掘</li>
<li>最近也没太多新的会议，故还是先好好看看 FAST20 上的文章，对一些可能感兴趣的文章做些简单记录</li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>最近进入了一个怠惰期，一是苦于没有明确的研究方向，二是沉湎于琐碎小事，所以科研上很多事情都被搁置</li>
<li>遇到了问题就总得寻找解决的办法，所以决定还是好好看几篇论文，看看能不能找到感兴趣的点，再深入挖掘</li>
<li>最近也没太多新的会议，故还是先好好看看 FAST20 上的文章，对一些可能感兴趣的文章做些简单记录</li>
</ul>
</blockquote>
<!--more-->
<h1 id="fast20">FAST20</h1>
<ul>
<li>此次会议主要分为了 Cloud Storage、File Systems、HPC Storage、SSD and Reliability、Performance、Key Value Storage、Caching 和 Consistency and Reliability 几个 Topic。本篇文章不会对所有的 Topic 下的所有论文都进行总结记录，譬如 HPC Storage 由于缺乏一定的了解就没有在此处记录，针对每个 Topic 下的文章也只是选择了自己有一定的了解或者感兴趣的几篇来简单地记录。</li>
<li>有的文章会详细展开，有的因为受限于我自己的水平无法深入，故只能泛泛而谈，但会尽力尝试去理解所要解决的问题以及解决问题的方式。</li>
<li>本篇博文会持续记录更新，因为阅读量还挺大的，遇到比较好的感兴趣的论文会单独开一篇进行详细的理解记录。</li>
</ul>
<h2 id="cloud-storage">Cloud Storage</h2>
<ul>
<li>云存储主题下 FAST20 有三篇：
<ul>
<li>MAPX: Controlled Data Migration in the Expansion of Decentralized Object-Based Storage Systems
<ul>
<li>Li Wang, <strong>Didi Chuxing</strong>; Yiming Zhang, NiceX Lab, NUDT; Jiawei Xu and Guangtao Xue, SJTU</li>
</ul>
</li>
<li>Lock-Free Collaboration Support for Cloud Storage Services with Operation Inference and Transformation
<ul>
<li>Jian Chen, Minghao Zhao, and Zhenhua Li, <strong>Tsinghua University</strong>; Ennan Zhai, Alibaba Group Inc.; Feng Qian, University of Minnesota - Twin Cities; Hongyi Chen, Tsinghua University; Yunhao Liu, Michigan State University &amp; Tsinghua University; Tianyin Xu, University of Illinois Urbana-Champaign</li>
</ul>
</li>
<li>POLARDB Meets Computational Storage: Efficiently Support Analytical Workloads in Cloud-Native Relational Database
<ul>
<li>Wei Cao, <strong>Alibaba</strong>; Yang Liu, ScaleFlux; Zhushi Cheng, Alibaba; Ning Zheng, ScaleFlux; Wei Li and Wenjie Wu, Alibaba; Linqiang Ouyang, ScaleFlux; Peng Wang and Yijing Wang, Alibaba; Ray Kuan, ScaleFlux; Zhenjun Liu and Feng Zhu, Alibaba; Tong Zhang, ScaleFlux</li>
</ul>
</li>
</ul>
</li>
<li>云存储主题下的文章被国内的企业和高校包揽，其实不难发现云存储还是更偏向于工业界的实际应用的，而国内的企业在相应的领域都有着各自丰富的积累，特别是在数据库领域更是百花齐放（POLARDB Meets Computational Storage）；也有自己在运维相关存储系统时的经验总结以及对应的优化方案（MAPX）；还有一个比较有意思的点就是近年来比较多的团队协作式的云存储（Lock-Free Collaboration Support for Cloud Storage），又恰逢疫情更是推动了云存储的普及。</li>
</ul>
<h3 id="mapx-controlled-data-migration-in-the-expansion-of-decentralized-object-based-storage-systems">MAPX: Controlled Data Migration in the Expansion of Decentralized Object-Based Storage Systems</h3>
<ul>
<li>这篇因为之前有针对全文的翻译和理解，此处不做过多的介绍，更详细的可以参考
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/111505363">知乎：信息存储论文选读 - MAPX</a></li>
<li><a href="https://blog.shunzi.tech/post/controlled-data-migration-in-the-expansion-of-decentralized-object-based-storage-systems/">shunzi blog - MAPX</a></li>
</ul>
</li>
</ul>
<h4 id="简要介绍">简要介绍</h4>
<ul>
<li><strong>问题</strong>：该文解决的问题其实是 CURSH 算法最大的问题——集群扩容或者添加中间逻辑结构（如PGs）时会造成不受控制的数据迁移，虽然迁移可以在扩展之后立即重新平衡整个系统的负载，但是在扩展规模较大时会导致显著的性能下降。（如以机架的规模进行扩容）</li>
<li><strong>为什么会产生这样的问题？</strong> 设计 CRUSH 算法目的其实主要是为了去中心化，即不需要像 HDFS 等分布式存储系统依赖中心化的目录或元数据管理来寻址对应的数据，而是通过直接计算的方式来实现从而降低对中心化的元数据管理的耦合。但是 CRUSH 相比于中心化管理，中心化目录的存储系统可以保证原有的数据在扩容过程中不受影响，只把新的数据存储在新的存储节点上，CRUSH 由于缺少了关于集群扩容过程中带来的物理存储节点（OSD）的差异信息，在进行计算时都统一处理，由于相应的逻辑节点的权重发生了显著变化，CRUSH 计算结果发生了变化，就会导致大量的数据迁移。</li>
</ul>
<h4 id="解决方案">解决方案</h4>
<ul>
<li>受中心化数据布局策略的启发，致力于实现扩容过程中数据迁移的可控，所以基于 CRUSH 设计实现了 MAPX，核心思想就是<strong>引入时间维度的映射机制来区分 新老 对象/OSD</strong> ，同时保留 CRUSH 算法随机和均匀的优点。</li>
<li>为了尽可能少地修改原有的 CRUSH 算法，在原本的 CRUSH 根节点下插入一个虚拟层，如图所示，每一个虚拟节点代表一次扩容。虚拟层对应的通过使用 MAPX 实现可控数据迁移，通过在执行原本的 CRUSH 算法之前将新的对象映射到新的 layer，因为新的 layer 不会影响原有 layer 的权重，原有对象的放置还是和以前一样，不会发生改变。<br>
<img src="https://blog.shunzi.tech/post-images/1584325944117.png" alt="image" loading="lazy"></li>
<li>MAPX 能保证每一层的负载均衡，主要是因为通用 CRUSH 算法的随机性和均匀性，随着时间的迁移，新的 layer 中的数据增多到和前一个 layer 时则实现了 layers 层面的负载均衡。但是一个 layer 的负载可能会因为 对象的删除、OSD 的宕机发生一些不可预测的负载变化。如图所示，当 layer1 中的负载跟原始集群 layer0 的负载一样高时，则可能会执行一次扩容产生 layer2，假设 layer1 中执行了大量的对象删除操作，则会造成不同 layers 之间的负载不均衡。</li>
<li>为了解决这个问题，MAPX 设计了三种灵活的策略来动态管理 MAPX 中的负载：
<ul>
<li><strong>PG 重映射</strong>：可以控制 PGs 到 Layer 的映射，来保证 layers 负载均衡</li>
<li><strong>集群缩容</strong>：缩容时需要进行 PG 重映射调整负载，但也要保留部分元数据来保证映射关系不变</li>
<li><strong>layers 合并</strong>：使用时间戳来保证物理层的变化在逻辑层 layer 上保持相同以实现负载均衡</li>
</ul>
</li>
</ul>
<h3 id="lock-free-collaboration-support-for-cloud-storage-services-with-operation-inference-and-transformation">Lock-Free Collaboration Support for Cloud Storage Services with Operation Inference and Transformation</h3>
<ul>
<li>这篇文章呢其实主要是对现如今比较时髦的一个场景进行了综合性的分析，也提供了自己的方案。即针对共享文档的编辑时的版本管理和冲突解决的方式进行了深入探讨，结合了市面上现有的多种云存储的团队协作方案，分析之后他们提出了一种无锁的共享文档的编辑的方案，设计了一种比较智能的办法来减少冲突，且开源。</li>
<li>提出了问题同时也利用并设计了算法上的优化，难点主要在于对整个过程进行建模的过程。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201012163936.png" alt="20201012163936" loading="lazy"></li>
<li>这篇文章还有的一个比较有意思的点在于，本文涉及到的别的云存储共享编辑的产品其本身是不开源的，所以在分析这些产品可能的实现方式的时候其实是个很复杂的过程，作者们通过抓包、解密网络流量、分析数据驱动的方法、阅读部分代码和文档的方式才渐渐分析出大致的实现原理</li>
<li>对共享文档的编辑或者云存储协作感兴趣的同学可以深入阅读，由于不涉及到自己更了解的存储系统领域，此处就不班门弄斧了。</li>
</ul>
<h3 id="polardb-meets-computational-storage-efficiently-support-analytical-workloads-in-cloud-native-relational-database">POLARDB Meets Computational Storage: Efficiently Support Analytical Workloads in Cloud-Native Relational Database</h3>
<ul>
<li>开始之前先贴几篇讲解和总结（主要是不想重复造轮子hhhh）
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/111013416">知乎：阿里云数据库技术 - 深度思考 | 读POLARDB论文有感 : 异构计算和数据库软硬一体化设计</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/111615643">知乎：CobbLiu - FAST20论文赏析（一）</a></li>
<li><a href="https://blog.csdn.net/qq_37151108/article/details/105096703">CSDN：黄小米吖 - 论文阅读——POLARDB</a></li>
</ul>
</li>
</ul>
<h4 id="简要介绍-2">简要介绍</h4>
<ul>
<li>PolarDB 整体架构<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201012194710.png" alt="20201012194710" loading="lazy"></li>
<li>存算分离架构的背景下，云原生的关系型数据库需要把数据敏感型的任务（例如 table scan）从前端数据库给下发到后端存储节点，以便充分支持分析工作负载，减小存储节点和计算节点之间的链路传输,，但将该类任务转发到存储节点之后对于存储节点的效率则提出了挑战，新出现的 computational storage drives （也称存内计算或者计算型存储）使得上述想法成为可能。</li>
<li>要想使存储节点有足够的能力支持”计算下推”，通常有两个方案，一是scale-up存储节点的CPU能力；二是在存储节点上配备特殊硬件（比如GPU 或者FPGA）来用这些特殊硬件执行存储节点上的”计算下推“任务。第一个方案会较大增加存储节点的成本；第二个方案会引起存储节点内大量的数据迁移， 同时在拥有多块NVMe SSD的存储节点上很容易使特殊硬件成为热点，制约单个存储节点的对外能力。 论文提出了一个新的思路，直接将”计算下推“的工作offload到物理介质<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201012175245.png" alt="20201012175245" loading="lazy"></li>
<li>然而，异构计算实际可行的实现和实际部署仍然完全缺失，至少在开放文献中是这样。这主要是由于很难解决两个挑战:
<ul>
<li>(1) 如何实际支持跨整个软件层次的表扫描 pushdown
<ul>
<li>由用户空间POLARDB存储引擎发起，该存储引擎通过指定文件中的偏移量来访问数据，而表扫描在物理上由计算存储驱动器提供，它作为原始块设备运行，并使用LBA(逻辑块地址)管理数据。整个存储I/O堆栈位于POLARDB存储引擎和计算存储驱动器之间。因此，我们必须内聚地增强/修改整个软件/驱动程序堆栈，以便创建一个支持表扫描叠加的路径</li>
<li>组成：
<ul>
<li>前端分析处理引擎 PolarDB MPP：该分析处理引擎与 MySQL 协议兼容，可以解析、优化和重写使用 AST(抽象语法树)的 SQL 和许多嵌入式优化规则，它将每个 SQL 查询转换为一个 DAG(有向无环图)执行计划，由操作符和数据流拓扑组成。该引擎原生就支持 pushdown</li>
<li>存储引擎 PolarDB Storage Engine：遵循了 LSM-tree 实现，数据被组织成了多个文件，每个文件包含很多块。
<ul>
<li>原有的实现中，存储引擎可以使用存储节点上的 CPU 来处理 table scan 请求，因此 table scan pushdown 将与底层的 IO 堆栈无关。</li>
<li>为了利用可计算型存储的特点，需要修改该引擎以便将 table scan 请求 pushdown 到 PolarFS 上。存储引擎根据文件中的偏移量访问数据块。每一个 table scan 请求包括：
<ul>
<li>要被扫描的数据的定位信息（文件内的偏移量）；</li>
<li>应用表扫描的表的 schema；</li>
<li>table scan condition。</li>
</ul>
</li>
<li>POLARDB 存储引擎分配一个内存缓冲区来存储从计算存储驱动器返回的数据，每个 table scan 请求都包含这个内存缓冲区的位置</li>
</ul>
</li>
<li>POLARDB部署在分布式文件系统PolarFS上，该文件系统管理跨所有存储节点的数据存储。computational storage drives 只能以 LBA 的形式定位数据，PolarFS 在收到来自 POLARDB存储引擎的每个表扫描请求后需要进行数据转换</li>
<li>计算存储驱动器完全由内核空间中的主机端驱动程序管理，该驱动程序将每个计算存储驱动器公开为块设备。当收到每个表扫描请求时，驱动程序执行以下操作
<ul>
<li>分析 scan conditions，可能对 conditions 重新进行组织以获得更好的性能</li>
<li>驱动程序进一步转换将被扫描数据的位置信息从LBA域到物理块地址(PBA)域，其中每个PBA与NAND闪存中的一个固定位置相关联。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201012195303.png" alt="20201012195303" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>(2) 如何实现低成本的计算存储驱动器具有足够的表扫描处理能力
<ul>
<li>虽然基于FPGA的设计方法可以显著降低开发成本，但FPGA往往比较昂贵。此外,由于<br>
FPGA通常仅工作在200 ~ 300MHz(与之相比，CPU时钟频率为2 ~ 4GHz)，为了实现足够高的性能，我们必须使用大量的电路级实现并行性(因此需要更多的硅资源)。因此，我们必须在我们的实现中开发出能够使用低成本FPGA芯片的解决方案</li>
<li>为了解决计算存储驱动器实现成本的挑战，关键是最大化FPGA硬件资源的利用效率。为了实现这一目标，我们跨软件和硬件层进一步开发了以下技术。
<ul>
<li>Hardware-Friendly Data Block Format<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201012201848.png" alt="20201012201848" loading="lazy"></li>
</ul>
</li>
<li>FPGA 并行化<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201012202048.png" alt="20201012202048" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="个人见解">个人见解</h4>
<ul>
<li>因为自己不是做数据库系统的，所以对于背景可能了解的不够，但这不妨碍对 PolarDB 整体结构的理解，个人感觉 PolarDB 对外提供的虽然是简单的关系型数据库服务，但是内部实现了大量的存储系统的工作。虽然本篇是基于 data-intensive 的负载 offload 到计算型存储的角度来组织的，但还是大体能看出 PolarDB 内部复杂的工作细节，以及各个组件都进行了各种软件栈上的优化。PolarDB 本身是一个很大的分布式存储系统，其中的很多小的创新点也基本都是能够组成一个 Paper Idea 的水准，且有工业界的实际实现，经得住实际负载的考验。</li>
<li>抛开本篇论文的主要内容不谈，PolarDB 本身就是一个十分出众的数据库，此处给一些 PolarDB 的整体介绍链接：
<ul>
<li><a href="https://help.aliyun.com/product/58609.html?spm=5176.155538.1357067.3.28ea1a9cb25UNl">阿里云 - PolarDB 帮助文档</a></li>
<li><a href="https://help.aliyun.com/product/58609.html?spm=5176.155538.1357067.3.28ea1a9cb25UNl">知乎 - 如何评价阿里云新一代关系型数据库 PolarDB？</a></li>
<li><a href="https://developer.aliyun.com/article/721566?utm_content=g_1000082241">阿里云 - 读懂POLARDB不能错过的18篇深度文章！</a></li>
<li><a href="https://github.com/AlibabaCloudDocs/polardb">Github PolarDB 官方文档库</a></li>
</ul>
</li>
</ul>
<h2 id="file-systems">File Systems</h2>
<ul>
<li>Read as Needed: Building WiSER, a Flash-Optimized Search Engine
<ul>
<li>Jun He and Kan Wu, University of Wisconsin—Madison; Sudarsun Kannan, Rutgers University; Andrea Arpaci-Dusseau and Remzi Arpaci-Dusseau, University of Wisconsin—Madison</li>
</ul>
</li>
<li>How to Copy Files
<ul>
<li>Yang Zhan, The University of North Carolina at Chapel Hill and Huawei; Alexander Conway, Rutgers University; Yizheng Jiao and Nirjhar Mukherjee, The University of North Carolina at Chapel Hill; Ian Groombridge, Pace University; Michael A. Bender, Stony Brook University; Martin Farach-Colton, Rutgers University; William Jannen, Williams College; Rob Johnson, VMWare Research; Donald E. Porter, The University of North Carolina at Chapel Hill; Jun Yuan, Pace University</li>
</ul>
</li>
</ul>
<h3 id="read-as-needed-building-wiser-a-flash-optimized-search-engine">Read as Needed: Building WiSER, a Flash-Optimized Search Engine</h3>
<ul>
<li>这篇文章是针对现有的搜索引擎进行设计和优化的（以前的研究中很少有针对搜索引擎这类上层应用进行优化的，但随着数据规模的增加，搜索引擎的应用也越来越广泛，尤其是在一些文本检索的领域），搜索引擎本身是一种计算密集型的应用，会有一些读取存储设备的操作，作为一种 &quot;read as needed&quot; 类型的负载，对于存储系统的要求和其他类型的应用负载稍有不同。本文则是实现了一个以相对较少的主存（main memory）提供高吞吐量和低延迟的搜索引擎。</li>
</ul>
<h4 id="简要介绍-3">简要介绍</h4>
<h5 id="背景">背景</h5>
<ul>
<li>
<p>由于本身研究的点不同于以往，所以就按照惯例先介绍了一下这个问题有多关键。此处不表。</p>
</li>
<li>
<p>对于存储系统而言，不管你上层的应用是什么，在存储设备上本质都是数据结构的存取，而搜索引擎和数据库以及图等负载稍有不同，主要使用了倒排索引等结构，又随着 SSD 的普及，所以基于 SSD 的优化方案就比较有搞头。</p>
</li>
<li>
<p>需要注意的是搜索引擎对于存储系统的要求：</p>
<ul>
<li>low data latency：因为搜索引擎的交互性很强，常常需要较低的延迟来保证</li>
<li>high data throughput：因为要处理和检索的数据很多，对于吞吐量的要求也较高</li>
<li>high scalability：因为搜索引擎主要面型文本存储领域，数据规模会随着时间不断地变大，相应地就需要较好的扩展性来提供相应的支持。</li>
</ul>
</li>
<li>
<p>以前的搜索引擎也会面对上述问题，但之前的解决方案都是利用内存作为一种存储介质，由于数据规模较大，为了保证低时延和吞吐量等特性，就常常需要把大量的数据放在内存中（虽然可能会丢，但重建肯定也是一个很大的开销）</p>
</li>
<li>
<p>作者觉得既然现在存储设备已经很快了现在，考虑到对大型数据集使用RAM的成本过高，那么是否可以重新构建一个搜索引擎，以更好地利用 SSD 来实现必要的性能目标，而使用比较少的内存。更明智的做法是重新组织传统的搜索数据结构，以创建和改进读流，从而利用现代 SSD 提供的带宽</p>
</li>
<li>
<p>针对 read as needed 的负载，作者提出了设计理念</p>
<ul>
<li>use small memory</li>
<li>read data from SSDs as needed</li>
<li>do not attempt to cache data in memory</li>
<li>attempt to read data from SSDs efficiently</li>
</ul>
</li>
<li>
<p>分析了现有的搜索引擎，其中 state-of-the-art 的 ElasticSearch。ES 不能实现高性能原因主要是因为读放大，因为 ES 将不同阶段的数据分组到多个位置，并将数据进行排列，使早期的数据项更小。其目的是缓存早期阶段的数据，因为早期阶段的数据要比后期阶段的数据访问得更频繁。然而，按阶段分组数据也可能导致比较大的读放大。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201019204848.png" alt="20201019204848" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201019205209.png" alt="20201019205209" loading="lazy"></p>
</li>
<li>
<p>因为 SSD 本身的一些限制（有限的带宽、高延迟、大IO友好），以及在 ES 中发现的问题，为了实现上述的搜索引擎对于存储系统的要求，就需要</p>
<ul>
<li>reduce read amplification</li>
<li>hide i/o latency</li>
<li>use large request to improve device efficiency</li>
</ul>
</li>
</ul>
<h5 id="design">Design</h5>
<ul>
<li>设计了四个关键技术
<ul>
<li>Grouping data by term
<ul>
<li>即不再采用分阶段存取在不同的文件中的方式进行存储，而是使用连续的压缩的数据块来进行放置，从而将小的读请求转换成了大的读请求<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201019204044.png" alt="20201019204044" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201019205307.png" alt="20201019205307" loading="lazy"></li>
</ul>
</li>
<li>Two-way Cost-aware Bloom Filters
<ul>
<li>针对于 phrase query 的场景，作者使用了两路布隆过滤器来帮助快速检索短语。</li>
<li>设置前后两路匹配的原因，是因为 before 和 after 的查询开销可能不一样，会尝试选择开销更小的那一路的布隆过滤器来进行匹配。但可能存在两路开销都很大的情况，这时候则直接使用默认的原有的短语匹配方式。这也就是所谓的 Cost-aware<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201019210315.png" alt="20201019210315" loading="lazy"></li>
</ul>
</li>
<li>Adaptive Prefetching
<ul>
<li>为了获得最佳性能，预取应该适应查询和持久数据的结构。在倒排索引的所有数据中，最常被访问的数据包括元数据、跳跃表、文档id和词频，这些数据经常被一起顺序访问;<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201019210851.png" alt="20201019210851" loading="lazy"></li>
</ul>
</li>
<li>Trade Disk Space for I/O
<ul>
<li>压缩的粒度和 ES 不同，从而减小读放大，但其实做了 trade-off，压缩后的大小比 ES 压缩后的要大<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201019211333.png" alt="20201019211333" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="个人见解-2">个人见解</h4>
<ul>
<li>这篇其实也不是个人所熟悉的领域，只是因为很早以前自己接触过 ElasticSearch 的应用（ELK 体系那一套），所以对 ES 还是比较感兴趣，这篇文章其实都是在和 ES 对比，可以理解为是对现有的 ES 上的优化，虽然作者指出可以延伸到按需读取场景下的其他负载，但本质还是在搜索引擎的这个领域下的优化。奈何才疏学浅，也就只能总结到这了。</li>
</ul>
<h3 id="how-to-copy-files">How to Copy Files</h3>
<ul>
<li>先放几个链接：
<ul>
<li><a href="https://www.xsky.com/tec/6390/">XSKY解读FAST'20 论文 《关于如何高效率的对文件目录树进行快速克隆操作》</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/151392761">知乎 - BetrFS: 一种写优化的文件系统</a></li>
<li><a href="https://github.com/oscarlab/betrfs">Github - BetrFS</a></li>
<li><a href="http://www.betrfs.org/">betrfs</a></li>
</ul>
</li>
<li>文章从标题开始其实就很吸引眼球，毕竟是一个看着很简单的问题，但是作为论文标题就不禁想让我这种门外汉也要尝试着去看看作者在里面写了些啥我不知道的东西哈哈。走马观花看了看发现嗯自己确实不懂。。</li>
<li>本文其实是做的文件系统领域中关于复制或者克隆操作的优化，现有的很多克隆其实是基于 Copy-On-Write 实现的，但原生的 Copy-On-Write 启发算法有一定的问题，所以作者在这上边也下了很多功夫，提出了 copy-on-abundant-write，基于 BetrFS 实现，除此以外还做了一些别的针对性的优化，复制操作性能提升也比较明显。</li>
</ul>
<h4 id="简要介绍-4">简要介绍</h4>
<h5 id="背景-2">背景</h5>
<ul>
<li>当然首先还是按惯例介绍这个问题多重要，所以就先介绍拷贝操作应用广泛，其实主要体现在备份、快照这些机制中，然后云计算领域中的容器、虚拟机等技术使用拷贝比较频繁。但拷贝本身其实可以分为逻辑拷贝和物理拷贝，从字面上也很好理解，物理拷贝肯定就是物理存储空间上进行完整的拷贝了，时间和空间的消耗可能会因为大文件而特别大，所以很多时候都用逻辑拷贝，也是 volume snapshots 中用的比较多的 Copy-On-Write 写时复制。CoW 可以对块设备进行，也可以在文件系统中对文件或者目录进行，取决于具体的产品实现。譬如 Linux 本身支持的 cp -reflink</li>
<li>引出主题 CoW 之后相应地指出现有的 CoW 的问题：标准的 CoW 本身其实是在写放大和局部性之间做了 trade-off。即 CoW 的粒度大小的设定将影响这两方面的表现。
<ul>
<li>如果粒度为文件的大小，那么对文件的小写操作带来的写放大就很严重，相应的写延迟也就增加了，空间也被浪费了（因为共享的数据被写操作给破坏了）</li>
<li>如果粒度很小，更新操作很快，但是容易产生碎片，顺序读副本的开销就变大了，因为局部性被破坏了。</li>
</ul>
</li>
<li>想要实现的效果，也就是文中作者描述为 Nimble clones 的复制操作应该是这样的：（那肯定现有的文件系统里的 CoW 实现就不是 nimble 的，文中有测试）
<ul>
<li>be fast to create</li>
<li>have excellent read locality</li>
<li>have fast writes</li>
<li>conserve space</li>
</ul>
</li>
<li>总结下来问题其实出在对克隆的写操作粒度与共享数据副本的粒度这两点，其实就是对于文件小写，不能直接就将源文件拷贝重写了，要设定一个相对大的 copy size 来保证局部性，即得 buffer 小写。所以就得把对克隆的写操作和副本的相关操作解耦。所以作者选了 BetrFS 来实现自己的方案。毕竟 BetrFS 以写见长，也有一些自己的 buffer 机制，当然主要还是测试出来的，文中的一个关于性能降级的测试。</li>
</ul>
<h5 id="design-2">Design</h5>
<ul>
<li>需要首先理解一下 btrfs 的原理和其中的数据结构 Bε-tree。
<ul>
<li>btrfs 基于 KV 来管理文件系统中的数据，元数据 KV 存储的是 文件全路径 Full Path 到文件系统元数据的映射，数据 KV 存储的是 {fullpath + block number} 到 block的映射。</li>
<li>Bε-tree 可以简单理解为一个带 buffer 缓冲的 B-tree，主要吸收随机小写。</li>
</ul>
</li>
<li>在 Bε-tree 基础上实现逻辑拷贝，即 Bε-DAG。在树中增加新的边 edge，以使得在访问克隆后的文件夹时，能通过某种方法访问克隆前的数据（克隆后的数据在不修改内容前，都是完全共享的），通过使用 DAG （有向无环图）的思想来支持共享访问，对应地需要实现一层如图所示的转换 red-&gt;green<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201029153451.png" alt="20201029153451" loading="lazy"></li>
<li>对于此时的写操作，则需要在 flush 的时候执行 copy-on-write，分为五个步骤执行： Copy-on-Abundant-Write
<ul>
<li>第一步，copy 该节点</li>
<li>第二步，转换文件对应的路径前缀（图中的 green-&gt;red）</li>
<li>第三步，删除无法到达的数据，图示中的蓝色 L，因为拷贝之后没有 blue 上层目录，即在该路径上该文件再也无法访问到，故可以删除</li>
<li>第四步，移动地址转换功能，即把原本的上一层的 red-&gt;green 移动到下一层（因为复制后的节点有一些数据为目录，如图中所示的 A 和 R，故需要指向底层文件，如果 flush 操作针对更底层的文件，那么再相应递归地执行 copy-on-write）</li>
<li>第五步，将数据刷入到复制后的节点中作为新的 buffer（即吸收小写）</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201029155112.png" alt="20201029155112" loading="lazy"></figure>
<ul>
<li>因为 Bε-DAG 中的节点本身比较大，即可以吸收小写，且局部性比较好，所以在读写上表现都很不错，又因为采用了新的上文描述的 Copy-on-Abundant-Write 在空间上的利用率也很高，但还有一个问题没有解决，即拷贝延迟</li>
<li>作者实现了一种称之为 GOTO Message 的机制，用于减小 Copy 操作的延迟。存储的数据大致如 (a,b) - height - dst_node，其中 （a,b）为拷贝操作覆盖的 key 空间/范围，height 表示要拷贝的目标节点的高度，dst_node 表示要拷贝的目标节点。</li>
<li>如果要进行拷贝操作，如图所示，拷贝 /green 到 /violet，那么相应地会先触发 green 的 flush，确保数据一致，然后插入一条 GOTO Message。</li>
<li>查询操作首先查询到了 GOTO Message，那么首先判断 key 是否在相应的区间中，如果在那么就要去 dst_node 处继续查找，相应地会进行前缀转换，直到找到该数据。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201029160655.png" alt="20201029160655" loading="lazy"></li>
<li>相应的 GOTO message 可以和其他数据一样，通过 flush 操作进入下一层，如下图所示，直到 GOTO Message 到达了目标节点高度 + 1 的层级的时候，GOTO Message 就此时可以成为一个真正的指向下一层的目录，也就是文中的 pivot，即 GOTO 将变成紫色的目录节点 /violet</li>
<li>这样子下来拷贝的时间复杂度完全取决于树的高度<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201029161740.png" alt="20201029161740" loading="lazy"></li>
</ul>
<h4 id="个人见解-3">个人见解</h4>
<ul>
<li>这篇呢个人也只是泛泛而谈，主要参考了 PPT 的动画解释，原文其实还涉及到了更为具体的实际的解释，由于重心不在这边所以没有细看，感兴趣的小伙伴可以再深入研究，但是在研究之前最好先大致看一下之前的 btrfs 的论文，至少了解到核心数据结构的设计和读写的流程，才有助于对本篇文章的理解。</li>
<li>想提一下的是，我发现 btrfs 相关的论文已经上了很多次 FAST 以及 TOS 了，而且本身这个文件系统提出来也没几年，FAST15 上提出来的，后续的一些对于该文件系统的迭代都直接被拿来作为了新的 idea，譬如本篇实现的 clone，其实做文件系统同学可以关注一下这个文件系统，我自己简单看了这个文件系统的数据结构之后理解为他其实是在利用 B-Tree 和 LSM-tree 各自的优势，当然主要还是解决 B-Tree 的写的问题，后续如果有相关的工作的话可能会关注一下。</li>
</ul>
<h2 id="ssd-and-reliability">SSD and Reliability</h2>
<ul>
<li>A Study of SSD Reliability in Large Scale Enterprise Storage Deployments
<ul>
<li>Stathis Maneas and Kaveh Mahdaviani, University of Toronto; Tim Emami, NetApp; Bianca Schroeder, University of Toronto</li>
<li><strong>Awarded Best Paper!</strong></li>
</ul>
</li>
<li>Making Disk Failure Predictions SMARTer!
<ul>
<li>Sidi Lu and Bing Luo, Wayne State University; Tirthak Patel, Northeastern University; Yongtao Yao, Wayne State University; Devesh Tiwari, Northeastern University; Weisong Shi, Wayne State University</li>
</ul>
</li>
</ul>
<h3 id="a-study-of-ssd-reliability-in-large-scale-enterprise-storage-deployments">A Study of SSD Reliability in Large Scale Enterprise Storage Deployments</h3>
<ul>
<li>虽然是 SSD 硬件相关的，但毕竟是 BestPaper，而且这篇其实更像是针对一些数据集的分析，不是具体的基于硬件或者协议的优化，想了想决定还是大概看看吧，万一之后有所涉及。</li>
<li>按照惯例放个链接：
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/111808111">CobbLiu - FAST20论文赏析（二）</a></li>
</ul>
</li>
<li>本文首次对企业存储系统中基于 NAND 的 SSD 进行了大规模的现场研究(与分布式数据中心存储系统中的驱动器形成对比)。该研究基于一组非常全面的现场数据，涵盖了一家主要存储供应商(NetApp)的 140 万份 SSD。驱动器包括三个不同的制造商，18种不同的型号，12种不同的容量，和所有主要的闪存技术(SLC, cMLC - consumer-class, eMLC - enterprise-class, 3D-TLC)。这些数据使我们能够研究很多之前没有研究过的因素，包括固件版本的影响，TLC NAND的可靠性，以及RAID系统中驱动器之间的相关性（为这些驱动器收集的数据非常丰富，包括驱动器替换(包括替换的原因)、坏块、使用情况、驱动器年龄、固件版本、驱动器角色(例如，数据、奇偶校验或备用)等信息）。本文介绍了我们的分析，以及由此得出的一些实际影响。</li>
</ul>
<h4 id="简要介绍-5">简要介绍</h4>
<h5 id="背景-3">背景</h5>
<ul>
<li>以前的存储设备的可靠性研究大多基于 HDD，近年来随着 SSD 的普及，对于 SSD 的可靠性研究才不断出现。现有的 SSD 可靠性研究除了在实验室的控制条件下的的相关研究以外，还有来自如 Facebook, Microsoft, Google, and Alibaba 等大型公司基于自己的数据中心中的数据对 SSD 可靠性的分析。但作者发现现有的研究中还是有一些 critical gap，所以本文就来填坑了：
<ul>
<li>没有研究关注企业级存储系统，这些系统中的驱动器、工作负载和可靠性机制可能与云数据中心中的非常不同。比如企业级存储系统中通常使用高端 SSD 并且可靠性通常由 RAID 来保障，而不是分布式存储中的那些副本的一些策略。</li>
<li>现有的研究没有涵盖构建现实的故障模型所需的一些最重要的故障特征，以便计算数据丢失的平均时间等指标，例如，这包括对驱动器替换原因的分析，包括底层问题的范围和相应的修复操作(RAID重建与耗尽驱动器)，以及最重要的是对同一RAID组中驱动器之间的相关性的理解。</li>
</ul>
</li>
</ul>
<h5 id="数据统计分析">数据统计分析</h5>
<ul>
<li>采集的系统和数据对应的相关信息此处不表，直接看相关数据统计。
<ul>
<li>前六列描述了不同厂商对应不同系列的 SSD 的相关参数，包括匿名给出了制造商、容量、接口、闪存颗粒技术、光刻技术、PE 周期（寿命）</li>
<li>后四列描述了不同的 SSD 被用于了何种的环境，包括 OP 比例（用于垃圾回收的保留空间比例）、第一次部署使用该 SSD 的日期、SSD 通电的中位数年数（因为每类 SSD 对应了很多个实际的 SSD）、SSD 的额定使用寿命的平均值和中位数（SSD 所经历的 PE 循环数占其 PE 循环极限的百分比）</li>
<li>最后三列描述了三种不同的 SSD 健康性和可靠性的指标：空闲块的使用比例、坏的扇区的数量、每年的置换率<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201103164701.png" alt="20201103164701" loading="lazy"></li>
</ul>
</li>
<li>从上表中的相关数据统计得出以下结论：
<ul>
<li>平均 ARR 为 0.22%，在 0.07% 到 1.2% 之间波动，比数据中心中的故障率要低得多</li>
<li>即便是具有相同工艺的同厂商的 SSD，相似容量和相似使用期限，年故障率也非常不一样</li>
<li>为坏块保留的备用区域为典型的驱动器提供了大量的资源：即使对于已经在数据中心中存放了好几年的 SSD，使用的备用块的百分比平均也不到 15%。即便是第 99.9 和 第 99.99 使用空闲空间最多的盘都分别为 17% 和 33%</li>
<li>很多 SSD 都没达到 PE 限制，即便是使用了 2-3 年的 SSD，第 99.9 和 第 99.99 寿命消耗的也只消耗了 15% 和 33%，对于绝大多数 SSD 盘来说，因为达到最大可擦写次数而失效的可能性几乎为零。</li>
</ul>
</li>
</ul>
<h5 id="原因分析">原因分析</h5>
<ul>
<li>有不同的原因可以触发更换 SSD，存储层次结构中的不同子系统也可以检测具体触发更换 SSD 的原因。可能由 SSD 本身或者存储层或者文件系统报告相应的问题，如下表所示描述了可能触发更换 SSD 的原因，以及它们的频率，以及系统采取的恢复操作(例如，从要替换的 SSD 复制数据与使用 RAID 重新构建数据)，以及问题的范围(例如，部分数据丢失的风险，完整驱动器丢失的风险，或者没有立即的问题)</li>
<li>原因被大致分为 4 类，分别以 ABCD 表示，严重程度递减。
<ul>
<li>最无关紧要的是 D 类，通常是由 SSD 内部或者更高的存储层在逻辑上触发的，即一些预测 SSD 未来故障的策略，基于之前发生的错误、超时以及磁盘的 SMART 统计信息等，但实际可能没坏。</li>
<li>最严重的是 A 类，通常是因为 SSD 变得完全无法响应，或者 SCSI 层检测到了 SSD 的问题严重到需要立即更换 SSD 并重建构建在当前 SSD 上的 RAID 时。</li>
<li>B 类是指替换发生在当系统怀疑 SSD 丢失了写操作的时候，例如 SSD 根本没有执行写操作，或者将其写到错误的位置，或者以其他方式破坏了写操作，根本原因可能是 SSD 中的固件错误，尽管存储堆栈中的其他层也可能是原因。由于有许多潜在的原因，heuristic（启发式判断） 被用来决定是否触发替换;具体地说，如果一个 SSD 中出现了多个这样的错误，而其他 SSD 中没有错误，那么前一个 SSD 将被替换。</li>
<li>C 类通常是因为命令被丢弃或者执行超时。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201103214752.png" alt="20201103214752" loading="lazy"></li>
</ul>
</li>
<li>抛开所有的分类看具体的错误原因，我们不难发现最常见的错误是 SCSI errors，大约有 1/3 的替换都是因为 SCSI errors 发生，同时也是最严重的错误之一；还有大约 1/3 的替换仅仅是为了预防 SSD 故障才采取的，也就是 D 类错误，预测了磁盘故障可能带来的严重影响，预测性的替换通常是统计了超时次数判断是否达到了阈值</li>
<li>后续测试了不同的因素对 SSD 的 annual replacement rate 的影响，主要对 eMLC 和 3D-TLC SSD 进行了分析，得出了以下发现和结论：
<ul>
<li>盘在刚开始使用的 1 年内的 ARR 是 1 年后 ARR 的 2-3 倍，并且盘片的 ARR 并没有随着使用时间的增加而增加，部分原因可能是因为绝大部分盘片的擦写次数都远没达到总擦写次数。</li>
<li>3D-TLC SSD 比其他类型的有更高的 ARR，但是这个差别很小，SLC、MLC 和 TLC（不同 flash 和 drive） 对 ARR 的影响比使用率对 ARR 的影响更小。</li>
<li>大容量 SSD 不仅整体替换率更高，而且 A 类错误概率更高，可预测的错误概率更低。</li>
<li>更高密度的 SSD 并不总是看到更高的替代率 ARR。事实上，我们观察到，尽管更高密度的 eMLC SSD 有更高的替代率，但这一趋势在 TLC 中是相反的</li>
<li>早期的固件版本可能与较高的替换率相关，这就强调了固件更新的重要性。</li>
<li>具有非空缺陷列表的 SSD 被替换的几率更高，不仅是因为可预测的故障，还因为其他替换原因</li>
<li>更多地使用其 OP 空间的 SSD 很可能在将来被替换</li>
<li>虽然大型 RAID 组有更多的驱动器替换，但我们没有发现每个组的多次故障率(这可能导致数据丢失)与 RAID 组大小相关的证据。原因似乎是在第一次失败后出现后续失败的可能性与 RAID 组大小无关</li>
</ul>
</li>
<li>最终作者总结了一下：
<ul>
<li>早期的固件版本可能与较高的故障率相关，所以得及时更新固件，要保证升级过程无痛且稳定</li>
<li>RAID 组的大小对 SSD 盘的平均 ARR 没有明显的影响</li>
<li>单奇偶校验 RAID 配置(例如，RAID-5)，可能容易发生数据丢失，而实际的数据丢失分析肯定必须考虑相关的故障。</li>
<li>具有非常大容量的驱动器总的故障率更高，出现更严重的故障。较高的故障率可能源于 SSD 上的更多 NAND 和die，这就强调了 SSD 及其系统能够处理部分驱动器故障(如 die 故障)的重要性，NetApp 正朝着这个方向努力，通过从 OP 区域来弥补部分故障的区域带来的容量损失</li>
<li>我们观察到，大容量的 SSD 预测失败率更小，这也提出了一个问题，即大容量 SSD 是否需要不同类型的故障预测器，以及是否需要更多来自 SSD 的内部问题(例如，坏死或 DRAM 问题)作为输入</li>
<li>随着 QLC NAND 的引入，人们重新开始关注 NAND SSD 的可靠性，其 PE 循环限制明显低于当前 TLC NAND。根据我们的数据，我们预测，对于绝大多数企业用户来说，向 QLC 的 PE 周期限制迈进不会带来任何风险，因为 99% 的系统最多使用其驱动器额定寿命的 15%</li>
<li>人们担心 NAND 有限的 PE 周期在 RAID 系统生命周期的后期，由于相关的磨损故障，SSD 可能会对数据的可靠性造成威胁，因为 RAID 组中的驱动器老化速度相同。相反，我们观察到，早期失效导致的相关失败可能是一个更大的威胁。例如，在我们的研究中，3D-TLC 驱动器，早期失效率高峰时的失败率比后期高出 2.5 倍</li>
<li>在选择 SSD 时，比起 flash type（比如 eMLC 还是 3D-TLC），工艺和容量更应该是首要的考量因素。</li>
</ul>
</li>
</ul>
<h4 id="个人见解-4">个人见解</h4>
<ul>
<li>这篇算是分析了 SSD 的一些物理特性和参数和 SSD 的故障之间的关系，以及 SSD 的替换策略的关系，但是文章开始的部分其实限定了场景为企业级存储，我个人对于企业级存储和如阿里等互联网企业的数据中心的存储这两种场景之间的差异其实不太具体理解，而且从 SSD 本身而言，这两种场景下，关于 SSD 的经验仿佛是通用的？这里有点一知半解</li>
<li>确实本篇文章有大量的数据支撑，最重要的其实都是文章总结出的那些发现，有的发现确实也一定程度上颠覆了以前大家对于 SSD 故障原因的一些固有认知，但可能缺少一些更为合理的解释？也可能是自己水平有限，对于相关成因的解释看的一知半解。</li>
</ul>
<h3 id="making-disk-failure-predictions-smarter">Making Disk Failure Predictions SMARTer!</h3>
<ul>
<li>这篇文章针对的领域是磁盘故障预测，之前有博客简要介绍过这篇文章，这篇文章的实验做的非常充分，整个行文也比较行云流水，照例贴一下链接：
<ul>
<li><a href="https://blog.shunzi.tech/post/AI-for-Systems-index/">shunzi - AI For System Papers Index</a></li>
<li><a href="https://nbjl.nankai.edu.cn/2020/0506/c12124a271163/page.htm">NBJL 2020论文导读24：Making Disk Failure Predictions SMARTer!</a></li>
</ul>
</li>
<li>磁盘驱动器是最常被替换的硬件组件之一，它继续对准确的故障预测提出挑战。在这项工作中，我们提出了一个最大的磁盘故障预测研究之一的分析和发现，涵盖了一个大型领先数据中心运营商的64个站点在两个月的时间里总共380,000个硬盘驱动器。我们提出的基于机器学习的模型在10天的预测周期内平均用0.95 F-measure和0.95 Matthews相关系数(MCC)预测磁盘故障</li>
<li>本篇文章就不展开介绍了，解决的其实就还是磁盘故障预测中的准确率低的问题和提前预警的时间较短的问题，而作者在磁盘故障预测的相关机器学习模型中引入了性能和物理位置条件的指标使得磁盘故障的预测模型更为准确，提前预警的时间也大约提升到了 10 天预警。</li>
<li>文章写的很清楚明朗，如果对磁盘故障预测感兴趣的同学，该文值得深入阅读。</li>
</ul>
<h2 id="performance">Performance</h2>
<ul>
<li>An Empirical Guide to the Behavior and Use of Scalable Persistent Memory
<ul>
<li>Jian Yang, Juno Kim, and Morteza Hoseinzadeh, UC San Diego; Joseph Izraelevitz, University of Colorado, Boulder; Steve Swanson, UC San Diego</li>
</ul>
</li>
</ul>
<h3 id="an-empirical-guide-to-the-behavior-and-use-of-scalable-persistent-memory">An Empirical Guide to the Behavior and Use of Scalable Persistent Memory</h3>
<ul>
<li>关于这篇就不再详细展开了，资料很多，贴几个典型的其他大佬的资料。做 NVM 的肯定是都会看的 8。
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/108671363">zhihu: 暗淡了乌云 - An Empirical Guide For 3D XPoint Persistent Memory</a></li>
<li><a href="https://developer.aliyun.com/article/770338">阿里云开发者社区：Intel PMEM的使用经验和指南</a></li>
</ul>
</li>
<li>整体:<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200828104859.png" alt="20200828104859" loading="lazy"></li>
<li>内存控制器和硬件交互细节： 对NVDIMM的访问首先到达DIMM上的控制器（本文中称为XPController），该控制器协调对Optane介质的访问。与SSD相似，Optane DIMM执行内部地址转换以实现损耗均衡和坏块管理，并为该转换维护AIT (address indirection table)。地址转换后，将实际访问存储介质。由于3D-XPoint物理介质的访问粒度为256B（文中称为XPLine），所以，XPController会将较小的请求转换为较大的256字节的访问以提升性能。然而，因为同样的原因，小数据量的存储会变为RMW（read-modify-write）操作而导致写放大。 XPController有一个小的写合并缓冲区（在本文中称为XPBuffer），用于合并地址相邻的写操作。 由于XPBuffer属于ADR域，因此到达XPBuffer的所有更新都是持久的。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201116111320.png" alt="20201116111320" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200828113725.png" alt="20200828113725" loading="lazy"></li>
<li>文章通过介绍 Optane PM 以及做了相关的测试得出了几个 Best Practice
<ul>
<li><strong>避免小于 256B 的随机读写</strong>；
<ul>
<li>Optane 的数据更新，在内部介质会进行 read-modify-write 操作。若更新的数据量小于内部操作的数据粒度（256B），会带来写放大，而使得更新效率低。</li>
<li>EWR（Effective Write Ratio，由DIMM的硬件测量）的概念：其为iMC发出的字节数除以实际写入3D-XPoint介质的字节数，即为写放大的倒数。EWR小于1表示，Optane介质写效率低。EWR也可以大于1，此时表示XP-Buffer做了写合并（在内存模式中，因为DRAM的缓存作用，EWR也可以大于1）</li>
<li>展示了Optane DIMM的带宽（三种store命令）与EWR的正相关的关系。一般而言，小数据量的存储使得EWR小于1。 例如，当使用单个线程执行随机的ntstore时，对于64字节的写，EWR为0.25，对于256字节访问，其EWR为0.98。值得注意的是，虽然iMC仅以64B为单位访问DIMM，但是XPBuffer可以将多个64B的写进行缓存，并合并为256B的Optane内部写，所以256字节更新是高效的。由上可知，如果Optane DIMM的访问具有足够好的局部性，同样可以高效地进行小数据量的存储。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201116112306.png" alt="20201116112306" loading="lazy"></li>
<li>为了得到“怎样的局部性才足够”的命题结论，我们设计了一个实验来测量XPBuffer的大小。 首先，我们分配N个XPLine大小（256B）的连续区域。 在实验中，进行循环的写数据。首先，依次更新每个XPLine的前半部分（128 B）， 然后再更新每个XPLine的后半部分。 我们测量每一轮后EWR的值。 图9显示： N 小于64（即16 kB的区域大小）时，EWR接近于1，其表明，后半部分的访问命中了XPBuffer。 N 大于64时，写放大进行了突变，其由XPBuffer miss急剧上升导致。这表明，XPBuffer的大小为16KB。进一步的实验表明，读操作也会占用XPBuffer中的空间从而造成竞争关系。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201116104322.png" alt="20201116104322" loading="lazy"></li>
</ul>
</li>
<li><strong>使用ntstore进行大数据（大于256B）写</strong>
<ul>
<li>一般通过下面操作进行数据写入：store操作后，程序员可以通过clflush/clflushopt操作进行高速缓存evict或通过clwb操作进行写回（write back)，以将数据写入至ADR域并最终写至Optane DIMM；或者，通过ntstore指令绕过高速缓存直接写入Optane DIMM。在进行完上述某种操作后，再进行sfence操作可确保先前的evict，write back和ntstore操作的数据变成持久的。写数据时，采用上述何种操作对性能影响很大。</li>
<li>对于写超过 64B 的数据，每store 64B进行cache的flush操作(相比于不进行flush操作）获得的带宽会更大</li>
<li>对于超过 512B 的访问，ntstore的延迟比store + clwb更低</li>
<li>对于超过 256B 的访问，ntstore操作的带宽也最高</li>
<li>当写入的大小超过 8MB时，写入后再进行刷新操作会导致性能下降，因为其导致了高速缓存容量的失效，从而使得EWR升高</li>
</ul>
</li>
<li><strong>限制访问 Optane DIMM 的并发线程数</strong>
<ul>
<li>XPBuffer的竞争。对XPBuffer中缓存空间的争用将导致逐出次数增加，触发写3D-XPoint介质，这将使EWR降低。</li>
<li>iMC中的竞争。每个线程随机访问N个DIMM（线程间分布均匀）。随着N的增加，针对每个DIMM的写入次数会增加，但是每个DIMM的带宽会下降。</li>
<li>当对交错的Optane DIMM进行随机 4KB 访问时，Optane带宽急剧下降。当写入的数据大小为 24kB 和 48kB，出现了性能的小峰值，其访问在6个DIMM上完美分布。</li>
</ul>
</li>
<li>避免 NUMA 访问（尤其对于是 read-modify-write 操作序列）。
<ul>
<li>Optane的NUMA效应远大于DRAM，因此应更加努力地避免跨插槽的存储器通信。对于读写混合且包含多线程访问的情况，其成本特别高。</li>
<li>对于本地和远程访问，单线程带宽差距不大。而对于多线程访问，随着访问压力的提高，远程访问性能会更快下降，从而导致相对于本地访问而言性能较低。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="key-value-storage">Key Value Storage</h2>
<ul>
<li>Characterizing, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook
<ul>
<li>Zhichao Cao, University of Minnesota, Twin Cities, and Facebook; Siying Dong and Sagar Vemuri, Facebook; David H.C. Du, University of Minnesota, Twin Cities</li>
</ul>
</li>
<li>FPGA-Accelerated Compactions for LSM-based Key-Value Store
<ul>
<li>Teng Zhang, Alibaba Group, Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University; Jianying Wang, Xuntao Cheng, and Hao Xu, Alibaba Group; Nanlong Yu, Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University; Gui Huang, Tieying Zhang, Dengcheng He, Feifei Li, and Wei Cao, Alibaba Group; Zhongdong Huang and Jianling Sun, Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University</li>
</ul>
</li>
<li>HotRing: A Hotspot-Aware In-Memory Key-Value Store
<ul>
<li>Jiqiang Chen, Liang Chen, Sheng Wang, Guoyun Zhu, Yuanyuan Sun, Huan Liu, and Feifei Li, Alibaba Group</li>
</ul>
</li>
</ul>
<h3 id="characterizing-modeling-and-benchmarking-rocksdb-key-value-workloads-at-facebook">Characterizing, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook</h3>
<ul>
<li>这篇文章可能和其他文章都有所不同，主要做 Benchmarking 方面的工作，和 Facebook 合作完成，对 Facebook 中现有的 RocksDB 典型的应用场景进行了表征，同时提出了一种新的更接近实际生产环境负载的模型考虑来取代 YCSB。照例先贴几个链接：
<ul>
<li><a href="https://jiangyuhang17.github.io/2020/07/16/FAST20-RocksDBBenchmark/">jiangyuhang17. - Characterizing, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook 论文笔记</a></li>
<li><a href="https://www.pianshen.com/article/61721875389/">程序员大本营 - 【论文阅读】Characterizing, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook</a></li>
</ul>
</li>
<li>持久化的键值存储是现代 IT 基础设施的基石，但是现有的表征 KV 存储的真是工作负载的研究有一定的局限，主要因为缺乏跟踪/分析工具以及在操作环境中收集跟踪的困难。本文对Facebook上三个典型的RocksDB生产用例的工作负载进行了详细表征:
<ul>
<li>UDB：用于MySQL中用来存储社交图数据，使用RocksDB作为底层存储；</li>
<li>ZippyDB：用于存储分布式对象存储的元数据的分布式KV；</li>
<li>UP2X：用于存储AI/ML数据的分布式KV。</li>
</ul>
</li>
<li>通过分析以上三种应用，有以下发现：
<ul>
<li>键和值大小的分布与用例/应用程序高度相关</li>
<li>KV 对的访问具有良好的局部性，并遵循一定的特殊模式</li>
<li>收集的性能指标在 UDB 中显示强烈的昼夜变化模式，而其他两个没有</li>
</ul>
</li>
<li>除此以外，作者表明现如今被广泛应用的 KV 负载 YCSB 尽管提供了各种工作负载的配置和 KV 对访问分布模型，但是忽视了键的空间局部性，和实际生产环境中的工作负载还是有一定的差距，于是本文提出了一种基于键范围的工作负载，并开发了一个可以更好地模拟真实键值存储的工作负载的基准。</li>
</ul>
<h4 id="简要介绍-6">简要介绍</h4>
<h5 id="introduction-background">Introduction &amp; Background</h5>
<ul>
<li>首先描述工作的意义，主要是解决现如今提升 KV 存储的性能比较困难，原因主要表现在：
<ul>
<li>对KVstores的真实工作负载表征和分析的研究非常有限，KV-stores的性能与应用程序生成的工作负载高度相关</li>
<li>描述KV-store工作负载的分析方法与现有的块存储或文件系统的工作负载特性研究不同（语义不同）</li>
<li>在评估KV-store的底层存储系统时，我们不知道KV-store基准生成的工作负载是否能代表真实的KV-store工作负载</li>
</ul>
</li>
<li>为了解决上面的问题，本文主要就做了三方面的事情：对 RocksDB 的 workload 进行 characterize, model, and benchmark
<ul>
<li>引入了一系列工具，可以在生产环境中应用，主要是收集 KV 层的查询 traces，replay traces 和分析 traces。且已开源：https://github.com/facebook/rocksdb/wiki/RocksDB-Trace%2C-Replay%2C-Analyzer%2C-and-Workload-Generation</li>
<li>为了更好地了解KV工作负载及其与应用程序之间的关系，分析了 UDB， ZippyDB，UP2X，有以下发现：
<ul>
<li>UDB 和 ZippyDB 中的查询主要是 read，而 UP2X 中的主要查询类型是 read-modify-write (Merge)</li>
<li>由于上层应用程序的键组合设计，键大小通常较小且分布狭窄，大的值大小只在某些特殊情况下出现</li>
<li>大多数 KV 对是冷的(访问较少)，只有一小部分 KV 对经常被访问</li>
<li>Get, Put, and Iterator 都有很强的针对基于键的空间局部性（比如经常访问的 KV 对通常在空间的分布上也相对较近），与上层应用程序的请求局部性密切相关的一些键范围非常热（经常被访问）</li>
<li>UDB 中的访问显式地表现为昼夜模式</li>
</ul>
</li>
<li>发现尽管 YCSB 可以生成与 ZippyDB 工作负载类似的键值(KV)查询统计数据，但 RocksDB 存储 I/Os 可能会有很大的不同，这个问题主要是由 YCSB 生成的工作负载忽略键的空间局部性这一事实引起的。YCSB 中热的键值对可以在整个键空间中随机分配，也可以聚集在一起，这将导致存储中访问的数据块与与 KV 查询相关的数据块之间的 I/O 不匹配。在不考虑键空间局部性的情况下，基准测试生成的工作负载将导致 RocksDB 的读放大和写放大比实际工作负载大。于是作者提出了一种基于键范围的热度的工作负载建模方法。整个键空间被划分为较小的键范围，并且我们对这些较小的键范围的热度进行建模。在新的基准测试中，将根据键范围热度的分布将查询分配给键范围，并且在每个键范围中热键将被紧密地分配。</li>
</ul>
</li>
<li>RockDB 介绍：相比于普通的 LSM Tree 或 LevelDB，从架构上来看主要是多了一个 Column Family 的概念<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201116170504.png" alt="20201116170504" loading="lazy"></li>
<li>三种应用场景介绍：
<ul>
<li>UDB：Facebook 的社交图数据长期存储在UDB中，这是一个分片 MySQL 数据库层。UDB 依赖 MySQL 实例来处理所有的查询，查询会被 MyRocks 转换成对于 RocksDB 的查询。图数据主要被维护成点和边，相应地在 RocksDB 中使用了不同的列族来存储对应的数据。收集了 14 天的 traces，也单独分析了最后一天 24 小时的负载
<ul>
<li>Object，Assoc，Assoc_count，Object_2ry，Assoc_2ry和Non_SG</li>
</ul>
</li>
<li>ZippyDB：基于 RocksDB 的分布式 KV 存储，使用 Paxos 来保证数据一致性和可靠性。KV 对被划分为切片，每个切片由一个 RocksDB 实例支持。选择一个副本作为主切片，其他副本作为次要切片。主切片处理对某个切片的所有写操作。如果读取需要强一致性，则读取请求(如 Get 和 Scan )仅由主切片处理。一个 ZippyDB 查询被转换为一组RocksDB 查询(一个或多个)。</li>
<li>UP2X：Facebook 使用各种 AI/ML 服务支持社交网络，并使用大量动态变化的数据集(如用户活动统计计数器)进行AI/ML预测和推断。UP2X 是分布式的专门开发的 KV-store，用于将这种类型的数据存储为 KV 对。当用户使用 Facebook 服务时，UP2X 中的 KV 对会经常更新，例如计数器增加时。如果 UP2X 在每个 Put 之前调用 Get 来实现读-修改-写操作，由于随机 Get 的速度相对较慢，它将产生很高的开销。UP2X 利用 RocksDB Merge 接口避免在更新过程中获取 Gets。</li>
</ul>
</li>
</ul>
<h5 id="methodology-and-tool-set">Methodology and Tool Set</h5>
<ul>
<li>开源的 RocksDB 负载分析和表征工具 https://github.com/facebook/rocksdb/wiki/RocksDB-Trace%2C-Replay%2C-Analyzer%2C-and-Workload-Generation</li>
<li><strong>Tracing</strong>：工具收集 RocksDB 对外暴露的开放接口对应的查询信息，并将信息记录在 trace files 中。主要包括 query type、CF ID、key、query specific data、timestamp。对于 Put 和 Merge，将值信息存储在特定于查询的数据中，对于 Seek 和 SeekForPrev 之类的迭代器查询，扫描长度(在 Seek 或 SeekForPrev 之后调用 Next 或 Prev 的次数)存储在特定于查询的数据中。为了在跟踪文件中记录每个查询的跟踪记录，需要使用锁来序列化所有查询，这可能会带来一些性能开销，但是，根据常规生产工作负载下的生产中的性能监视统计数据，我们没有观察到跟踪工具导致的吞吐量下降或延迟增加。</li>
<li><strong>Trace Replaying</strong>：回放工具根据跟踪记录信息向 RocksDB 发出查询，查询之间的时间间隔遵循跟踪中的时间戳，通过设置不同的快进和多线程参数，RocksDB 可以对不同强度的工作负载进行基准测试。但是，多线程不能保证查询顺序。Replayer 生成的工作负载可以看作是真实世界的工作负载。</li>
<li><strong>Trace Analyzing</strong>：由于工作负载跟踪的潜在性能开销，很难跟踪大规模和长时间的工作负载，此外，跟踪文件的内容对其用户/所有者来说是敏感和机密的，因此，RocksDB 用户很难与其他 RocksDB 开发人员或第三方公司的开发人员共享跟踪信息。为了解决这些限制，我们提出了一种分析 RocksDB 工作负载的方法，该方法根据跟踪中的信息来分析工作负载。
<ul>
<li>针对每一个 CF 中的 KV 对、query numbers、query types 的详细统计摘要</li>
<li>key value 大小统计</li>
<li>kv 对的流行度（热度）</li>
<li>键的空间局部性，它将访问的键与数据库中所有现有的键按排序顺序组合在一起</li>
<li>查询次数/秒 统计</li>
</ul>
</li>
<li><strong>Modeling and Benchmarking</strong>：首先选定两个变量计算对应的相关系数，来确定变量相关性较低。通过这种方式，每个变量都可以单独建模，然后我们将收集到的工作负载匹配到不同的统计模型中，以找出哪一个具有最低的拟合误差，哪一个比总是将不同的工作负载匹配到相同的模型(如Zipfian)更精确。然后，该基准可以基于这些概率模型生成KV查询。</li>
</ul>
<h5 id="general-statistics-of-workloads">General Statistics of Workloads</h5>
<ul>
<li>我们将介绍每个用例的一般工作负载统计，包括每个 CF 中的查询组合，KV-pair 热度分布和每秒查询数。</li>
<li><strong>Query Composition</strong>：Get 是 UDB 和 ZippyDB 中最常用的查询类型，而 Merge 在 UP2X 查询中占主导地位。在不同的 CF 中查询组合可能都会有很大不同，
<ul>
<li>如下图所示 UDB 的统计<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201117092355.png" alt="20201117092355" loading="lazy"></li>
<li>ZippyDB 只有一个 CF，Get : Put : Delete : Iterator = 78 : 13 : 6 : 3</li>
<li>UP2X Merge : Get : Put = 92.53 : 7.46 : 0.01</li>
</ul>
</li>
<li><strong>KV-Pair Hotness Distribution</strong>：UDB 和 ZippyDB 中大部分 KV 数据是冷数据
<ul>
<li>UDB 24 小时内访问的 key 最高不超过 3%，而 14 天内访问的 key 最高不超过 15%。如下为 UDB 的 Get 与 Put 操作的 KV 数据访问的 CDF 图。对于 Get，除了 Assoc 之外，其他 CF 的数据 60% 或者以上的数据都只被访问了一次。对于 Put，超过 75% 的数据都只被访问一次，Put 次数超过 10 的数据仅占不到2%，所以UDB中的KV数据大部分很少被Update。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201117093340.png" alt="20201117093340" loading="lazy"></li>
<li>对于ZippyDB，大约80%的key只被访问一次，1%的key被访问超过100次，因此表现出较好的局部性。约73%的数据只被Put一次，访问次数超过10次的数据仅有0.001%，因此Put的局部性较差。</li>
<li>UP2X：对于UP2X，Get与Merge的访问次数分布较广，并且访问次数高的数据占比比较大。</li>
</ul>
</li>
<li><strong>QPS (Queries Per Second)</strong>：UDB 的部分 CF 表现出较强的昼夜模式，这跟社交网络用户习惯相关（白天上 Facebook，晚上在睡觉），ZippyDB 和 UP2X 没有表现出这样的特征。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201117094915.png" alt="20201117094915" loading="lazy"></li>
<li><strong>Key and Value Sizes</strong>：key size通常比较小，value size的大小与具体数据类型有关，key size的标准差较小但是value size较大， UDB平均的value size比其他两个例子要大<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201117095426.png" alt="20201117095426" loading="lazy"></li>
<li><strong>Key-Space and Temporal Patterns</strong>：统计方法：对key按递增顺序编号，然后统计每个key的访问次数绘制heat-map，统计key的访问时间绘制time-series。结论：heat-map可以看到三种DB的访问具有较强的key space locality，也就是热数据往往聚集分布在某些key space内。UDB的Delete/Single Delete以及UP2X的Merge的time-series表明其访问具有时间局部性
<ul>
<li>UDB：KV数据访问并不会随机分布在整个key space，而是根据key-space进行区分，部分key-space访问热度较高，这部分数据占比较小，而部分基本没有访问。属于同一个MySQL table的数据物理上也相邻存储，部分SST和block具有较高的热度，可以考虑基于这个优化compaction以及cache。</li>
<li>ZippyDB：ZippyDB的访问具有较为明显的key-space locality</li>
<li>UP2X：UP2X的访问也表现出较强的key-space locality，只有后半段key被访问，而前半段key基本没有访问。merge的time-series表现出来merge每一段时间内会集中访问一个range内的key。</li>
</ul>
</li>
</ul>
<h5 id="modeling-and-benchmarking">Modeling and Benchmarking</h5>
<ul>
<li>一些研究使用YCSB/db_bench + LevelDB/RocksDB来基准测试KV存储的存储性能。研究人员通常认为YCSB产生的工作量接近于实际工作量。对于实际的工作负载，YCSB可以针对给定的查询类型比率，KV对热度分布和值大小分布生成具有相似统计信息的查询。但是，尚不清楚它们在实际工作负载中生成的工作负载是否与基础存储系统的I/O相匹配。</li>
<li>为了对此进行调查，我们集中于存储I/O统计信息，例如由RocksDB中的perf_stat和io_stat收集的块读取，块缓存命中，读取字节和写入字节。为了排除可能影响存储I/O的其他因素，我们重放跟踪并在干净的服务器中收集统计信息。基准测试也在同一服务器中进行评估，以确保设置相同。为确保重放期间生成的RocksDB存储I/O与生产环境中的I/O相同，我们在收集跟踪的同一RocksDB的快照中重放跟踪。快照是在我们开始跟踪时创建的。YCSB是NoSQL应用程序的基准测试，而ZippyDB是典型的分布式KV存储。因此，预期YCSB生成的工作量接近ZippyDB的工作量，我们以ZippyDB为例进行调查。由于特殊的插件要求以及UDB和UP2X的工作量复杂性，我们没有分析这两个用例的存储统计信息。</li>
<li>总的来说YCSB测workload相比于真实的trace会造成更大的读放大以及更小的写放大，同时cache命中率也更低。其中的主要原因在于忽略了真实workload的key space locality，YCSB中的热点数据随机分布在整个key范围内，访问这些key会造成大量的block读并且被缓存，而这些block可能仅包含较少的热数据，cache大小有限所以降低了cache命中率。对于put，随机的热点分布使得数据在前几层就被compaction掉，所以造成更小的写放大，update的数据具有key space locality，那么新数据会不断写入，就数据一直往下compact直到新数据遇到旧数据才会被处理掉。</li>
<li><strong>Key-Range Based Modeling</strong>：整个键空间被划分成几个较小的键范围。我们不再仅仅基于整个键空间统计数据对KV对访问进行建模，而是关注这些键范围的热度。实验发现 <strong>当键范围大小接近SST文件中KV对的平均数目时，它可以保留数据块级别和SST级别的局部性。因此，我们使用每个SST文件的平均KV对数作为键范围大小。</strong> 然后将key size，value size以及QPS套到模型里面去，再处理kv的访问次数，访问顺序以及每个range的平均访问次数，然后和原有的负载进行对比测试。
<ul>
<li>Prefix_dist：基于建模构建的workload</li>
<li>Prefix_random：随机将冷热数据分布到各个key-range</li>
<li>All_random：热数据随机分布到整个key space</li>
<li>All_dist：热数据集中放置<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201117100641.png" alt="20201117100641" loading="lazy"></li>
</ul>
</li>
</ul>
<h4 id="个人见解-5">个人见解</h4>
<ul>
<li>做 Benchmarking 的工作今年来比较少，一般也只有相应的企业才能统计出相应的数据特征。Benchmarking 常常意味着一系列工具都需要去实现，如本文中的负载的 Trace 收集分析统计，意义很大，对于后续的 KV 存储研究提供了新的基准测试，也配套了相应的工具可以自己去收集相应的负载，且已开源。总之对于 KV 存储的研究，未来可能会成为新的测试基准。</li>
</ul>
<h3 id="fpga-accelerated-compactions-for-lsm-based-key-value-store">FPGA-Accelerated Compactions for LSM-based Key-Value Store</h3>
<ul>
<li>本文主要还是解决 LSM Tree 中的压缩慢的问题，压缩慢还会因为资源的争用影响整个存储系统处理的性能，然后呢也是得出相同的结论，存储系统的瓶颈在往 CPU 转移，这个观点在之前看的 KVell （SOSP19）的那篇文章就已经充分说明。采用的解决办法呢其实就是替 CPU 减压，引入一个新的处理单元进来，FPGA，因为 compaction 操作其实本质就是归并排序，所以 FPGA 完全可以胜任，这个思路其实也不是很新奇，ATC20 的 Best Paper 的 PinK 其实也采用了这种方法。</li>
<li>其实问题和思路都不算是特别地别具一格（这里没有去追究前面文章里的具体的时间先后顺序），但是毕竟是经历了工业界的验证的，阿里巴巴自研的 X-Engine 的存储引擎就使用了本文描述的技术，所以也不妨深入读一读，看看有什么有意思的点。</li>
<li>照例贴链接：
<ul>
<li><a href="https://developer.aliyun.com/article/748726">阿里云-开发者社区：X-Engine 研究综述</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/100139565">知乎：匠心之作 | 厉害了！阿里云自研存储引擎X-Engine又发顶会啦</a></li>
<li><a href="https://www.jianshu.com/p/2e2b37fd3ad6">简书 - Glitter试做一号机：FPGA-Accelerated Compactions for LSM-based Key-Value Store</a></li>
</ul>
</li>
<li>本文主要提出的方法就是将压缩给下沉到 FPGA 来执行，从而加速压缩，减小 CPU 瓶颈。测试表明该方法加速压缩 2-5 倍，系统吞吐量提升了 23%，能源效率（每瓦特处理的事务数量）提升了 31.7%。</li>
<li>BTW，X-Engine 的论文发表在 SIGMOD19</li>
</ul>
<h4 id="简要介绍-7">简要介绍</h4>
<h5 id="introduction-background-2">Introduction &amp; Background</h5>
<ul>
<li>
<p>首先大致介绍了基于 LSM Tree 的 KV 的应用场景，以新零售为例做了简单介绍。除此以外，KV 主要还会和其他数据库一起作为缓存或者索引来提供服务，这也是 KV 存储的关键的一些应用。然后简单介绍 LSM Tree，LSM 这种数据组织形式通常迫使查询遍历多个级别，以合并分散的记录以获得完整的答案或查找记录，甚至使用索引。这样的操作会带来跳过标记为删除的无效记录的额外开销。为了控制这些 drawbacks，后台压缩操作被引入，在相邻的层之间合并键范围重叠的数据块，并删除已经标记为删除的记录，目的是保持 LSM 树在一个适当的分层形状。</p>
</li>
<li>
<p>引入了一个新的概念，<strong>WPI（write and point read-intensive）负载</strong>，在长时间的 WPI 负载下，因为 LSM Tree 本身数据结构维护的不好（比如出现过大的 levels），性能就会表现得越来越差。</p>
</li>
<li>
<p>作者总结发现在 LSM Tree 中有一个很困难的 trade-off，即分配给关键路径上查询操作和事务处理的资源 和 分配给后台压缩线程的资源（后台压缩操作需要消耗大量的计算资源和磁盘 I/O 资源，特别是对于既包含读又包含写的 WPI 负载），如果给 compactions 分配更多的软件线程，就会在降低 CPU 实际处理查询和事务的风险下，加大了对存储的后台维护。</p>
</li>
<li>
<p>如图 1 所示，描绘了在 WPI （75% 点查询、25% 写操作）的负载下吞吐量随着用于 Compaction 线程增加的变化情况。线程数小于 32 之前都是随着线程数单调递增，从而带来显著的性能优势。然而，随着更多的线程用于 Compactions，CPU 逐渐饱和，然后会产生 CPU 争用，因此系统吞吐量在 32 个线程之后下降。后文将有更详细的研究表明 32 线程压缩的时候仍然不够快，无法解决上述问题。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201207203824.png" alt="20201207203824" loading="lazy"></p>
</li>
<li>
<p>现有的优化 Compaction 的研究主要采用了两种方法：</p>
<ul>
<li>一种是通过利用数据分布的特点（几乎是有序的，没有重叠的范围）来减小来减少每次压缩的负载，从而避免不必要的合并。如 X-engine（SIGMOD19），VT-Tree（FAST13）
<ul>
<li>或者通过将数据分割到多个分区，并在需要时分别为每个分区调度 Compaction 操作。The partitioned exponential file for database storage management(VLDBJ07)</li>
</ul>
</li>
<li>另外一种方法是优化压缩的时机和选择哪些数据来压缩(when and where)。bLSM (SIGMOD12)。理想情况下，为了提高性能，压缩应该在最需要的时候完成，并且它的执行与系统中其他操作的资源竞争最小
<ul>
<li>但是上述的关于 when 和 where 的条件在 WPI 负载下经常都是会有冲突的，因为对compaction 的需求和对高吞吐量的需求经常同时达到峰值。因此，对于CPU和I/O，存储系统中的资源竞争仍然是一个挑战，通过增加 CPU 线程限制了压缩速度的可伸缩性，并留下了性能问题。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>本文提出讲 Compaction 的压力从 CPU 向 FPGA 转移从而加速压缩的执行。理论角度上分析，</p>
<ul>
<li>offload compaction 一定程度上将 CPU 从 I/O 密集型应用中解放了出来，从而让存储系统使用更少的 CPU 或者在使用相等数量的 CPU 的情况下增加了吞吐量，在公有云的场景下都能降低成本开销。</li>
<li>相比于更喜欢进行 SIMD（单指令多数据流） 类型的计算的 GPU，FPGA 更符合加速压缩操作的需求，压缩任务本质是计算任务的 pipeline。我们还发现对于比较小的 KV 对的压缩合并往往会被计算资源给限制住，可能是因为现在磁盘的 I/O 带宽越来越高。</li>
<li>与其他方案相比，FPGA 的高能源效率在降低总拥有成本(TCO)方面具有竞争优势。KV 存储的用户对于成本其实很敏感，因为存储往往都意味着需要永久支出这笔成本。所以在云场景下，使用 FPGA 来 offload compaction 将能显著提升 LSM Tree 的经济效益。</li>
</ul>
</li>
<li>
<p>在 FPGA 上，我们设计并实现了压缩操作，一个包含了三个阶段的流水线操作：</p>
<ul>
<li>decoding/encoding inputs/outputs</li>
<li>merging data</li>
<li>managing intermediate data in buffers</li>
</ul>
</li>
<li>
<p>我们还实现了一个 FPGA 驱动程序和异步压缩任务调度器，以方便 offload 和提高效率，该方案被集成在 X-Engine 中，使用了不同的 WPI 负载来进行测试。效果显著。</p>
</li>
<li>
<p>以前的 LSM Tree 结构如图 a 所示，C0 满了之后合并到 C1，合并的开销会随着 C1 的大小的增加而增加，为了限制这样的开销，更好的选择是是把一个磁盘组件分成不同层级的多个组件，每个组件然后比前一层的组件大。但是会有写放大，因为一个 KV 对可能不得不合并很多次，同时也有读放大，因为查询不得不访问多个具有重叠键范围的组件。</p>
</li>
<li>
<p>为了限制读写放大，许多研究提出了如图 b 所示的分层存储结构。该结构具有优化的内存数据结构、多层磁盘组件，每一层由多个文件或细粒度的数据块组成。数据首先被插入到内存的 memtables 中（常用跳表来实现），一旦 memtables 满了之后转变成 immutable memtables，然后刷入到磁盘上的 L0 层，这里的 Lk 和以前的 LSM 树中的 Ck 是类似的，最大的区别是 Lk 是被分区成很多个文件（也就是 RocksDB 中的 SSTables）或者数据块（X-Engine 中的 extents），对应的合并策略有两种类型：</p>
<ul>
<li>将其与目标级别中的现有数据合并，即所谓的 level 策略，这种方法以压缩速度为代价，将数据按良好的排序顺序保存在某个级别中</li>
<li>另外一种只需将数据追加到下一层，而不进行合并，这称为 tier 策略，压缩本身速度很快，但会牺牲某个级别内的排序顺序<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201208111918.png" alt="20201208111918" loading="lazy"></li>
</ul>
</li>
<li>
<p>尽管上面介绍了最先进的优化，但我们发现，由于以下原因，压缩速度慢仍然会导致运行WPI 工作负载的 LSM-tree KV 存储的性能疲劳问题：</p>
<ul>
<li>Shattered L0：L0 层的数据块通常具有重叠的键范围，因为它们直接从主存中刷新而没有合并。除非压缩及时合并它们，否则点查找可能不得不检查多个块，以找到单个键，甚至索引也是如此。在这种压缩速度慢的情况下，随着时间的推移，L0 中存储的数据块会不断增加查找开销。这种破碎的 L0 对性能有重大影响，因为由于数据局部性，刷新到L0的记录仍然非常热(即很可能被访问)</li>
<li>Shifting Bottlenecks：压缩操作自然由多个阶段组成:解码、合并和编码，因为KV记录通常是前缀编码的。为了确定这些阶段中的瓶颈，我们对 SSD 上由单个 CPU 线程执行的单个压缩任务进行概要分析。如图所示执行时间分解，随着 value 大小的增加，计算时间(解码、合并、编码)的百分比减少。而对于小 KV，计算占据整个压缩过程的 60% 的开销。当 value 大小达到 128 字节时，I/O 操作占用了大部分 CPU 时间。这个分解表明随着 KV 大小的增加，瓶颈从 CPU 转移到 I/O。这表明在合并小 KVs 时压缩以计算为限，在其他情况下压缩以 I/O 为限。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201208202644.png" alt="20201208202644" loading="lazy"></li>
</ul>
</li>
<li>
<p>本文就是将上述的三个阶段给映射成 pipeline，并 offload 到专门的加速器。因为有了更快的压缩操作，L0 的数据块合并的更加频繁，因为 offloading，CPUs 从 heavy 的压缩操作中释放出来，从而腾出更多的资源用于事务和查询操作的处理。加速器选了 FPGA，因为 FPGA 它适合加速压缩等计算任务的 pipeline，且具有低 TCO 的低能耗，以及作为可插拔的 PCIe-attached 加速器的灵活性</p>
</li>
<li>
<p>原文还有一些关于 FPGA 本身的介绍，以及 FPGA 和 KV Store 结合的场景介绍。此处简单提及和 KVs 的结合问题，现有的研究大致有两种结合方式：</p>
<ul>
<li>bump-in-the-wire：将 FPGA 放在 CPU 和 disk 之间，该方法中，FPGA 类似于一个 data filter，在 FPGA 的片上 RAM 较小，只能临时保存数据流的一个 slice</li>
<li>随着片上 RAM 大小增加，FPGA 现在能像一个 co-processor 一样工作，所以可以把一些大数据量的处理任务给 offload 到 FPGA 上执行。这种方法适用于异步任务，在此期间，CPU 不会因为 offloaded 任务而 stall，本文就采用了这种方式，CPU 只用于任务的生成。Samsung 的 SmartSSD 也采用了这种方案实现计算型存储。</li>
</ul>
</li>
</ul>
<h5 id="design-and-implementation">Design and Implementation</h5>
<ul>
<li>
<p><strong>Overview</strong>：利用 Memtables 缓冲新插入的 KV 记录，利用缓存来缓冲热 KV 对和数据块，磁盘上的每一层包含多个 extents，每个 extent 依次用关联的索引和过滤器存储 KV 记录。X-Engine 在内存中还维护了一个全局索引用于加速查询。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201208211801.png" alt="20201208211801" loading="lazy"></p>
</li>
<li>
<p>为了 offload compactions，首先设计了一个 Task Queue 来缓冲新触发的压缩任务，一个 Result Queue 缓冲在内存中的压缩过的 KV 记录。软件层面，引入了一个 Driver 来 offload compactions，包括管理从 host 到 FPGA 的数据传输过程，在 FPGA 上，设计并应用了多个 Compaction Units (CUs) 来负责合并 KV 对。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201208212133.png" alt="20201208212133" loading="lazy"></p>
</li>
<li>
<p><strong>Managing Compaction Tasks</strong>：设计了三种线程，builder threads, dispatcher threads and driver threads 分别用于构建压缩任务、分发压缩任务到 FPGA 的 CU，install 压缩后的数据块到存储中。</p>
<ul>
<li><strong>Builder thread</strong>：对于每个触发的压缩，Builder thread 将 extents 分区合并到多个大小相近的组中，每个组然后形成一个压缩任务，且将数据加载在内存中。FPGA 压缩任务。将构建一个 FPGA 压缩任务，其中包含所需的元数据，包括指向任务队列的指针、输入数据、结果和一个回调函数（将压缩后的数据块从FPGA传输到主存）、返回代码（指示任务是否成功完成）和压缩后任务的其他元数据。压缩任务会被推送到 task queue，等待被分发到 FPGA 的 CU 上，Builder Thread 也会检查 result queue 并把压缩后的数据块 install 回存储设备中（如果任务被成功处理的话），如果 FPGA 处理压缩任务失败了（比如 KV 的大小达到 FPGA 的容量），将重新启动一个 CPU 压缩线程来重新处理该任务。实践表明，offload 到 FPGA 上平均只有 0.03% 的任务处理失败。</li>
<li><strong>Dispatcher thread</strong>：dispatcher 消费任务队列，然后以 Round-Robin 的策略把任务分发到 FPGA 上所有的 CU。由于压缩任务大小相似，这种循环调度实现了 FPGA 上多个 CUs 之间的工作负载均衡分配。dispatcher 还会通知驱动线程将数据从设备内存传输到 FPGA。</li>
<li><strong>Driver thread</strong>：Driver thread 将输入数据和一个压缩任务一起传输到 FPGA 上的 device memory，然后通知对应的 CU 开始工作，当压缩任务完成之后，Driver thread 被中断以执行回调函数，回调函数将压缩后的数据块传输到宿主机 Memory，然后把完成后的任务推送到 result queue。</li>
<li>在这样的实现中，需要调整压缩任务的大小以为 compaction unit 提供充分的数据，在 CUs 之间保证负载均衡，同时也可以限制重试在 FPGA 上执行任务的开销。我们还会对 builder/dispatcher/installer 线程数单独进行调整，以实现比较稳定的吞吐量表现。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209092309.png" alt="20201209092309" loading="lazy"></li>
</ul>
</li>
</ul>
<p><strong>Instruction and Data Paths</strong></p>
<ul>
<li>为了驱动 FPGA 用于压缩，我们需要通过 PCIe 总线传输指令和数据，为了最大化传输效率，设计了 Instruction and Data Paths，还设计了 Interruption Mechanism 来通知 Installer Thread，Memory Management Unit (MMU) 来管理 FPGA 上的设备内存。
<ul>
<li>Instruction Path：指令路径是为像 CU 可用性检查这样的小而频繁的数据传输而设计的</li>
<li>Compaction Data Path：数据路径使用 DMA。要压缩的数据通过此路径传输。这样，CPU 就不参与数据传输过程了。</li>
<li>Interruption Mechanism：当压缩任务完成时，将通过PCIe发送一个中断，然后在中断向量的帮助下将结果写回主机</li>
<li>Memory Management Unit (MMU)：MMU 在设备存储器上分配内存来存储从主机复制的输入数据<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209100819.png" alt="20201209100819" loading="lazy"></li>
</ul>
</li>
</ul>
<p><strong>Compaction Unit</strong></p>
<ul>
<li>压缩单元(CU)是在FPGA上实现压缩操作的逻辑实现。很多个 CUs 被部署到同一个 FPGA 上，具体的数量取决于时机可用的资源。如下图所示了 CU 的设计，如下设计中，压缩任务由几个阶段共同组成：Decoder, Merger, KV Transfer, and Encoder。我们引入缓冲区<br>
(即KV 环缓冲器、键缓冲器)在后续模块和控制器之间协调各模块的执行。
<ul>
<li><strong>Decoder</strong>：KV 存储的 key 通常都是前缀编码的，为了节省空间，所以 Decoder 需要解码输入的 KV 记录。如果采用了 tiering compaction 策略，可能存在多种输入数据块的合并方式。而对于 levelling policy，只会有最多两个输入数据的方式，来自两个相邻的层。同时我们实际发现 tiering 最多也只有两个或四个输入方式，如果在一个 CU 里我们放置两个 decoders，每一个 decode 一种输入，那么我们需要构建三个 两路压缩 来实现一个 四路压缩，如果我们使用四个 decoder 会多消耗 40% 的硬件资源，而无需在 2-4 路压缩方式下执行额外的任务。因此我们在每个 CU 中放置了四个 decoders，decoder 将 解码后的 KV 对输送到了 KV Ring Buffers 中。</li>
<li><strong>KV Ring Buffer</strong>：KV Ring Buffer 缓存解码后的 KV 记录，我们在实践中观察到 KV 的大小很少超过 6KB，因此我们给每一个 KV Ring Buffer 配备了 32*8KB 的 slots，额外的 2KB 可以用于存储如 KV 长度这样的元数据信息。我们还设计了三种状态信号， FLAG_EMPTY, FLAG_HALF_FULL and FLAG_FULL 来表示 buffer 的空间情况。从一个空缓冲区开始，解码器持续解码并填充这个缓冲区，当处于 FLAG_HALF_FULL 时，下游的 Merger 将被允许独去缓冲区中填充的数据然后开始合并，在 Merger 工作的同时，decoder 持续地填充数据直到填满，我们匹配 merger 和解码器的速度，这样，通过填充一半的环形缓冲区，merger 将花费相同的时间来完成它的工作。通过这种方式可以有效地将 decoder 和 merger 流水线化。如果两个模块速度不匹配，Controller 将停止 decoder。我们为 merger 维护了一个读指针来标记从哪里读取的 KV 记录，并为解码器类似地维护了写指针。</li>
<li><strong>KV Transfer, Key Buffer and Merger</strong>：只有 keys 被传输到了 Key Buffer，然后 Merger 进行比较。如果一个 key 被限定为一个输出，KV Transfer 模块将相应的 KV 记录从上游的 KV Ring Buffer 传输到 KV Output Buffer，数据结构和 Ring Buffer 完全相同。Controller 收到比较结果的通知后移动 ring buffer 中相应的 read pointer。如图 9 所示，如果 way 2 上的 KV 是最小的 KV，Controller 将会通知 KV Transfer 将该条记录传输，使用对应的读指针进行寻址，然后再移动到下一个位置来拉取用于下一轮比较的 entry。</li>
<li><strong>Encoder</strong>： 该模块编码合并后的 KV 记录，并放置到设备内存，因为这只有一种合并后的数据，所以每个 CU 只需要一个 encoder。</li>
<li><strong>Controller</strong>：Controller 在 CU 中更多地是作为一个协调者，管理 KV ring buffer 的读写指针（分别为 merger 和 decoder 管理），也需要给每一个信号传递开始或者停止的信号。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209105209.png" alt="20201209105209" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209111854.png" alt="20201209111854" loading="lazy"></li>
</ul>
</li>
</ul>
<p><strong>Analytical Model for CU</strong>：</p>
<ul>
<li>由于采用流水线设计，因此匹配不同模块的吞吐量非常重要，以避免硬件资源的过度供应和浪费，但是，很难通过如此多的调优选项来确定每个组件的资源数量。因此提出了一种分析模型来指导资源分配。参数如下：<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209113239.png" alt="20201209113239" loading="lazy"></li>
<li>CU 的吞吐量由最慢阶段的吞吐量来决定，只有一个例外 KV Transfer，当 KV Transfer 工作时，合并 KVs 的转移与其前一阶段的 Merger 串行执行，这种情况下，他们的开销应该合并起来计算。每一阶段的成本由其计算和内存开销组成，除了在启动此阶段时消耗的恒定数量的基本周期之外。</li>
<li>等式 2 3 4 5 都建模了每个 KV 对在对应组件内的开销，等式 6 建模了在 host 和 device 之间数据传输的吞吐量，主要受到 PCIe 带宽的限制。通过检查硬件实现和性能分析，我们使用表1中列出的数据初始化这些模型。例如一个 KV 对，8B key，32B value，每个 KV 在每个阶段消耗的周期为 16， 55， 23， 52（Decoder, Merger, KV ransfer, and Encoder stages）。整体的吞吐量为 3.6M records/s<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209113313.png" alt="20201209113313" loading="lazy"></li>
</ul>
<h5 id="evaluation">Evaluation</h5>
<ul>
<li>
<p>Hardware：</p>
<ul>
<li>two Intel Xeon Platinum 8163 2.5 GHz 24-core CPUs with two-way hyperthreading</li>
<li>a 768 GB Samsung DDR4-2666 main memory</li>
<li>a RAID 0 consisting of 10 Samsung SSDs</li>
<li>a Xilinx Virtex UltraScale+ VU9P FPGA board (running at 200MHz) with a 16 GB device memory to this server through a x16 PCIe Gen 3 interface</li>
</ul>
</li>
<li>
<p>Software: Linux 4.9.79, X-Engine</p>
</li>
<li>
<p>KV 对越小，更多的开销都是在 offload 过程，随着 KV 的增大，逐渐被稀释这部分开销，所以 KV 对越大，性能提升越明显<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209114414.png" alt="20201209114414" loading="lazy"></p>
</li>
<li>
<p>总吞吐量总是限制在合并和 KV 传输阶段的组合，既不不是对设备存储器的访问，也不是通过 PCIe 的数据传输<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209114638.png" alt="20201209114638" loading="lazy"></p>
</li>
<li>
<p>24 线程以前，压缩比 KV 存储的总写吞吐量要慢，因此它不能摄取lsm树中足够的新写数据。因此，使用更多线程加速压缩是有回报的。从24个线程到32个线程，吞吐量几乎没有变化。大于 32 个线程之后，随着线程的增加吞吐量下降。原因主要在于更多的线程也就引入了更多的资源争用，如前面图 1 所示整体的 CPU 利用率接近 100%，此时瓶颈在于 CPU。第二个原因是前面增加的线程已经让磁盘 I/O 饱和，持续增加线程只会造成更多的查询/事务处理和 compaction 之间的 I/O 争用。</p>
</li>
<li>
<p>FPGA-offloading 和 CPU-based 两种对比发现，FPGA-offloading 比最好的 CPU-based 的吞吐量都要高出 23%，因为不仅加速了压缩，还减少了 CPU 的争用。又因为 FPGA 上的压缩任务比较好的调度和分配，没有观察到对于内存的消耗上有太显著的区别，CPU-Only 的负载相对消耗更多的内存带宽。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209115040.png" alt="20201209115040" loading="lazy"></p>
</li>
<li>
<p>吞吐量都有提升，延迟有所下降，尾延迟也有所下降，操作的响应时间也有降低，能源消耗也有所降低，整体的能源效率有所提高。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209151041.png" alt="20201209151041" loading="lazy"></p>
</li>
<li>
<p>当读比例在 WPI 负载中下降到了 75% 时，也就是此时成为一个写密集的 WPI 负载，我们提出的卸载方法的性能优于基准，在所有情况下都减少了约 10% 的 CPU 消耗，并且由于其吞吐量高于 CPU，因此消耗的 I/Os 稍微多一些。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209151956.png" alt="20201209151956" loading="lazy"></p>
</li>
<li>
<p>在 DBBench 和 YCSB 基准测试中，与读密集型的操作相比，当工作负载中有大量写操作时，提出的 FPGA-offload 压缩对 KV 存储的贡献更大，因为压缩在工作负载中 lsm 树只在写操作时触发<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209152230.png" alt="20201209152230" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209152257.png" alt="20201209152257" loading="lazy"></p>
</li>
</ul>
<h5 id="related-work">Related Work</h5>
<p><strong>Software Optimizations of Compactions</strong></p>
<ul>
<li>FAST13 的 VT-tree 使用拼接技术来避免排序和不重叠的键范围的不必要的磁盘 I/Os，但是这种方法受数据分布的影响，可能导致碎片化，使范围扫描和压缩的性能变差。</li>
<li>SIGMOD12 的 bLSM 和 VLDBJ07 的 PE 考虑了数据分布，都是将键范围分渠道多个键的子范围并限制比较热的键范围的数据压缩。</li>
<li>IPDPS14 的 PCP 观察到压缩可以流水线化，使用多个 CPUs 和存储设备来充分利用 CPU 和 I/O 资源从而加速压缩过程。</li>
<li>SIGMOD18 的 Better spacetime trade-offs for lsm-tree based key-value stores via adaptive removal of superfluous merging 通过合并尽可能少的内容来实现查找成本和空间的给定边界，从而提供了更丰富的时空权衡，并提出了一种混合压缩策略(即，对最大级别使用 levelling，对其余级别使用 tiering) 来减少写入放大</li>
<li>SIGMOD19 的 X-engine 提出将 LSM-tree 中的数据分割成小数据块，并在压缩过程中广泛重用键范围不重叠的数据块，以减少写放大。</li>
<li>所有这些软件优化和我们提出的基于 FPGA 的优化是正交的，即可以一起作用来显著提升系统性能并降低能耗。</li>
</ul>
<p><strong>Hardware Accelerations in Databases</strong></p>
<ul>
<li>数据库领域早就在尝试使用各种其他类型的硬件来加速数据的读写。</li>
</ul>
<h4 id="个人见解-6">个人见解</h4>
<ul>
<li>本文还是问题找的比较关键准确，所以后续的提升方案才能带来如此大的提升，而且这个问题也基本是学术界很多学者都已经发现了的问题，只是各自的解决方式不同，但大体思路其实是相通的，即借助其他处理器资源来减少 CPU 的争用问题。不同的是不同层级的优化，如很多做 KVSSD 的研究人员更多是在 SSD 那一层去做这样的优化，本文则更多地是从系统层面来做优化，一个好的点是可能很少人关注到引入新硬件后引入的成本和能耗问题，这个确实云厂商比较关注这方面的问题，所以在评价的角度上能够多出一环。</li>
<li>看完这篇文章的具体感受就是，处理器现在也是百家争鸣，具有各自鲜明特点的硬件单元堆积在板子上可能将会成为一个趋势，即把更专门的运算交给更专业的人去做，而不是像以前 CPU 一锅端。</li>
</ul>
<h3 id="hotring-a-hotspot-aware-in-memory-key-value-store">HotRing: A Hotspot-Aware In-Memory Key-Value Store</h3>
<ul>
<li>本文主要针对的内存 KVs，最主要的应用还是作为 Cache，在大量的互联网场景中都有应用，作为 Cache 需要面对和解决的问题其实就是热点数据的访问。内存中的 KVs 最常见的数据结构就是 HASH，诸如像 Redis 这样的成熟的的内存 KVs，大多都是使用 HASH 来实现。而本文立足的场景也是阿里云淘宝这种并发高的电商场景，需要强劲的缓存支撑，淘宝的 Tair 也算是业界比较知名的数据库团队。</li>
<li>本文主要还是针对热点数据的优化，更多地是从数据结构本身出发，因为相关参考资料也已经讲的很多了，此处主要介绍问题和大致的方案。</li>
<li>贴几个链接：
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/109774040">知乎 - 暗淡了乌云：看了几篇FAST 2020</a></li>
<li><a href="https://www.cnblogs.com/helloworldcode/p/13022166.html">CNBlogs - 晓乎：HotRing: A Hotspot-Aware In-Memory Key-Value Store</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/112928251">知乎 - 阿里技术：性能提升2.58倍！阿里最快KV存储引擎揭秘</a></li>
</ul>
</li>
<li>本文主要探索针对内存索引结构的热点感知的相关设计，作者首先分析了理想的热点感知的索引的潜在收益，并讨论了有效利用热点感知可能面临的挑战（热点变化和并发访问问题）， 基于此分析提出了可以热点感知的 KVs 设计 HotRing，针对一小部分 items 进行大规模并发访问而优化的。HotRing 基于有序的一个有序的环状 HASH 索引结构，通过移动 head 指针来快速访问热点数据。也会应用一个比较轻量的策略来检测运行时的热点变化。HotRing 在设计中采用了无锁的结构，所以并发操作能够更好地利用多核架构的性能。实验表明我们的方法相比于其他内存 KVs 在高度倾斜的负载下实现了 2.58x 的提升。</li>
</ul>
<h4 id="简要介绍-8">简要介绍</h4>
<h5 id="introduction-background-3">Introduction &amp; Background</h5>
<ul>
<li>
<p>常见的内存 KVs，如 Memcached、Redis、SIGMOD18 的 FASTER(HASH)、NSDI13 的 MemC3(HASH)、NSDI14 的 MICA(HASH) 等。热点问题是一个广泛的问题，有一些集群层面上的热点问题的解决方案，如一致性 HASH、数据迁移、前端数据缓存等，同样单节点上的热点问题也需要被解决。比如计算机体系结构利用垂直的存储结构来缓存最常访问的数据在更低延迟的存储介质上。但是对于内存 KVs 内部的热点数据问题往往忽略了。作者从阿里巴巴的生产环境中收集了内存 KVs 的访问情况如图所示，可以发现 <strong>日常分布中的百分之五十和极端分布中的百分之九十的访问都只会访问到总的数据的 1%</strong>，这说明网络时代的热点问题空前严重。（具体的原因主要是在线应用的活跃用户数量持续增长，一些热门事件都会导致在短期内对于少部分数据的大量访问，所以对这些热点数据的快速访问是比较关键的，除此以外这些应用程序之下的基础设施变得复杂，一个小错误，例如由于软件错误或配置错误，可能导致(不可预测的)重复访问一个项，例如无休止地读取和返回一个错误消息。理想的效果是这些不可预测的热点不会导致整个系统崩溃或阻塞）<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201209172247.png" alt="20201209172247" loading="lazy"></p>
</li>
<li>
<p>HASH 索引是最流行的内存 KV 数据结构，特别是针对于一些不需要范围查询的场景。下图展示了 HASH 索引的一种通用结构，bucket + list。HASH 值可以分为两部分，一部分用作 HASH 表的索引，一部分用作 list 种的比对，从而减少比较过程中的需要比较的对象数据的长度。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201211203318.png" alt="20201211203318" loading="lazy"></p>
</li>
<li>
<p>现有的内存 HASH 索引无法感知热点数据，即未对热点数据进行区分（如上图中的 热点数据 item3 位于冲突链的末尾，就会比之前多更多的内存访问次数，在一些倾斜负载的情况下热项访问成本的轻微增加可能导致整体性能的严重下降）</p>
</li>
<li>
<p>采用的相同的策略管理所有数据，但是理论分析表明查询热点数据的开销比理想的策略大得多，虽然存在一些减少内存访问的机制，但它们只能提供有限的效率。</p>
<ul>
<li>比如 CPU 利用自己的缓存来加速吗，但是只有 32M 大小，完全不足以缓存热点数据，即便是有一些缓存友好的数据结构</li>
<li>可以扩大哈希表(即通过重新哈希)，以减少冲突链的长度，从而查找一个热项所需的内存访问更少，Rehash 可以帮助减少冲突链的长度，但会显著增加内存占用。特别是当 HASH 表已经很大的时候，就不再推荐重 HASH。例如，对于两个连续的重哈希操作，第二个需要两倍的内存空间，但只带来一半的效率(就减少链长度而言)。</li>
</ul>
</li>
<li>
<p>在本文中，我们提出了 HotRing，这是一种支持热点的内存 KVS，它利用 HASH 索引来优化对一小部分数据项(即热点)的大规模并发访问。最初的想法是让查找一个项所需的内存访问与它的热度负相关，即越热的项读取速度越快。但是需要解决两个问题：</p>
<ul>
<li>hotspot shif：热点项集不断变化，我们需要及时发现并适应这种变化
<ul>
<li><strong>使用 ordered-ring 来解决，当热点变化时，bucket headers 可以直接重新指向热的数据项，而不会影响正确性</strong></li>
<li>同时设计了一个轻量的机制来检测运行时的热点变化</li>
</ul>
</li>
<li>concurrent access：热点本质上是被大量并发请求访问的，我们需要为它们维持高并发性
<ul>
<li><strong>基于现有的无锁数据结构（无锁链表）采用了一种无锁的设计，并扩展该数据结构以支持 HotRing 所需要的其他操作，包括热点变化检测、头指针移动以及有序环 rehash</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="design-3">Design</h5>
<ul>
<li>
<p>HotRing 的 HASH 索引结构如下所示，将以往的传统的 HASH 冲突链表转变为冲突环，原本的链表最后的项将和链表的首项连接起来，当环中只有一项数据时，所有指针都指向自身。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201211211441.png" alt="20201211211441" loading="lazy"></p>
</li>
<li>
<p><strong>Ordered-Ring Hash Index</strong>：环状结构的问题就是没有遍历的终止条件（当对应 bucket 内无对应数据时），就需要一个机制来安全地终止查询过程。很直观的想法就是将 HEAD 指向的第一项标记为停止遍历的标识，但是对于并发请求时会有问题，比如删除了标记的项。所以本文提出了有序环结构来决定查询的过程，使用 Key 和 Tag 进行排序。（先按照 tag 排序，然后按照 key 排序），相比于以往的链式结构，平均查询次数减少到了 (n/2) + 1 次<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201214104313.png" alt="20201214104313" loading="lazy"></p>
</li>
<li>
<p><strong>Hotspot Shift Identification</strong>：此处讨论的都是 bucket 内的热点数据的变化，通常冲突链上有 5-10 个数据项，然后根据热点数据的比例 0.1 到 0.2 推断大约每个 Bucket 内有一个热点数据，可以直接把 HEAD 指针指向唯一的热点数据，从而避免数据的重新组织并减少内存开销。为了获取较好的性能，需要考虑两个因素：</p>
<ul>
<li>热点识别的准确率：热点识别的准确性是通过识别热点所占的比例来衡量的</li>
<li>响应延迟：响应延迟是一个新的热点出现和我们成功检测到它之间的时间跨度。</li>
</ul>
</li>
<li>
<p>基于上述两个因素提出了两种策略： random movement 和 statistical sampling strategy</p>
<ul>
<li><strong>Random Movement</strong>：响应时间短，但是准确率低，其基本思想是，头指针从即时决策周期性地移动到潜在热点，而不记录任何历史元数据。每个线程维护一个 ThreadLocal 变量来记录该线程执行的请求数量，每 R 个请求后，线程决定是否执行头指针的移动操作。如果第 R 次访问是对热数据的访问，那么指针不移动，如果是对冷数据的访问，那么 HEAD 指针指向该冷数据，因为可能即将成为热数据。参数 R 将影响响应延迟和识别的准确率，如果 R 太小，为了实现稳定的性能的响应延迟会很低，但是将导致频繁的且低效的头指针移动。我们的场景中，数据负载是严重倾斜的，因此头指针的移动往往不频繁，根据经验，参数R默认设置为5，该参数可以提供较低的反应延迟和可忽略的性能影响。
<ul>
<li>如果负载的倾斜状况不是很明显，该策略将变得特别低效，最重要的是该策略无法处理一个冲突环中多个热点数据的问题，多个热点数据的时候，头指针频繁地移动，并不会加速对热点数据的访问反而会对正常操作产生不利影响。</li>
</ul>
</li>
<li><strong>Statistical Sampling Strategy</strong>：为了实现更高的性能，我们设计了一种统计采样策略，旨在提供更准确的热点识别与稍高的反应延迟。
<ul>
<li>首先考虑数据格式：Head Pointer 和 Item。将同时记录 Ring 和 Item 级别的统计数据。
<ul>
<li>Head Pointer 由三部分组成：
<ul>
<li>Active bit: 用于控制该策略的 flag</li>
<li>Total Counter: 对该冲突环的访问总次数</li>
<li>Address: 为对应项的物理地址</li>
</ul>
</li>
<li>Item 由以下几部分组成：
<ul>
<li>Rehash：用于控制 rehash 过程的 flag</li>
<li>Occupied：用于保证并发时的准确性</li>
<li>Counter：用于记录该项的访问次数<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201214202717.png" alt="20201214202717" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>Statistical Sampling：如何在这么大的 HASH 表中以一个低开销的方式动态识别出热点数据是一个极具挑战性的问题，关键是尽量减少开销，同时保持精度，这是通过周期采样在HotRing实现的。每个线程维护一个 ThreadLocal 变量用于计数已经处理了的请求数，每 R 个请求之后我们决定是否要开启新一轮的采样，通过改变 Active flag 的值来控制。如果第 R 个访问时热点数据，意味着当前的热点识别仍然是准确的，采样无需触发，如果是冷数据，意味着热点发生了变化，然后我们开始采样。R 默认还是设置为 5，当 Active 位被置为 1，后续对环的访问将被记录在 Total Counter 和对应的 Item 的 Counter 中。采样的策略要求额外的 CAS 操作，可能会导致临时的性能降级。为了减少这个时间，我们将样本的数量与每个环中的项目数量设置相等，我们认为这已经提供了足够的信息来派生新的热点。</li>
<li>Hotspot Adjustment：采样完成后，最后一个访问线程负责频率计算和热点调整。该线程首先使用 CAS 原语 RESET Active BIt，这确保了只有一个线程将执行后续任务。然后，该线程计算环中每个项的访问频率（<strong>用于后续计算 income</strong>），对应项的 Counter 除以该环的 Total Counter，然后计算每个项被头指针指向的 income，即某个项被选中被头指针指向对应的平均内存访问次数。然后选择出 income 最小的项作为热数据从而确保热点最快被访问，头指针的移动也是 CAS 操作。对于多个热点数据的情况，可以计算出相对较优的位置从而避免热点数据之前的频繁移动。调整了热点数据之后，负责的线程重置所有的计数器便于下次采样。</li>
<li>Write-Intensive Hotspot with RCU：对于更新操作，如果 value 小于 8 byte，那么可以就地更新。这个例子中，reading 和 updating 一个项被视作相同热度的操作，但是对于 value 比较大的项的更新操作就完全不同了。RCU（Read-Copy-Write）协议的情况下，前项的指针需要被修改因为在更新过程中指向了新的 item，如果HEAD 指针指向的写密集型热点被修改，整个冲突链将被遍历才能到达前项，也就是说一个写密集型的热数据也会造成他的前项数据变热，基于此我们稍微修改了统计采样策略。对于 RCU 更新，改为只对它的前一项的计数器加一。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201214211131.png" alt="20201214211131" loading="lazy"></li>
<li>Hotspot Inheritance：当对head项执行RCU更新或删除时，我们需要将head指针移动到另一个项。但是，如果头指针随机移动，它可能指向一个冷的数据，这将导致热点识别策略被频繁触发。此外，识别策略的频繁触发会严重影响系统的性能。如果环中就一个数据项，CAS 直接修改头指针来完成更新和删除操作，如果这有很多项，HotRing 使用现有的热点信息（头指针指向的位置）来继承对应的热度。针对RCU的更新和删除操作，我们设计了不同的头指针移动策略，以保证热点调整的有效性：
<ul>
<li>对于head项的RCU更新，由于访问的时间局部性，最近更新的项有很高的被立即访问的概率，因此头指针被移动到 head 的新版本</li>
<li>对于头项的删除，头指针只是移动到下一个项，这是一种简单而有效的解决方案</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Concurrent Operations</strong>：HEAD 可移动导致并发控制更为复杂，但其实主要控制几个关键数据的原子操作即可。如 Next Item Address 后项指针需要使用 CAS 操作来保证原子性。</p>
<ul>
<li>Insert 操作如图 A 所示，需要保证只有一个修改后向指针的操作成功。</li>
<li>Update 小于 8 byte 时无需额外的保证，对于 RCU 操作才需要进行控制。还是图 A 的例子，一个插入 C 的线程需要修改 B 的后向指针，一个线程需要更新 B 的数据为 B‘，这两个操作因为更新的是不同的数据指针其实都会成功，但是因为 B 对于环而言不可见了，即便 C 插入已经成功，所以后续对 B 的操作就会出错（C 的插入更新 B 的后向指针的操作），在图 b 中也有相同的问题，所以使用 Occupied 位来确保正确性，所以使用两个步骤来完成操作。对于 Update&amp;Insert 操作，需要更新后向指针的 B 先把 Occupied 位置原子性第置为 1 ，一旦 Occupied 被置为 1，插入 C 的完整操作将会失败并需要重试。然后更新 A 的后项指针指向 B’，然后将 B‘ 的 Occupied 位重置。</li>
<li>Delete：删除是通过将原本指向了已删除项的指针修改为下一个项来实现的。因此需要保证要删除的项的后向指针在操作过程中不被改变，还是借助 Occupied 位来实现。如图 C 所示</li>
<li>Head Pointer Movement：
<ul>
<li>如何处理正常操作的和热点识别策略引起的头指针移动 形成的并发的情况？ Occupied</li>
<li>如何处理头部指针移动，造成更新或删除头部项目? HotRing不仅需要 occupy 准备删除的项，还需要 occupy 下一个项。因为如果在删除操作期间下一项未被占用，则下一个节点可能已被更改，这使得头指针指向一个无效的项。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201214220309.png" alt="20201214220309" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Lock-free Rehash</strong>：我们在HotRing中提出了一种无锁的重新哈希策略，允许在数据量增加时灵活地重新哈希。传统的重哈希策略是由哈希表的装载因子(即链的平均长度)触发的。但是，这没有考虑热点的影响，因此不适合HotRing。为了使索引适应热点项的增长，HotRing使用访问开销(即检索一个项的平均内存访问次数)来触发重新哈希。</p>
<ul>
<li>Initialization：创建一个后台 HASH 线程，线程通过共享 tag 的最高位来初始化新哈希表，新哈希表的大小是旧哈希表的两倍。如图 a 所示。同时，重哈希线程创建一个由两个子重哈希项组成的重哈希节点，这两个子重哈希项分别对应两个新的头指针。每个重哈希项的格式与数据项相同，只是没有存储有效的KV对。HotRing 通过每个项中的Rehash 位来标识重新散列项。在初始化阶段，两个子重散列项的标记设置不同。如图 b 所示，对应的重散列项分别将标签设置为0和T/2。</li>
<li>Split: 重哈希线程通过向环中插入两个重哈希项来分割环。如图 C 所示，将重新哈希项分别插入到项B和项E的前面，作为标签范围的边界来划分环。当两个插入操作完成时，新建表被激活。之后，依次访问新表需要通过比较 tag 选择相应的头指针，而以前访问(从旧的表）通过 tag 重新散列节点继续。可以在不影响并发读和写的情况下正确地访问所有数据。到目前为止，对项的访问在逻辑上被划分为两条路径。</li>
<li>Deletion: 如图 d 所示，在此之前，重散列线程必须维护一个过渡期，以确保从旧表发起的所有访问都已经完成，比如read-copy-update同步原语的过渡期。当所有访问结束时，重新哈希线程可以安全地删除旧表，然后重新哈希节点。注意，过渡期只阻塞重散列线程，而不阻塞访问线程。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201214222311.png" alt="20201214222311" loading="lazy"></li>
</ul>
</li>
</ul>
<h4 id="个人见解-7">个人见解</h4>
<ul>
<li>本文还是问题找的比较关键准确，当然主要是因为淘宝有对应的真实场景，冷热数据的访问影响极大，但相较于以往针对缓存算法中冷热数据的识别，本文将问题更多地聚焦在 HASH 冲突链内，所以方向性也就比较明确，个人觉得可以在缩小问题范围之前加一个测试来说明 HASH 冲突链内的热点问题的严重性，来进一步证明把这个大问题缩小范围的有效性和可行性。</li>
<li>本文设计的数据结构还是挺巧妙的，乍一看链变环仿佛没啥新东西，但其中蕴藏了很多有意思的问题，尤其是并发场景下的一些数据访问的问题，你使用了有序环的结构减少内存访问次数，但也就需要见招拆招地解决环结构本身的问题，对于并发访问的场景考虑的也很周全。</li>
</ul>
<h2 id="caching">Caching</h2>
<ul>
<li>BCW: Buffer-Controlled Writes to HDDs for SSD-HDD Hybrid Storage Server
<ul>
<li>Shucheng Wang, Ziyi Lu, and Qiang Cao, Wuhan National Laboratory for Optoelectronics, Key Laboratory of Information Storage System; Hong Jiang, Department of Computer Science and Engineering, University of Texas at Arlington; Jie Yao, School of Computer Science and Technology, Huazhong University of Science and Technology; Yuanyuan Dong and Puyuan Yang, Alibaba Group</li>
</ul>
</li>
</ul>
<h3 id="bcw-buffer-controlled-writes-to-hdds-for-ssd-hdd-hybrid-storage-server">BCW: Buffer-Controlled Writes to HDDs for SSD-HDD Hybrid Storage Server</h3>
<ul>
<li>
<p>本文是隔壁实验室大佬发的，和 Alibaba 也有一些合作（盘古），有一些生产环境中的实际问题和数据可以借鉴。发现的问题也算是比较关键。</p>
</li>
<li>
<p>贴几个链接：</p>
<ul>
<li><a href="https://developer.aliyun.com/article/758338">FAST20 论文学习：Buffer-Controlled Writes to HDDs for SSD-HDD Hybrid Storage Server</a></li>
<li><a href="https://nbjl.nankai.edu.cn/2020/0308/c12124a266896/page.htm">NBJL 2020论文导读10：BCW: Buffer-Controlled Writes to HDDs for SSD-HDD Hybrid Storage Servere</a></li>
</ul>
</li>
<li>
<p><strong>场景</strong>：本文主要针对混合存储（Hybrid Storage）场景，SSD 作为缓存为 HDD 加速。HDD 因为容量大、成本低在数据中心还是有着很多的应用，特别是对一些冷数据的存储，但对于当下对于存储设备的性能需求，HDD 又无法提供用户期待的性能，所以大多数公司会使用性能更好的 SSD 来为 HDD 加速，在保证大容量低成本的同时提供一定的性能保证。</p>
</li>
<li>
<p><strong>问题</strong>：在阿里的生产环境中发现（Pangu storage nodes A (Cloud Computing), B (Cloud Storage), C and D (Structured Storage)），这种混合存储的场景下有一个很严重的问题，就是对于 HDD 和 SSD 的使用严重不均衡，即对 SSD 过度使用，而 HDD 的利用率较低，如果负载是一些写密集型的负载，那么 SSD 磨损的情况更严重，而且因为 SSD 本身的机制的原因，写密集将导致频繁的 GC 从而增大 SSD 响应的尾延迟。</p>
<ul>
<li>写入的数据量极大，每个 SSD 每天写入的数据有接近 3TB，接近于 DWPD (Drive Writes Per Day)，严重影响 SSD 的可靠性（相当于每天满负荷运行） https://www.kingston.com/cn/ssd/dwpd</li>
<li>有很多突发 IO，SSD 需要处理这种突发的写密集型负载</li>
<li>写入到 SSD 和 HDD 的数据量差别较大，利用率有 10 个百分点的差距，而且 HDD 大多是转储 SSD 的数据，基本不直接服务用户请求</li>
<li>存在长尾延迟，因为队列阻塞。主要原因有两类：单个 IO 操作较大 1MB；频繁的垃圾回收</li>
<li>小 IO 占据了所有 IO 的很大一部分<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201215104026.png" alt="20201215104026" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>以往的方案</strong>：以往解决上述问题的方案主要有两类，一类则简单粗暴直接增加 SSD，但成本开销巨大；另一类则是利用相对空闲的 HDD 来吸收部分写，也就是所谓的 SSD 写重定向 SSD-Write-Redirect (SWR)  SoCC 2019，该方案可以一定程度上解决 SSD 队列的阻塞问题，HDD 上的延迟比 SSD 高 3-12 倍，对于大多数需要微妙级延迟的小型写操作来说，这即使不是不可接受的，也显然是不可取的。所以方案目标还是想降低 HDD 的延迟到 SSD 级别。</p>
</li>
<li>
<p><strong>发现</strong>：除了上述问题以外，作者还有对于 HDD 新的发现，一系列连续的、顺序的对 HDD 的写操作呈现出周期性的、阶梯状的写延迟模式（低、中、高），原因主要是因为 HDD 控制器将写操作给缓冲了。这个发现也就意味着 HDD 本身是可以提供微妙级的 IO 写延迟的（如果进行了适当的写操作调度），这时候和 SSD 的写性能相近。这些观察结果促使作者有效地利用 HDD 的这种性能潜力来吸收尽可能多的写操作，从而避免 SSD 的过度使用而不会降低性能。</p>
<ul>
<li>如图所示，无论是多大的 IO 操作，HDD 都表现出了低中高三种延迟模式，且具有很强的周期性，前两种可以视作微秒级的响应，因为写操作一旦被写到内置的控制器 buffer 中就已经认为该写操作完成了。</li>
<li>但是当写缓冲满了之后，host 写操作不得不被阻塞直到缓冲的数据被 flush 到磁盘，造成较慢的写操作，这一发现启发我们充分利用 HDD 的缓冲写提供的性能潜力，在 SSD 上提高性能的同时减少写损失。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201215101124.png" alt="20201215101124" loading="lazy"></li>
<li>测试了不同品牌不同容量的 HDD，发现都有相同的规律，至于为什么有这样的规律，主要是因为 HDD 中有内建的 DRAM，但是 DRAM 中只有很少的一部分容量会被用于缓冲写 IO，剩下的大部分容量主要用于 read-ahead cache 预读缓存、ECC buffer、sector remapping buffer、prefetching buffer，然而，在 HDD 中使用此内置 DRAM 的具体策略(随HDD模型的不同而不同)通常仅为 HDD 制造商专有。幸运的是，写缓冲区的实际大小可以通过分析从外部测量。</li>
<li>成功缓冲写操作后，HDD会立即通知主机请求完成。当缓冲的数据到达阈值之后，HDD 将强制执行刷回，这期间将阻塞后续的写入直到 buffer 被释放。值得注意的是，在空闲一段时间后，由于将数据刷新到磁盘，HDD 缓冲区可能隐式变为空。但是，要显式清空缓冲区，我们可以主动调用 <code>sync()</code> 来强制刷新。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201215115010.png" alt="20201215115010" loading="lazy"></li>
</ul>
</li>
<li>
<p><strong>贡献</strong>：本文基于上述问题和发现，对 HDD 的性能表现进行了建模，提出了一个预测模型来准确地决定下一个写延迟状态（因为 HDD 内置的控制器 Buffer 对于 HOST 而言是完全不可见的，主机只能根据当前的延迟状况判断状态，利用缓冲写周期和当前写状态信息，可以实现对下一次写状态的预测）。基于这个模型，提出了一种写方法， Buffer-Controlled Write approach, BCW 来主动和有效地控制缓冲写，所以在 HDD 的低延迟、中延迟阶段调度数据的写操作，而在高延迟阶段使用填充数据。基于 BCW，设计了一个混合的 IO 调度器（MIOS）来根据写模式、运行时队列长度和磁盘状态自适应地将传入数据引导到 SSD 和 HDD。在真实生产环境下的负载和 Benchmarks 都表明 MIOS 移除了写到 SSD 数据的 93%，减少了 65% 平均延迟和 85% 尾延迟。</p>
</li>
</ul>
<h4 id="design-4">Design</h4>
<h5 id="the-hdd-buffered-write-model">The HDD Buffered-Write Model</h5>
<ul>
<li>建模如下，每个时间序列都以 Sync 操作开始，F 表示可以完全缓冲写入到 HDD Buffer 的阶段，M 则是该 Buffer 越来越接近满的阶段，S 则是 Buffer 已满后续的写入都会被阻塞的阶段。
<ul>
<li>Fast stage lasts for <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">W_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> data written</li>
<li>Mid stage	lasts	for	<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">W_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> data	written<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201216105852.png" alt="20201216105852" loading="lazy"></li>
</ul>
</li>
</ul>
<h5 id="write-state-predictor">Write-state Predictor</h5>
<ul>
<li>F/A : The current write state is F and the buffer is available. Next write state is most likely to be F.</li>
<li>F/U : Although the current write state is F, the buffer is unavailable. Next write state is likely to change to S.</li>
<li>M/A : The current write state is M and the buffer is available. Next write state is most likely to remain M.</li>
<li>M/U : Although the current write state is M, the buffer is unavailable. Next write state should be S.</li>
<li>S : The current write state is S. Next write state will be M with a high probability.</li>
<li>The Sync operation will force the next write state and buffer state back to be F/A in all cases<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201216111112.png" alt="20201216111112" loading="lazy"></li>
<li>通过监视 IO 请求大小和延迟，并计算写缓冲区中的空闲空间确定了当前的写状态，F，M 或 S，也就是说，记录当前写状态(F 或 M)中的 ADW，并与 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">W_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 或 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">W_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 进行比较，以预测下一个写状态。</li>
<li>关于预测准确度的问题，实验表明对于 S 状态的预测相对较低，S 状态的低预测精度是由于当实际的 S 状态被错误地预测为另一种状态时，预测策略倾向于 S 状态以减少性能下降。</li>
</ul>
<h5 id="buffer-controlled-writes">Buffer-Controlled Writes</h5>
<ul>
<li>缓冲区控制写(BCW)是一种 HDD 写方法，它确保用户使用 F 或 M 写状态进行写操作，并避免分配慢写操作。BCW 的核心思想是使缓冲写可控。</li>
<li>激活 BCW 后，将调用 sync() 操作来强制同步以主动清空缓冲区，如果预测处于 F 或 M 状态，BCW 将向 HDD 发送连续的用户写操作，否则，将非用户数据填充到 HDD，直到达到缓冲写的最大设置循环(或无限)序列。如果队列中有用户请求，BCW 按顺序写入它们。写完成后，BCW将它的写大小添加到 ADW，并相应地更新写状态。</li>
<li>在请求稀少的轻量级或空闲工作负载期间，HDD 请求队列将时不时为空，使写流不连续。为了确保按顺序和连续模式缓冲写操作的稳定性和确定性，BCW 将主动地将非用户数据填充到磁盘上写入。填充数据有两种类型：（即使对于每个填充写，BCW 仍然执行写状态预测算法）
<ul>
<li>PF：用于用 4KB 的非用户数据填充 F 和 M 状态，小的 PF 可以尽量减少用户请求的等待时间</li>
<li>PS：用更大的块大小填充 S 状态。例如 64KB 的非用户数据，大的 PS 帮助更快地触发慢写操作</li>
</ul>
</li>
<li>BCW 持续计算当前状态( F 或 M )的 ADW。当 ADW 接近 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">W_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 或 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">W_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 时，意味着硬盘驱动器缓冲写处于快速或中期阶段的末尾。S 写状态可能在多次写之后发生。此时，BCW 会通知调度程序，并使用 PS 主动触发慢写。为了避免用户写操作的长延迟，在这个阶段，所有传入的用户请求都必须被引导到其他存储设备，比如 SSD。S 状态的写完成之后，下一个写操作将为 M，然后 BCW 重新设置 ADW 并再次接受用户请求。</li>
<li>作者发现在 F 状态下 ADW 达到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">W_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 之前没有必要主动地填充写操作。因为这时候物理磁盘操作尚未触发，缓冲区可以在此期间吸收用户请求，短时间之后达到该阈值，这意味着缓冲区将开始将数据刷新到磁盘，下一个写状态将更改为 S。另一方面，当 ADW 长时间小于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">W_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 时，磁盘可以自动刷新缓冲过的数据，以便下一个写状态可能是 F。但是，它不会影响性能。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201216155537.png" alt="20201216155537" loading="lazy"></li>
</ul>
<h5 id="mixed-io-scheduler">Mixed IO scheduler</h5>
<ul>
<li>调度器根据写状态预测器的结果和当前队列状态决定是否将用户写操作引导到 HDD 请求队列。</li>
<li>架构如下所示，MIOS 在运行时监控 SSD 和 HDD 的所有请求队列，明智地触发 BCW 进程，并确定是否应该将用户写操作定向到所选的 HDD 或 SSD。MIOS 在配置过程中在每个 HDD 中创建一个设备文件。设备文件以仅追加的方式存储BCW 写入。在 MIOS 调度之前，执行概要分析来确定写状态预测器的关键参数(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">W_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 或 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">W_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>等)<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201216160553.png" alt="20201216160553" loading="lazy"></li>
<li><strong>调度策略</strong>：SSD 在 t 时刻的请求队列长度 l(t) 是关键参数，当大于预定义的阈值 L，调度器通过预测用户的写状态是 F 或 M 来引导用户写到 HDD。阈值 L 是根据 SSD 上的实际性能测量值预先确定的。设定的标准是，我们测量不同 SSD 队列长度下的写延迟，如果队列长度为 l 的请求延迟大于在 M 状态下，我们只需设置阈值 L 为最小的 l 即可。其基本原理是，当 SSD 队列长度大于 L 时，SSD 写操作的延迟将与 BCW 的 F 或 M 写状态下 HDD 上的延迟相同。L 可以在运行时根据工作负载行为和存储设备配置实验性地确定和调整。此策略虽然不能避免，但可以缓解工作负载激增或繁重时的长尾延迟以及 SSD 上的垃圾回收，在这些情况下，SSD 请求队列长度可能是其平均长度的 8-10 倍。因此，重定向的 HDD 写操作不仅减轻了突发请求和重 gc 带来的 SSD 压力，抑制了长尾延迟，而且还降低了平均延迟。</li>
<li>另外，当SSD的队列长度小于 L 时，可选触发 BCW。在这种情况下，启用或禁用 BCW 分别表示为 MIOS_E 或MIOS_D。换句话说，当 SSD 的队列长度小于 L 时，MIOS_E 策略允许使用 BCW 重定向。MIOS_D 策略相反地可以在 SSD 队列长度小于 L 时关闭重定向。注意，在 M 写状态下的 HDD 的写延迟仍然比 SSD 的要高得多。重定向后的请求延迟可能会增加。因此，当 l(t) 小于 l 时，我们只重定向用户请求以利用 MIOS_E 中 HDD 的 F 写状态。</li>
<li>通常，一个典型的混合存储节点包含多个 SSD 和 HDD。我们把所有的磁盘分成独立的 SSD/HDD 对，每个对包含一个SSD 和一个或多个 HDD。每个 SSD/HDD 对都由一个独立的 MIOS 调度程序实例管理。</li>
<li>最后，MIOS 需要对 HDD 的完全控制。这意味着 BCW 中的 HDD 不会受到其他 IO 操作的干扰。当一个 HDD 正在执行 BCW 并且一个读请求到达时，MIOS 立即挂起 BCW 并提供这个读。此时，它将尝试将所有写操作重定向到其他空闲磁盘。对于以读为主的工作负载，可以禁用 BCW 以避免干扰读操作。</li>
</ul>
<h4 id="个人见解-8">个人见解</h4>
<ul>
<li>SSD/HDD 混合存储的场景其实在工业界的应用极为广泛，但仿佛很少有人关注这种场景下存在的问题，即便是考虑到对于 SSD 的磨损也大多是通过对单一的 SSD 层面上进行优化来减少磨损，而从整个混合存储系统的角度出发，屏蔽器件内部的技术细节，还是在 HDD/SSD 的写调度上发力来减少对 SSD 的消耗，当然关键主要还是对于 HDD 的测试发现了 HDD 本身的性能变化的规律，还是比较巧妙的。</li>
<li>本文的设计与实现其实在对于 HDD 的测试之后就已经呼之欲出了，但作者还是设计了很多细节上的东西来提供了更多实现方面的细节，包括一些具体调度策略的伪代码，使得该方案在工业界落地也成为可能，</li>
</ul>
<h2 id="consistency-and-reliability">Consistency and Reliability</h2>
<ul>
<li>
<p>CRaft: An Erasure-coding-supported Version of Raft for Reducing Storage Cost and Network Cost</p>
<ul>
<li>Zizhong Wang, Tongliang Li, Haixia Wang, Airan Shao, Yunren Bai, Shangming Cai, Zihan Xu, and Dongsheng Wang, Tsinghua University</li>
</ul>
</li>
<li>
<p>Hybrid Data Reliability for Emerging Key-Value Storage Devices</p>
<ul>
<li>Rekha Pitchumani and Yang-suk Kee, Memory Solutions Lab, Samsung Semiconductor Inc.</li>
</ul>
</li>
<li>
<p>Strong and Efficient Consistency with Consistency-Aware Durability</p>
<ul>
<li>Aishwarya Ganesan, Ramnatthan Alagappan, Andrea Arpaci-Dusseau, and Remzi Arpaci-Dusseau, University of Wisconsin–Madison</li>
<li><strong>Awarded Best Paper!</strong></li>
</ul>
</li>
</ul>
<h3 id="craft-an-erasure-coding-supported-version-of-raft-for-reducing-storage-cost-and-network-cost">CRaft: An Erasure-coding-supported Version of Raft for Reducing Storage Cost and Network Cost</h3>
<ul>
<li>因为很久没单开分布式的文章的坑了，所以干脆拿这篇作为一个 Motivation，然后把 Raft、Paxos 也总结一下。虽然这篇文章跟 EC 有很大关系，但是更多的还是解决一致性的一些问题吧。</li>
<li>完成之后此处贴链接。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[FileMR: Rethinking RDMA Networking for Scalable Persistent Memory]]></title>
        <id>https://blog.shunzi.tech/post/NSDI20-FileMR/</id>
        <link href="https://blog.shunzi.tech/post/NSDI20-FileMR/">
        </link>
        <updated>2020-10-05T08:37:41.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>NSDI 2020 的文章 FileMR: Rethinking RDMA Networking for Scalable Persistent Memory</li>
<li>这篇论文主要结合了 RDMA 和 NVM，针对各自的特性进行了整合重组，修改相应的协议实现</li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>NSDI 2020 的文章 FileMR: Rethinking RDMA Networking for Scalable Persistent Memory</li>
<li>这篇论文主要结合了 RDMA 和 NVM，针对各自的特性进行了整合重组，修改相应的协议实现</li>
</ul>
</blockquote>
<!--more-->
<h2 id="abstract">Abstract</h2>
<ul>
<li><strong>问题</strong>：NVM 和 RDMA 看起来天作之合。大容量持久性内存 + 远程内存访问。但实际上现有的 NVMM-aware 的文件系统使用文件来管理 NVM，RDMA 而是以 Memory Regions 的形式进行组织访问。因此要想构建 可使用 RDMA 访问的 NVMM 则需要实现代价较高的转换层，代价高是因为会有大量重复的工作需要做，如跨越权限、命名和地址转换。</li>
<li><strong>贡献</strong>：在现有的 RDMA 协议基础上引入了两个变化：FileMR (file memory region) 和  range-based address translation。这两个优化点将内存区域和文件结合起来实现了内存抽象，即一个客户端可以通过 RDMA 直接访问一个由 NVMM 作为后端存储设备支持的文件，通过文件偏移进行内存寻址，从而消除了重复的地址转换，减小了在网卡上完成的地址转换的数量，减小了网卡中的地址转换缓存的负载，提升了命中率约 3.8x - 340x，应用性能相应提升了 1.8x - 2.0x</li>
</ul>
<h2 id="introduction">Introduction</h2>
<ul>
<li>可伸缩计算机系统存储和访问数据的方式近年来变化迅速，而这些变化的部分原因是传统独立的系统组件之间的界限越来越模糊。NVM 模糊了内存和存储之间的界限，RDMA 模糊了本地和远端内存之间的界限。NVM+RDMA 仿佛组合起来就能整合内存、存储、网络来提供一个大规模的稳定的字节寻址的网络直连的内存。不幸的是，用于管理这些技术的现有系统同时存在重叠和不兼容的情况。</li>
<li>NVMMs 合并内存和存储。该技术允许应用程序使用加载/存储指令访问持久数据，避免了传统存储系统使用的基于块的接口。而 NVMM 通常被一个基于 NVMM 的文件系统来管理，文件系统来负责对存储设备的访问，应用只需要使用文件系统的相关接口即可。应用程序可以将一个文件映射到它们的地址空间，然后使用 load 和 store 指令访问它，这大大减少了访问持久性数据的延迟。</li>
<li>RDMA 合并了本地和远端的内存。RDMA允许客户端直接访问远程服务器上的内存。一旦远程服务器决定允许传入访问，它将其地址空间的一部分注册为 RDMA 内存区域，并向客户机发送访问该区域的密钥。使用密钥，客户端可以利用服务器的 RDMA 网络接口(RNIC) 绕过 CPU 直接读写服务器的内存。RDMA之所以流行，是因为它将大部分网络栈转移到硬件上，并提供了接近硬件的抽象，与 TCP/IP 协议相比，它表现出更好的延迟。</li>
<li>基于 NVM 的文件系统和 RDMA 在设计之初没有考虑过两者的结合，所有如果将他们直接结合起来就会出现很多重复的工作。虽然只有 RDMA 提供网络数据传输和只有 NVMM 文件系统提供持久内存元数据，但两个系统都实现了保护、地址转换、命名和跨不同内存抽象的分配，RDMA 基于 Memory Region，NVMM Filesystem 基于 File。天真地同时使用RDMA 和 NVMM 文件系统会导致重复工作和它们抽象之间的低效转换层。这些转换层代价极高，特别是因为 RNIC 只能为有限的内存提供转换，而 NVM 的容量可以非常大。</li>
<li>所以我们提出了 FileMR，通过实现新的内存区域类型，它将RDMA 需要的大多数与内存管理相关的任务卸载到 NVM 文件系统，从而实现这一目标;文件系统从而有效地成为 RDMA 的控制平面。FileMR 直接以文件代替 RDMA 访问过程中的 Memory Region，读写直接通过文件系统被定向到文件，并使用文件偏移来进行寻址。文件偏移和物理内存地址之间的转换则还是由 NVMM 文件系统来保证。对文件的访问还是由 NVM 文件系统来管理，使用原生的 ACL 来实现访问保护。为了进一步优化地址转换，我们将基于范围的转换系统集成到 RNIC 中，该系统使用地址范围(而不是页面 pages)进行转换，从而减少了地址转换所需的空间 space，并解决了 RDMA 和 NVMM 文件系统之间的内存抽象不匹配问题。</li>
<li>该方案相比于原生的 RDMA+NVMM 的组合，带来了以下好处：
<ul>
<li>NIC 上完成的地址转换数量降低，从而减轻了 NIC 的地址转换缓存的负载，提升缓存命中率 3.8x - 340x</li>
<li>使用现有的文件系统 ACL 机制来替代了 RDMA 的 ad-hoc memory keys，从而简化了内存保护机制</li>
<li>通过使用持久性的文件代替了短暂的内存区域 IDs，从而简化了连接的管理</li>
<li>允许在不撤消权限或关闭连接的情况下移动或扩展网络可访问内存，从而使文件系统能够整理碎片并向文件追加内容。</li>
</ul>
</li>
</ul>
<h3 id="rdma-networking">RDMA Networking</h3>
<ul>
<li>RDMA 硬件支持一组操作，如单边原语 read/write，无需远程 CPU 的参与就可直接访问远端内存，事实上是完全绕过了远端 CPU。还有双边原语，要求两台机器发起匹配的请求，比如 send/receive，通过本地发送方和接收方应用程序选择的地址在已注册的缓冲区之间传输数据。</li>
<li>为了建立 RDMA 连接，应用程序注册一个或多个内存区域(MRs)，授权本地 RNIC 访问本地地址空间的，MR 既是一个命名空间又是一个安全域：为了让客户访问一个区域，本地 RNIC 提供 MR 的虚拟地址、内存大小和一个特殊的 32 位“rkey”。Rkeys 在任何单边原语发送过程中就被发送，并允许接收端 RNIC 验证客户端是否有直接访问该区域的权限。对于双边原语，send/recv 操作要求发送方和接收方都发布匹配的请求，每个请求都附加到某个本地的、预先注册的内存区域，从而消除对 rkey 的需求。</li>
<li>为了管理未完成的请求，RDMA使用来自虚拟接口体系结构（VIA）的工作队列，应用在建立连接之后，可以通过本地 RNIC 发布工作队列项 WQEs 来初始化一个 RDMA 原语。这些项被写入到一组队列中，也就是所谓的 QP，一个 Queue 用于 send/write 请求，一个 Queue 用于 read/receive 请求。一旦 WQE 被写到 QP 中，RNIC 将执行 RDMA 原语并访问远程机器。一旦原语完成，RNIC 将通过放置一个 completion 标志在 completion queue (CQ) 中来确认原语成功处理。应用程序可以从完成队列轮询完成，以接收谓词成功完成的通知。</li>
</ul>
<h5 id="参考链接">参考链接</h5>
<ul>
<li><a href="https://blog.csdn.net/qq_21125183/article/details/80563463">[1] CSDN - 深入浅出全面解析RDMA</a></li>
</ul>
<h3 id="nvm">NVM</h3>
<ul>
<li>NVMM 是持久性的存储介质，需要管理软件提供 naming, allocation 以及 protection 等功能，NVMM 通常由文件系统来管理，但和之前基于较慢的块设备构建的文件系统有一些不一样，支持 NVMM 的文件系统在提供高效的 NVMM 访问过程中扮演了重要的角色，接近 DRAM 延迟的 NVMM 意味着软件开销将显著影响整体的性能，因此支持 NVMM 的文件系统在关键路径上尽可能减小软件开销的方式大致有两种：
<ul>
<li>支持直接访问 mmap() (DAX-mmap)功能。DAX-mmap 允许应用将 NVMM 文件直接映射到他们自己的地址空间，并通过简单的 load/stores 指令来执行数据的访问。该模式允许应用对于大多数数据访问可以直接绕过内核和文件系统，显著提高了文件访问的性能。</li>
<li>NVMM 驻留在内存层次结构中，这可能会导致并发症，因为缓存不是持久的，但可以保存应用程序希望持久保存的数据。为了让数据持久化，对 NVMM 的缓存写操作之后必须执行缓存行刷新或清理指令，以确保实际将数据写回 NVMM，而非临时写操作可以完全绕过 CPU 缓存。store fence 可以强制保证执行写操作的顺序，并保证数据在断电时仍然有效。</li>
</ul>
</li>
</ul>
<h3 id="managing-rdma-and-nvmm">Managing RDMA and NVMM</h3>
<ul>
<li>用户空间 RDMA 访问和 NVMM mmapped-DAX 访问共享一个关键功能:它们允许直接访问内存，而不涉及内核。一般来说，我们可以将 NVMM 文件系统和 RDMA 划分为访问内存的数据平面和管理向用户应用程序公开的内存的控制平面。两者的数据平面实际上是相同的:它由直接的对内存的 load 和 store 组成。相比之下，不同系统之间的控制平面差别很大。</li>
<li>对于RDMA和NVMM文件系统，控制平面必须为内存管理提供四种服务。
<ul>
<li>naming: 确保应用程序能够找到要直接访问的适当内存区域</li>
<li>access control: 阻止应用程序访问它不应该访问的数据</li>
<li>allocation: 提供一种机制来分配和释放资源，扩大或缩小为应用程序可用内存</li>
<li>translation: 必须在应用程序级名称(例如，虚拟地址，或内存和文件偏移量)与物理内存地址之间进行转换.意味着 RDMA 和 NVMM 文件系统必须与虚拟内存子系统紧密合作</li>
</ul>
</li>
<li>下表展示了 RDMA 和 NVMM Filesystem 已经提供的功能，总结了控制平面需要支持的元数据操作。但是内存管理功能被关联到了 RDMA 和 NVMM FS 不同的内存抽象上，RDMA 使用了 Memory Region 或者 Memory Windows，而 NVMM FS 使用了文件。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201004222708.png" alt="20201004222708" loading="lazy"></li>
</ul>
<h4 id="naming">Naming</h4>
<ul>
<li>Naming 提供了一种独立于硬件的方式来引用物理内存，在 RDMA 应用中，memory region 的虚拟地址是和其主机地址一起的，如 IP or GID，从而作为一个全局的有意义的物理内存区域的命名。这些命名的生命周期是短暂的，因为当创建该命名的应用退出的时候命名也就失效了；命名同时也不够灵活，因为它们防止 RDMA 公开的页面在可访问时更改其虚拟地址到物理地址的映射。为了与希望通过读和写直接访问名称的客户机共享 Naming，主机提供 MR 的元数据，对于双边原语(例如，发送/接收)，Naming 是特别的:接收方必须使用带外通道来决定将接收到的数据放在哪里。</li>
<li>基于 NVMM 的文件系统使用文件名来命名主机上的内存区域，由于文件的寿命比应用程序长，因此文件系统独立于应用程序管理命名，并为命名内存区域提供更复杂的管理（例如分层目录和基于文本的名称）。为了访问一个文件，客户端和应用必须通过文件来访问</li>
</ul>
<h4 id="permission">Permission</h4>
<ul>
<li>权限决定哪个进程有权限访问哪一块内存。在 RDMA 中，RDMA上下文是隔离的，权限通过两种方式执行：
<ul>
<li>为了授予客户端对内存位置的直接读/写访问权，主机共享内存区域特定的“rkey”。rkey 是一个和所有的单边原语关联的 32位的 key，会被 RNIC 验证是否有权限访问对应地址的内存区域。对于每一个注册了的区域，RNIC 驱动都会维护一个 rkey，和其他 RDMA 元数据一起在 DRAM 的硬件可访问数据结构中提供隔离和保护。</li>
<li>当两个节点之间建立起了 RDMA 连接的时候，Permissions 也被建立，由应用程序代码在建立连接的时候授权，权限不会比进程的寿命长，如果系统重启也会丢失。保护双边原语是由接收应用程序以一种特别的方式执行:接收方使用一个带外信道来决定发送方有哪些权限。</li>
</ul>
</li>
<li>NVMM 的访问控制使用传统的文件系统设计，权限被关联到每一个文件，并针对每个用户或者用户组单独设计。与 RDMA 内存区域和它们的 rkey 不同，权限是底层数据的一个属性，并且在进程和系统重启后仍然存在。</li>
<li>文件系统主要使用了 Permission Bits 和 Access Control Lists 来进行访问控制。延伸阅读 <a href="https://blog.shunzi.tech/post/basic-of-persistence-three/">Series Three of Basic of Persistence - Files and Directories</a></li>
</ul>
<h4 id="allocation">Allocation</h4>
<ul>
<li>RDMA 原语和 NVMM 文件都直接访问内存，所以可用内存的分配和扩充对于两者都是一个重要的元数据操作。</li>
<li>NVMM 文件系统中维护了一个空闲物理页的列表，可以用于创建或者扩展文件。文件的创建涉及到编组适当的资源，并将新页面链接到现有的文件层次结构中，类似地，可以将空闲页面链接到现有文件或将其与现有文件分离，以扩大或缩小文件。通过调用 fallocate 和 mremap，也可以很容易地更改 DAX-mmap 文件的大小。</li>
<li>创建一个新的 RDMA 内存区域包括分配所需的内存资源、固定它们的页面和生成 rkey。需要注意的是尽管许多 RNICs 可以处理物理地址，但是内存区域的物理地址经常不受程序员控制（关键取决于 malloc 的实现方式），页面一旦被固定到了注册的区域，就将导致物理地址空间的碎片。</li>
<li>除此之外，改变内存区域的映射开销很大。例如，为了提升内存区域的大小，主机端的服务器通常需要先解除内存区域的注册，然后重新注册一个更大的区域，再将相应的变化发送给客户端。<code>rereg_mr</code> 原语包括了解除注册和重新注册的步骤，但是仍然会有很大的开销。带公共内存池的 MPI 应用使用了内存窗口在内存区域的上层来提供动态的访问控制。这种方法不能与 NVMM 文件系统混合使用，因为它仍然需要底层内存区域的静态映射。</li>
<li>程序员也可以把其他内存与添加到当前连接或者保护域中，由于内存区域需要不可忽略的元数据，并且 RDMA 不支持多区域访问，因此这种解决方案显著增加了复杂性。</li>
<li>这种固定的大小限制还阻碍了常见的文件系统操作和优化，例如附加到文件、重新映射文件内容和碎片整理</li>
</ul>
<h4 id="address-translation">Address Translation</h4>
<ul>
<li>如下图所示，RDMA 通过将虚拟地址固定到物理地址来解决地址转换的问题，也就是说，只要注册了一个内存区域，它的虚拟地址和物理地址就不能改变。一旦这个映射被固定，RNIC 就能够直接处理在虚拟地址范围上注册的内存区域：RNIC 为传入的 RDMA 原语从虚拟地址转换为物理地址。为了完成这个转换，NIC 维护了一个内存转换表 memory<br>
translation table(MTT)，它保存了系统页表的一部分。</li>
<li>MTT 将 RDMA 可访问的页面相关的地址转换条目扁平化，且可以缓存在 RNIC 的板载 SRAM 来加速这个映射的查找。pin-down 缓存对于 RDMA 获得良好性能至关重要，该缓存通常很小，几个 MB，如果缓存不命中开销将会很大，因为其对应的地址转换机制，大多数 RNICs 要求一个 region 的所有页都得是相同的大小，为了回避这些限制，研究者们做了大量的工作试图尽可能地利用缓存来寻址大内存。尽管存在复杂的解决方案，但最常见的建议是减少所需的地址转换数量，例如使用大页面或物理地址来寻址大型连续内存区域来减少地址转换的次数。</li>
<li>NVMM 文件系统处理地址转换有两种方式，都和 RDMA 有所不同。
<ul>
<li>对于常规的读和写操作，文件系统使用偏移量来将文件名转换成物理地址，地址转换在内核中由系统调用完成。</li>
<li>对于映射内存的访问，mmap 从用户空间直接向 NVMM 上的文件内容建立了虚拟到物理地址的映射。只有在用户和物理地址之间缺少转换时，文件系统才会发起缺页中断，在正常的数据访问中，文件系统被绕过。</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201005110858.png" alt="20201005110858" loading="lazy"></figure>
<ul>
<li>不同的转换方案相互干扰，从而产生性能问题。如果一个页通过 RDMA 访问，那么该页将被固定到了一个特定的物理地址，除此以外，内存区域内的每个页的大小还必须相同，因此文件系统不能更新打开的了的文件的数据布局（譬如对文件进行碎片整理或扩容）。 由于 RDMA 阻碍文件的碎片整理，并且禁止在 RDMA 可访问内存中混合页面大小，由文件支持的内存区域必须使用许多小页面来寻址较大的区域，压倒了 pin-down 缓存并削弱了 RDMA 性能。</li>
<li>下图展示了 pin-down cache 不命中对 RDMA 写吞吐量的影响。每个工作请求向随机的 8 字节对齐偏移量写入 8 字节。当内存区域大小为 16 MB 时，使用 4kB 可以达到基准性能的 61.1%(发送物理地址、没有 TLB 或 pin-down cache 缓存丢失)，而使用 2 MB 的大页面时有95.2%。当区域大小达到 16 GB 时，即使是 2 MB 的页面也不够——只能达到 61.2% 的性能。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201005112650.png" alt="20201005112650" loading="lazy"></li>
</ul>
<h2 id="design">Design</h2>
<ul>
<li>FileMR 是一种扩展了 RDMA 协议的内存区域新类型，提供针对 NVMM 的基于文件的内存抽象。它需要对现有的 RDMA 协议进行较小的更改，并且不依赖于任何特定的文件系统设计，FileMR 可以与传统的 RDMA 内存区域共存，确保向后兼容性。</li>
<li>FileMR 通过一些创新解决了 RDMA 和 NVMM 文件系统之间的冲突，这些冲突会导致不必要的限制和性能下降。
<ul>
<li><strong>Merged control plane</strong>：客户端使用文件偏移来寻址内存，代替虚拟或物理地址，FileMR 还利用文件系统的命名、寻址和权限来流水线化 RDMA 访问。</li>
<li><strong>Range-based address translation</strong>：FileMR 利用文件系统的高效、基于区段的布局描述机制来减少 NIC 需要保留的状态数量。由于文件已经被组织成连续的区段，我们将这种寻址机制扩展到 RNIC，允许 RNIC 的 pin-down 缓存使用空间高效转换方案来寻址大量的 RDMA 可访问内存</li>
</ul>
</li>
</ul>
<h3 id="assumptions-and-definitions">Assumptions and Definitions</h3>
<ul>
<li>FileMR 作为跨用户空间应用程序、系统软件和 RDMA 网络堆栈的高效和协调的内存管理层。本文假设 NVMM 是由系统软件主动管理的，我们将其描述为一个文件系统。注意，文件系统的概念是松散定义的:FileMR 可以与内核文件系统、用户空间文件系统或用户空间访问原始 NVMM(也称为device-DAX)并提供命名的 NVMM 库集成，其中文件映射到对应的实体。</li>
<li>本文假设 NVMM 在其整个生命周期中映射到应用程序地址空间：NVMM 最突出的特点是以非常低的成本获得细粒度的持久性。FileMR 的设计目标是支持远程 NVMM 访问，同时保持本地 NVMM 访问的简单性和效率。另一种方法是构建管理这两种存储的整体系统 (NVMM) 和网络 (RDMA)</li>
</ul>
<h3 id="filemr">FileMR</h3>
<ul>
<li>新的内存抽象 FileMR 既是一个 RDMA 内存区域，又是一个 NVMM 文件，这允许 RDMA 和 NVMM 控制平面以实现顺畅的交互操作。对FileMR 的 RDMA 访问是通过文件偏移来寻址的，文件系统管理底层文件的访问权限、命名和分配，就像管理任何文件一样。NVMM 文件始终由文件系统管理的物理页面支持，因此，在使用 FileMR 时，RDMA 子系统可以简单地重用文件系统元数据中已经可用的转换、权限和命名信息，以便进行适当的检查和寻址。</li>
<li>如下图所示描述了 FileMR 中的元数据和数据访问。
<ul>
<li>对于元数据，初始化内存区域的流程如下
<ul>
<li>step1. 在创建 FileMR 之前，应用带着对应的权限去打开对应的后端文件</li>
<li>step2. 应用创建 FileMR (File Memory Region)</li>
<li>step3. 将对应的 region 绑定到文件上，将 FileMR 绑定到文件会产生一个类似于 rkey 的 filekey，远程客户端可以使用它来访问 FileMR</li>
<li>step4. 创建了 FileMR 并将其绑定到后端文件之后，文件系统将使文件的寻址信息与 RNIC 保持同步</li>
</ul>
</li>
<li>对于数据：对于远程 FileMR 及其后端 NVMM 文件的数据访问，应用程序使用 FileMR (带有 filekey 来证明其权限)和文件偏移量来访问，RNIC 使用由文件系统提供的地址转换信息来在文件偏移和物理内存之间转换。除了对 FileMR 的 read/write 单边原语以外，引入了一个新的单边原语 append，来增大对应的内存区域。当发送一个 append 原语的时候，客户端不包含远程地址，服务端处理该原语类似于处理对地址等于当前 FileMR 大小的写原语，然后更新 FileMR 的大小并通知文件系统。一个优化点，为了防止在每个 append 消息上出错，文件系统可以预先分配超出文件大小的地址转换项，即使在通过 FileMR 打开并访问后端我文件时，本地应用程序仍然可以使用普通的文件系统调用或映射的地址继续访问它，对文件元数据的任何更改都将传播到 RNIC。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201005114907.png" alt="20201005114907" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="range-based-address-translation">Range-based Address Translation</h3>
<ul>
<li>NVMM 文件系统尝试在 NVMM 中以大的线性区段存储文件数据。FileMR 在 MTT 和 pin-down cache 中分别使用基于范围的地址转换 RangeMTT, range pin-down cache。这一变化与传统 RDMA 基于页的寻址方式有很大的不同。基于页面的转换使用一组固定大小的页面将虚拟地址转换为物理地址，而基于范围的转换(在cpu端转换中探索和使用)不同于基于页面的转换，它将可变大小的虚拟地址范围映射为物理地址。当寻址很大的线性内存区域的时候，基于范围的地址缓缓就十分有用，并且能够利用已经存在的基于 extent 的文件组织。</li>
<li>对于 FileMR，基于范围的地址转换有两个主要的好处，存储映射所需的空间和 用可变大小的区段数量(而不是固定大小的页面数量)注册映射比例所需的时间。在 MTT 和 pin-down cache 中注册一个页大概需要花费 5 微妙，该过程需要对内存描述符加锁，而且很难并行化。因此，单核只能注册 4KB 的页以 770MB/s 的速度。如果是 TB 级的 NVMM，结果注册时间会长到无法接受的程度。</li>
</ul>
<h3 id="design-overview">Design Overview</h3>
<ul>
<li>下图灰色部分展示了原生 RDMA 堆栈，绿色部分则是在 FileMR 中做的一些必要的改变。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201005145015.png" alt="20201005145015" loading="lazy"></li>
<li>为了支持 FileMR 的抽象，文件系统要求实现 <code>bind()</code> 函数来关联一个 FileMR 和一个 File，在必要时，当绑定文件的元数据通过回调发生变化时通知 RDMA 堆栈(最终是 RNIC 的 RangeMTT 和 pin-down 缓存)。这些回调允许 RNIC 为传入的 RDMA 请求维护正确的基于范围的物理地址映射</li>
<li>可选地，文件系统还可以注册一组回调函数，当 RNIC 无法找到传入地址的转换项时触发。这个过程类似于按需分页，需要它来支持新的 append ，它既修改文件布局，又写入文件<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201005152720.png" alt="20201005152720" loading="lazy"></li>
<li>支持 FileMR 抽象还需要更改 RNIC 硬件。在我们提出的 RangeMTT 中，RNIC 硬件和驱动程序需要在 MTT 和pin-down 缓存中采用基于范围的寻址。基于范围的硬件寻址方案可以用来实现基于范围的地址查找。我们使用了软件 RNIC 进行模拟测试。</li>
<li>FileMR 还向 RDMA 接口本身添加了增量的、向后兼容的更改。如下表所示，它为内存区域创建添加了一个新的访问标志，以标识 FileMR 的创建，创建后，FileMR 被标记为处于未配置状态。对文件系统的后续 <code>bind()</code> 调用将在RangeMTT 中分配 FileMR 的转换条目(通过来自文件系统的<code>cm_bind</code>回调)。<code>bind()</code> 方法可以通过 <code>ioctl()</code>(用于内核级文件系统)或库调用(用于用户级文件系统)实现。FileMR 还添加了新的 RDMA 单边原语 Append。将现有应用程序转换为使用 FileMRs 很容易，因为应用程序只需要更改其区域创建代码<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201005162220.png" alt="20201005162220" loading="lazy"></li>
</ul>
<h2 id="implementation">Implementation</h2>
<ul>
<li>为了实现 RangeMTT，我们遵循了冗余内存映射中引入的设计:每个 FileMR 指向存储了偏移量和长度的b树，我们使用这些偏移量作为索引。所有 RangeMTT 条目都是页面对齐的地址，因为 OS 只能以页面粒度管理虚拟内存</li>
<li>与页面对齐的 RangeMTT 不同，FileMR 支持任意大小并允许子页面文件/对象。每个 RangeMTT 条目由一个页面地址、一个长度字段和必要的位组成。这些条目没有重叠，对于稀疏的文件可能会有间隙。</li>
<li>为了支持 append 原语，FileMR 允许超出其大小的地址转换项。Append 是单边原语，不会在 WR 具体指定远程服务器的地址。在服务器端，RNIC 总是尝试 DMA 到当前的大小 FileMR，并在成功时增加其大小。当地址转换 missing，当IOMMU可用时，服务端可能会发起一个 IO 缺页中断，并且将调用文件系统例程来完成中断条目的处理。或者，如果这种支持不可用，服务器将通过类似于接收端未就绪(RNR)错误的消息向客户端发送信号。</li>
<li>Soft-RoCE 将 MTT 条目管理为一个 64 位物理地址的平面数组，查找复杂度为O(1)。我们发现在硬件 RNIC 驱动程序如 mlx4 中也实现了类似的设计。对于具有范围 pin-down 缓存缺失的 FileMR，条目查找将以更高的时间复杂度遍历已注册的数据结构(O(log(n)))</li>
<li>由于映射是在 DRAM 中，Soft-RoCE 不具有 pin-down 缓存。为了模拟 RangeMTT，我们构建了一个<br>
4096 项 4 路关联缓存用于模拟传统的定位缓存，以及用于 FileMR 的 4096 项 4 路关联范围定位缓存。每个范围转换条目由一个 32 位的页面地址和一个 32 位的长度组成，这允许最大的 FileMR 大小为 16TB (4 kB页)或 8PB (2 MB页)。</li>
<li>我们适配了两个应用程序来使用 FileMR。对于内核文件系统，我们的实现基于NOVA，这是一个成熟的内核空间 nvmm感知文件系统，具有良好的性能。我们还将 FileMR 修改为 libpmemlog (pmdk 的一部分，pmdk 是一个管理本地持久对象的用户级库)，以构建可远程访问的持久日志。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201005165841.png" alt="20201005165841" loading="lazy"></li>
</ul>
<h3 id="remote-file-access-in-nova">Remote File Access in NOVA</h3>
<ul>
<li>NOVA 是一种符合 posix 的日志结构本地 NVMM 文件系统。在 NOVA 中，每个文件都组织为一个持久日志，其中包含大小不一的区段，这些区段驻留在持久内存中。文件数据由文件系统通过每个 cpu 空闲列表分配，并作为合并条目进行维护。</li>
<li>为了处理远程文件系统上的元数据操作，我们添加了一个用户级守护进程 novad，该进程打开文件以建立 FileMR，并接收来自远程应用程序的任何元数据更新（譬如目录创建），并将这些应用到本地文件系统上。</li>
<li>在客户端，应用程序通过与 novad 通信并接收 filekey 来远程打开文件。然后它可以发送单方面的 RDMA 原语来直接远程访问 NVMM。同时，本地运行的应用程序仍然可以使用传统的 POSIX IO 接口访问文件，或者将文件映射到它的地址空间，并发出加载和存储指令。</li>
<li>我们的组合系统也可以轻松处理数据复制。通过使用几个 FileMRs，我们可以简单地复制一个原语(具有相同或不同的filekey，具体取决于文件系统实现)并发送到多个主机，而无需考虑文件的物理地址(只要它们的名称相等)。</li>
</ul>
<h3 id="remote-nvmm-log-with-libpmemlog">Remote NVMM Log with libpmemlog</h3>
<ul>
<li>FileMR 抽象只要求后端的“文件系统”适当地实现 <code>bind()</code> 方法，RNIC 回调，并可以访问原始 NVMM。例如，可以由能够访问原始 NVMM 设备的应用程序创建 FileMR。在本节中，我们将利用这种灵活性并基于 libpmemlog 构建远程 NVMM 日志</li>
<li>我们修改 libpmemlog 的分配器以使用必要的 FileMR 回调。也就是说，每当为日志分配或释放内存时，RNIC 的RangeMTT 都会更新。客户端使用新的 append 谓词追加到日志。在服务器端，当 FileMR 大小在映射的 RangeMTT 范围内时, RNIC 绕过服务器应用程序时可以进行地址转换。如果没有，则发生范围故障，并且库通过分配和映射额外的内存来扩展该区域</li>
</ul>
<h2 id="evaluation">Evaluation</h2>
<ul>
<li>DRAM 模拟 PM</li>
<li>2 Intel Xeon (Broadwell) CPUs with 10 cores and 256 GB of DRAM（64 GB configured as an emulated NVMM device）</li>
<li>Soft-RoCE,  Intel X710 10GbE NIC</li>
</ul>
<h3 id="registration-overhead">Registration Overhead</h3>
<h4 id="allocated-regions">Allocated Regions</h4>
<ul>
<li>这个实验演示了当应用程序直接分配和映射文件而不更新其元数据时的用例。对于 FileMR，我们还包含了从 NOVA 日志中生成范围条目的时间，这在应用程序第一次打开文件时发生。</li>
<li>结果表明 注册一个大的内存区域会消耗大量的时间。主要是由于文件系统分配器的内部碎片。它花费 30 秒注册一个64gb 的持久性(文件)和易失性的具有 4 kB页面的(Alloc-4K)内存区域。使用 hugepages (alloc-2M)将注册成本降低到 20秒，而 FileMR 只需要67毫秒(低3个数量级)。</li>
<li>对于小文件，NOVA 只为文件创建一个或两个区段，而传统的 MRs 仍然与操作系统的虚拟内存例程交互，从而造成开销<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201008092601.png" alt="20201008092601" loading="lazy"></li>
</ul>
<h4 id="data-fragmentation">Data Fragmentation</h4>
<ul>
<li>FileMR 得益于文件数据的连续性。文件系统的内部碎片可能有两个原因:文件系统老化和使用频繁更改文件布局的POSIX IO。为了测试 FileMR 在碎片化的文件系统上的性能，我们先使用了四个敏感的发起 POSIX IO 操作的负载来让文件系统产生碎片。完成之后，我们再在所有的 NVMM 文件上创建内存区域。使用了如下负载：<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201008093333.png" alt="20201008093333" loading="lazy"></li>
<li>结果如下所示：在碎片化的文件上运行 FileMR 仍然显示了显著的的改善，在 region 注册时间和内存消耗 MTT 条目上。
<ul>
<li>Fileserver 演示了许多文件的情况，其中FileMR 只创建传统内存区域条目的 0.5%，并且只需要 6.8% 的注册时间</li>
<li>Metadata heavy 工作负载(Varmail), FileMR 条目的数量只减少了 3%(由于严重的内部碎片和小文件大小), 但它仍然可以节约 20% 的注册时间，因为它拥有索引节点锁，减少争用</li>
<li>Redis 是一个键值存储，它在 IO 路径上持久化一个附加文件，并异步刷新数据库——少量的内部碎片意味着它只需要传统内存区域 2% 的空间和时间。</li>
<li>类似地，SQLite 也使用日志记录，这导致很少的碎片，并且极大地节省了空间和时间。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201008093407.png" alt="20201008093407" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="translation-cache-effectiveness">Translation Cache Effectiveness</h3>
<ul>
<li>RDMA 在大型 NVMM 上的性能下降主要是由于 pin-down 缓存丢失造成的。由于 Soft-RoCE 在 UDP 中封装 RDMA 消息，并在 DRAM 中访问所有 RDMA 状态，因此我们不能通过端到端性能来衡量缓存的有效性。</li>
<li>相反，我们为 FileMR 测量模拟的向下缓存和范围向下缓存的缓存命中率。我们收集对表5中描述的工作负载的POSIX IO 系统调用的跟踪，并使用单向 RDMA 原语对远程主机 replay 它们。</li>
<li>下图展示了测试结果，range-based 的 pin-down cache 远好于 page-based pin-down cache。对于比较大的分配的文件，也就意味着更少的地址转换表项，range-based pin-down cache 的命中率接近达到了 100%<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201008094125.png" alt="20201008094125" loading="lazy"></li>
</ul>
<h3 id="accessing-remote-files">Accessing Remote Files</h3>
<ul>
<li>为了测试数据路径上的性能，我们让客户端访问运行 novad 的远程服务器上的文件。客户机使用 RDMA 写谓词发出随机的 1KB 写操作，我们测量客户机应用程序发出谓词和远程 RNIC DMAs 到目标内存地址(memcopy for Soft-RoCE)之间的延迟。我们将 FileMR 与映射本地访问和其他提供分布式存储访问的分布式系统进行了比较。所有这些系统都通过在链路上上发送物理地址来避免转换开销。</li>
<li>如下所示，延迟分解结果如下。注意，所有系统的延迟都比典型的 RDMA NIC 要高，因为 Soft-RoCE 比真正的 RNIC效率低。此外，我们省略了 UDP 包封装和交付的延迟，这控制了端到端延迟。它只需要1.5 微妙就可以将 4kB 的数据存储并持久化到本地 NVMM。FileMR 延迟更低，因为它消除了任何间接层的需要（Mojim 需要系统调用 msync，LITE 需要共享内存写入，Orion 需要进行 POSIX 写 ）<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201008094720.png" alt="20201008094720" loading="lazy"></li>
</ul>
<h3 id="accessing-remote-nvmm-logs">Accessing Remote NVMM logs</h3>
<ul>
<li>我们使用引入的远程日志实现来评估引入的新 append 谓词。我们比较基线 libpmemlog 使用本地NVMM(绕过网络),以及日志的 HERD RPC RDMA library。</li>
<li>如下所示了创建 64 字节日志项的延迟分解。使用 libpmemlog 花费大概 5.5 微妙来在本地进行日志记录。FileMR为远程日志和本地日志增加了 53% 的开销，HERD RPC-based 增加了 192% 的开销<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20201008095529.png" alt="20201008095529" loading="lazy"></li>
</ul>
<h3 id="discussion">Discussion</h3>
<ul>
<li>本章节讨论了软件模拟和实际硬件的差距，即该方案如果要像应用在实际的物理硬件上会有哪些问题与挑战，感兴趣请阅读原文。</li>
</ul>
<h3 id="related-work">Related Work</h3>
<ul>
<li>该章节介绍了大量的实验对比对象，以及一些思想的起源。</li>
</ul>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>NVMM 和 RDMA 系统之间元数据管理的冲突会导致昂贵的转换开销，并阻止文件系统更改其布局。这项工作引入了对现有RDMA协议的两个修改：:基于FileMR和范围的转换，从而提供了一种结合内存区域和文件的抽象。它通过消除无关的转换提高了 RDMA 可访问 NVMMs 的性能，同时为 RDMA 提供了其他好处，包括更有效的访问权限和更简单的连接管理。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RADOS 读写流程]]></title>
        <id>https://blog.shunzi.tech/post/rados-io-path/</id>
        <link href="https://blog.shunzi.tech/post/rados-io-path/">
        </link>
        <updated>2020-09-22T07:33:52.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<ul>
<li>本篇主要总结 RADOS 底层的读写流程，并结合源码进行分析</li>
<li>考虑基于现有的强一致性模型的读写流程是否有可以优化的点，提升 Ceph 的 IO 性能</li>
<li></li>
</ul>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<ul>
<li>本篇主要总结 RADOS 底层的读写流程，并结合源码进行分析</li>
<li>考虑基于现有的强一致性模型的读写流程是否有可以优化的点，提升 Ceph 的 IO 性能</li>
<li></li>
</ul>
</blockquote>
<!-- more -->
<h2 id="osd-读写流程">OSD 读写流程</h2>
<p><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200924171959.png" alt="20200924171959" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200924172030.png" alt="20200924172030" loading="lazy"></p>
<ul>
<li>大致分为三个阶段：
<ul>
<li>接受请求：主要是网络模块相关</li>
<li>OSD 的 op_wq 处理：在工作队列 op_wq 的线程池中处理，检查 PG 状态，封装请求为事务</li>
<li>PGBackend 的处理：仍然在 op_wq 的线程池中处理，将事务进行分发，由对应的 PGBackend 来实现本地事务处理</li>
</ul>
</li>
</ul>
<h2 id="pg">PG</h2>
<ul>
<li>Placement Group (PG)，是一些对象的集合，对象和 PG 的对应关系其实就是对象标识 HASH 之后取模得到对应的 pg_id（模值为对应存储池对应的 PG 数目）。</li>
</ul>
<pre><code class="language-Python">locator = object_name
obj_hash = hash(locator)
pg = obj_hash % num_pg
OSDs_for_pg = crush(pg)  # returns a list of OSDs
primary = osds_for_pg[0]
replicas = osds_for_pg[1:]
</code></pre>
<ul>
<li>以 PG 为单位进行组织的目的是为了使用有限的、可控数目的 PG 来管理无限扩张的对象数据，并控制节点资源的分配。</li>
<li>PG 是数据备份、同步、迁移等操作的基本单位。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200923115445.png" alt="20200923115445" loading="lazy"></li>
</ul>
<h3 id="常见的-pg-级别的操作">常见的 PG 级别的操作</h3>
<h4 id="peering">Peering</h4>
<ul>
<li>指（当前或者过去曾经）归属于同一个 PG 所有的 PG 实例就本 PG 所存储的全部对象及对象相关的元数据进行协商并最终达成一致的过程。</li>
<li>Peering 基于 Info 和 Log 进行。Log 是指权威日志，作为数据同步的依据。Info 是指 PG 的基本元数据信息，在 Peering 过程中通过交换 Info，可以由 Primary 选举得到权威日志。</li>
<li>此处说的一致，并不意味着每个 PG 实例都实时拥有每个对象的最新内容</li>
<li><strong>Golden Rule</strong>: 对任何 PG 的写操作只有在该 PG 的操作集的所有成员都持久化后，才会向客户端确认，且在 Peering 期间不能进行任何 IO 操作，且不能做 Recovery</li>
</ul>
<h5 id="涉及的其他概念">涉及的其他概念</h5>
<ul>
<li><em>Acting Set</em>：负责特定 PG 的(或在某些 epoch 时) OSD 的有序列表。列表第一个 OSD 为主 OSD，其余为 Replica OSD</li>
<li><em>Up Set</em>：通常情况下和 Acting Set 相同，出现 PG temp 时有所不同。Acting Set 完全由 CRUSH 决定，Up Set 会受到 PG temp 的影响</li>
<li><em>PG temp</em>：假设一个 PG 的 acting set 为 [0,1,2] 列表。此时如果 osd0 出现故障，导致 CRUSH 算法重新分配该 PG 的 acting set 为 [3,1,2]。此时 osd3 为该 PG 的主 OSD，但是 osd3 为新加入的 OSD，并不能负担该 PG 上的读操作。所以 PG 向 Monitor 申请一个临时的 PG，osd1 为临时的主 OSD，这时 up set 变为 [1,3,2]，acting set 依然为 [3,1,2]，导致 acting set 和 up set 不同。当 osd3 完成 Backfill 过程之后，临时 PG 被取消，该 PG 的 up set 修复为 acting set，此时 acting set 和 up set 都为 [3,1,2] 列表。</li>
<li><em>Epoch</em>：OSDMap 的版本号，Monitor 管理生成，单增。OSDMap 发生了变化，Epoch 相应地增加，但为了防止 Epoch 的剧烈变化和较快的消耗，一个特定时间段内的修改会被折叠进入一个 Epoch</li>
<li><em>Interval</em>：OSDMap 的一个连续 Epoch 间隔，该期间内的 PG 的 Active Set 和 Up Set 没有发生变化，也就意味着和 PG 是绑定的。每个 Interval 的起始 Epoch 称之为 <em>same_interval_since</em></li>
</ul>
<h5 id="触发时机">触发时机</h5>
<ul>
<li>系统初始化时，OSD 重新启动导致 PG 重新加载</li>
<li>PG 新创建时，PG 会发起一次 Peering 的过程</li>
<li>当有 OSD 失效，OSD 的增加或者删除等导致 PG 的 acting set 发生了变化，该 PG 就会重新发起一次 Peering 过程</li>
</ul>
<h4 id="recovery">Recovery</h4>
<ul>
<li>当 PG 完成了 Peering 过程后，处于 Active 状态的 PG 就已经可以对外提供服务了。如果该 PG 的各个副本上有不一致的对象，就需要进行修复。Ceph 的修复过程有两种：Recovery 和 Backfill。本质是针对 PG 某些实例进行数据同步的过程，最终目标是将 PG 变成 Active+Clean 状态</li>
</ul>
<h5 id="过程">过程</h5>
<ul>
<li>Peering 过程产生关于缺失对象的信息，主副本和从副本对应的缺失对象信息有所不同，存储的位置不同。主 OSD  缺失的对象存储在权威日志 pg_log 的相关数据结构中，副本上缺失的对象存储在 OSD 对应的 peer_missing 的数据结构中。</li>
<li>对于主 OSD 缺失的对象，随机选择一个拥有该对象的 OSD，拉取数据（PULL）。（先修复主 OSD，再修复从 OSD）</li>
<li>对于 replica 数据缺失的情况，从主副本上把缺失的对象数据推送到副本上完成数据修复（PUSH）</li>
<li>快照对象有一些单独的处理</li>
</ul>
<h5 id="场景">场景</h5>
<ul>
<li>OSD 暂时下线，然后又上线</li>
<li>OSD 硬件故障下线，更换硬盘重新上线</li>
</ul>
<h4 id="pullpush">Pull/Push</h4>
<ul>
<li>Recovery 由 Primary 主导进行，期间 Primary 通过 Pull 或者 Push 的方式进行对象间的数据同步</li>
</ul>
<h4 id="backfill">Backfill</h4>
<ul>
<li>是 Recovery 的一种特殊场景，指 Peering 完成后，如果基于当前权威日志无法对 Up Set 当中的某些 PG 实例实施增量同步（例如承载这些 PG 实例的 OSD 离线太久，或者是新的 OSD 加入集群导致的 PG 实例整体迁移），则通过完全拷贝当前 Primary 所有对象的方式进行全量同步。</li>
</ul>
<h4 id="scrub">Scrub</h4>
<ul>
<li>Ceph 内部实现的数据一致性检查工具 Ceph Scrub。原理为：通过对比各个对象副本的数据和元数据完成副本的一致性检查。后台执行检查操作，可以设置相应的调度策略来触发 Scrub（立即启动/间隔一定的时间/定时）</li>
<li>主要包括scrub 和 deep-scrub。
<ul>
<li>其中 scrub 只对元数据信息进行扫描，相对比较快；</li>
<li>而 deep-scrub 不仅对元数据进行扫描，还会对存储的数据进行扫描，几乎要扫描磁盘上的所有数据并计算 crc32 校验值，相对比较慢。</li>
</ul>
</li>
</ul>
<h2 id="primarylogpgdo_request">PrimaryLogPG::do_request</h2>
<ul>
<li>该步骤主要是做一些 PG 级别的检查，以及一些 PG 级别的操作的分发处理。</li>
<li>操作最终可能因为各种各样的原因被加入到响应队列推迟处理，对应了很多种重试队列，用于区分不同的场景。<br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200923164805.png" alt="20200923164805" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200923164817.png" alt="20200923164817" loading="lazy"></li>
<li>为了保证 OP 之间不会乱序，上述队列均为 FIFO 队列，且队列之间也严格有序。当对应的限制接触后，PG 会触发关联的 OP 重新进入 op_shardedwq 队列排队，等候再次被 PG 执行</li>
<li>最终许多普通的操作都会进入 do_op 执行</li>
</ul>
<pre><code class="language-C++">void PrimaryLogPG::do_request(
    OpRequestRef &amp;op,
    ThreadPool::TPHandle &amp;handle)
{
  // Trace 相关配置检查
  if (op-&gt;osd_trace)
  {
    op-&gt;pg_trace.init(&quot;pg op&quot;, &amp;trace_endpoint, &amp;op-&gt;osd_trace);
    op-&gt;pg_trace.event(&quot;do request&quot;);
  }

  // make sure we have a new enough map
  // 判断 waiting_for_map 队列中是否有来自相同客户端的操作
  auto p = waiting_for_map.find(op-&gt;get_source());
  if (p != waiting_for_map.end())
  {
    // 有则将当前 Op 加入 waiting_for_map 队列，然后直接返回
    // preserve ordering
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot; waiting_for_map &quot;
             &lt;&lt; p-&gt;first &lt;&lt; &quot; not empty, queueing&quot; &lt;&lt; dendl;
    p-&gt;second.push_back(op);
    op-&gt;mark_delayed(&quot;waiting_for_map not empty&quot;);
    return;
  }

  // 判断当前 op 携带的 Epoch 信息是否是最新的 op-&gt;min_epoch &lt;= get_osdmap_epoch()
  if (!have_same_or_newer_map(op-&gt;min_epoch))
  {
    // 如果 Op 携带的 epoch 更新，则将当前 Op 加入 waiting_for_map 队列，然后直接返回
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot; min &quot; &lt;&lt; op-&gt;min_epoch
             &lt;&lt; &quot;, queue on waiting_for_map &quot; &lt;&lt; op-&gt;get_source() &lt;&lt; dendl;
    waiting_for_map[op-&gt;get_source()].push_back(op);
    op-&gt;mark_delayed(&quot;op must wait for map&quot;);
    osd-&gt;request_osdmap_update(op-&gt;min_epoch);
    return;
  }

  // 判断是否可以丢弃掉该 op
  //   1. op 对应的客户端链路断开
  //   2. 收到 op 时，PG 当前已经切换到一个更新的 Interval (即 PG 此时的 same_interval_since 比 op 携带的 Epoch 要大，后续客户端会重发)
  //   3. op 在 PG 分裂之前发送（后续客户端会进行重发）
  //   4. ...
  if (can_discard_request(op))
  {
    return;
  }

  // pg-wide backoffs
  const Message *m = op-&gt;get_req();
  int msg_type = m-&gt;get_type();
  if (m-&gt;get_connection()-&gt;has_feature(CEPH_FEATURE_RADOS_BACKOFF))
  {
    auto session = ceph::ref_cast&lt;Session&gt;(m-&gt;get_connection()-&gt;get_priv());
    if (!session)
      return; // drop it.

    if (msg_type == CEPH_MSG_OSD_OP)
    {
      if (session-&gt;check_backoff(cct, info.pgid,
                                 info.pgid.pgid.get_hobj_start(), m))
      {
        return;
      }

      bool backoff =
          is_down() ||
          is_incomplete() ||
          (!is_active() &amp;&amp; is_peered());
      if (g_conf()-&gt;osd_backoff_on_peering &amp;&amp; !backoff)
      {
        if (is_peering())
        {
          backoff = true;
        }
      }
      if (backoff)
      {
        add_pg_backoff(session);
        return;
      }
    }
    // pg backoff acks at pg-level
    if (msg_type == CEPH_MSG_OSD_BACKOFF)
    {
      const MOSDBackoff *ba = static_cast&lt;const MOSDBackoff *&gt;(m);
      if (ba-&gt;begin != ba-&gt;end)
      {
        handle_backoff(op);
        return;
      }
    }
  }

  // PG 是否处于 Active 或者 Peer 状态？
  if (!is_peered())
  {
    // 不处于上述状态，判断是否可以由后端直接处理。
    // 1. ECBackend 该情况下不能处理
    // 2. ReplicatedBackend 判断如果是 PULL 操作则可以进行处理
    // Delay unless PGBackend says it's ok
    if (pgbackend-&gt;can_handle_while_inactive(op))
    {
      bool handled = pgbackend-&gt;handle_message(op);
      ceph_assert(handled);
      return;
    }
    else
    {
      // 不能处理则加入 waiting_for_peered 队列，然后返回。
      waiting_for_peered.push_back(op);
      op-&gt;mark_delayed(&quot;waiting for peered&quot;);
      return;
    }
  }

  // PG 处于 Active 或者 Peer 状态，判断是否正在进行刷回
  if (recovery_state.needs_flush())
  {
    // 正在刷回则将该 op 加入 waiting_for_flush 队列，并返回
    dout(20) &lt;&lt; &quot;waiting for flush on &quot; &lt;&lt; op &lt;&lt; dendl;
    waiting_for_flush.push_back(op);
    op-&gt;mark_delayed(&quot;waiting for flush&quot;);
    return;
  }

  ceph_assert(is_peered() &amp;&amp; !recovery_state.needs_flush());

  // 由 PGBackend 直接处理然后返回，此处只处理以下操作
  // 1. MSG_OSD_PG_RECOVERY_DELETE (Common)
  // 2. MSG_OSD_PG_RECOVERY_DELETE_REPLY (Common)
  // 3. MSG_OSD_PG_PUSH (副本)
  // 4. MSG_OSD_PG_PULL (副本)
  // 5. MSG_OSD_PG_PUSH_REPLY (副本)
  // 6. MSG_OSD_REPOP (副本)
  // 7. MSG_OSD_REPOPREPLY (副本)
  // 8. MSG_OSD_EC_WRITE (EC)
  // 9. MSG_OSD_EC_WRITE_REPLY (EC)
  // 10. MSG_OSD_EC_READ (EC)
  // 11. MSG_OSD_EC_READ_REPLY (EC)
  // 12. MSG_OSD_PG_PUSH (EC)
  // 13. MSG_OSD_PG_PUSH_REPLY (EC)
  if (pgbackend-&gt;handle_message(op))
    return;

  // 其余操作如下处理：
  switch (msg_type)
  {
  case CEPH_MSG_OSD_OP:
  case CEPH_MSG_OSD_BACKOFF:
    // 判断是否是 Active 状态
    if (!is_active())
    {
      // 即 Peer 状态，加入 waiting_for_active 队列并返回
      dout(20) &lt;&lt; &quot; peered, not active, waiting for active on &quot; &lt;&lt; op &lt;&lt; dendl;
      waiting_for_active.push_back(op);
      op-&gt;mark_delayed(&quot;waiting for active&quot;);
      return;
    }

    // 为 Active 状态
    switch (msg_type)
    {
      // 处理 CEPH_MSG_OSD_OP
      // 如果为 tier 相关直接报错，否则 do_op
    case CEPH_MSG_OSD_OP:
      // verify client features
      if ((pool.info.has_tiers() || pool.info.is_tier()) &amp;&amp;
          !op-&gt;has_feature(CEPH_FEATURE_OSD_CACHEPOOL))
      {
        osd-&gt;reply_op_error(op, -EOPNOTSUPP);
        return;
      }
      do_op(op);
      break;
      
      
      // 处理 CEPH_MSG_OSD_BACKOFF
    case CEPH_MSG_OSD_BACKOFF:
      // object-level backoff acks handled in osdop context
      handle_backoff(op);
      break;
    }
    break;

  // 其他操作的处理
  case MSG_OSD_PG_SCAN:
    do_scan(op, handle);
    break;

  case MSG_OSD_PG_BACKFILL:
    do_backfill(op);
    break;

  case MSG_OSD_PG_BACKFILL_REMOVE:
    do_backfill_remove(op);
    break;

  case MSG_OSD_SCRUB_RESERVE:
  {
    auto m = op-&gt;get_req&lt;MOSDScrubReserve&gt;();
    switch (m-&gt;type)
    {
    case MOSDScrubReserve::REQUEST:
      handle_scrub_reserve_request(op);
      break;
    case MOSDScrubReserve::GRANT:
      handle_scrub_reserve_grant(op, m-&gt;from);
      break;
    case MOSDScrubReserve::REJECT:
      handle_scrub_reserve_reject(op, m-&gt;from);
      break;
    case MOSDScrubReserve::RELEASE:
      handle_scrub_reserve_release(op);
      break;
    }
  }
  break;

  case MSG_OSD_REP_SCRUB:
    replica_scrub(op, handle);
    break;

  case MSG_OSD_REP_SCRUBMAP:
    do_replica_scrub_map(op);
    break;

  case MSG_OSD_PG_UPDATE_LOG_MISSING:
    do_update_log_missing(op);
    break;

  case MSG_OSD_PG_UPDATE_LOG_MISSING_REPLY:
    do_update_log_missing_reply(op);
    break;

  default:
    ceph_abort_msg(&quot;bad message type in do_request&quot;);
  }
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200922103400.png" alt="20200922103400" loading="lazy"></figure>
<h2 id="primarylogpgdo_op">PrimaryLogPG::do_op</h2>
<pre><code class="language-C++">/** do_op - do an op
 * pg lock will be held (if multithreaded)
 * osd_lock NOT held.
 */
void PrimaryLogPG::do_op(OpRequestRef &amp;op)
{
  FUNCTRACE(cct);

  // 使用一个指针进行指向对应的请求，后续操作都使用该指针
  // NOTE: take a non-const pointer here; we must be careful not to
  // change anything that will break other reads on m (operator&lt;&lt;).
  MOSDOp *m = static_cast&lt;MOSDOp *&gt;(op-&gt;get_nonconst_req());
  
  // op 参数校验
  ceph_assert(m-&gt;get_type() == CEPH_MSG_OSD_OP);

  // decode 请求解码状态判断，从 bufferlist 中解析数据
  if (m-&gt;finish_decode())
  {
    op-&gt;reset_desc(); // for TrackedOp
    m-&gt;clear_payload();
  }

  dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: op &quot; &lt;&lt; *m &lt;&lt; dendl;

  const hobject_t head = m-&gt;get_hobj().get_head();

  // 【PG 参数检查】判断是否包含 op 所携带的对象
  if (!info.pgid.pgid.contains(
          info.pgid.pgid.get_split_bits(pool.info.get_pg_num()), head))
  {
    derr &lt;&lt; __func__ &lt;&lt; &quot; &quot; &lt;&lt; info.pgid.pgid &lt;&lt; &quot; does not contain &quot;
         &lt;&lt; head &lt;&lt; &quot; pg_num &quot; &lt;&lt; pool.info.get_pg_num() &lt;&lt; &quot; hash &quot;
         &lt;&lt; std::hex &lt;&lt; head.get_hash() &lt;&lt; std::dec &lt;&lt; dendl;
    osd-&gt;clog-&gt;warn() &lt;&lt; info.pgid.pgid &lt;&lt; &quot; does not contain &quot; &lt;&lt; head
                      &lt;&lt; &quot; op &quot; &lt;&lt; *m;
    ceph_assert(!cct-&gt;_conf-&gt;osd_debug_misdirected_ops);
    return;
  }

  bool can_backoff =
      m-&gt;get_connection()-&gt;has_feature(CEPH_FEATURE_RADOS_BACKOFF);
  ceph::ref_t&lt;Session&gt; session;
  if (can_backoff)
  {
    session = static_cast&lt;Session *&gt;(m-&gt;get_connection()-&gt;get_priv().get());
    if (!session.get())
    {
      dout(10) &lt;&lt; __func__ &lt;&lt; &quot; no session&quot; &lt;&lt; dendl;
      return;
    }

    if (session-&gt;check_backoff(cct, info.pgid, head, m))
    {
      return;
    }
  }


  // op 携带了 CEPH_OSD_FLAG_PARALLELEXEC 标志，指示可以并发执行
  if (m-&gt;has_flag(CEPH_OSD_FLAG_PARALLELEXEC))
  {
    // not implemented.
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: PARALLELEXEC not implemented &quot; &lt;&lt; *m &lt;&lt; dendl;
    osd-&gt;reply_op_error(op, -EINVAL);
    return;
  }

  {
    int r = op-&gt;maybe_init_op_info(*get_osdmap());
    if (r)
    {
      osd-&gt;reply_op_error(op, r);
      return;
    }
  }


  // op 携带了 CEPH_OSD_FLAG_BALANCE_READS 或者 CEPH_OSD_FLAG_LOCALIZE_READS 标志，
  // 指示可以读取别的 OSD 节点，不一定是主 OSD，或者执行本地读
  // 注意：该 Flag 支持读操作，且不支持缓存
  if ((m-&gt;get_flags() &amp; (CEPH_OSD_FLAG_BALANCE_READS |
                         CEPH_OSD_FLAG_LOCALIZE_READS)) &amp;&amp;
      op-&gt;may_read() &amp;&amp;
      !(op-&gt;may_write() || op-&gt;may_cache()))
  {
    // 当前节点既不是主节点，也不是 replicated 节点时，譬如 Stray，则报错
    // balanced reads; any replica will do
    if (!(is_primary() || is_nonprimary()))
    {
      osd-&gt;handle_misdirected_op(this, op);
      return;
    }
  }
  else
  {
    // 正常操作的时候必须是主节点，否则报错
    // normal case; must be primary
    if (!is_primary())
    {
      osd-&gt;handle_misdirected_op(this, op);
      return;
    }
  }

  // 判断是否为 laggy 状态
  // https://docs.ceph.com/en/latest/dev/osd_internals/stale_read/
  if (!check_laggy(op))
  {
    return;
  }

  // 检查权限 caps
  if (!op_has_sufficient_caps(op))
  {
    osd-&gt;reply_op_error(op, -EPERM);
    return;
  }

  // 如果包含 includes_pg_op 操作（对 PG 的操作，主要是获取 PG 相关信息），则执行 do_pg_op
  if (op-&gt;includes_pg_op())
  {
    return do_pg_op(op);
  }

  // 对象名称超过、key、命名空间等数据信息超过最大限制会影响存储后端
  // 检查 oid 是否为空，检查对象 key
  // object name too long?
  if (m-&gt;get_oid().name.size() &gt; cct-&gt;_conf-&gt;osd_max_object_name_len)
  {
    dout(4) &lt;&lt; &quot;do_op name is longer than &quot;
            &lt;&lt; cct-&gt;_conf-&gt;osd_max_object_name_len
            &lt;&lt; &quot; bytes&quot; &lt;&lt; dendl;
    osd-&gt;reply_op_error(op, -ENAMETOOLONG);
    return;
  }
  if (m-&gt;get_hobj().get_key().size() &gt; cct-&gt;_conf-&gt;osd_max_object_name_len)
  {
    dout(4) &lt;&lt; &quot;do_op locator is longer than &quot;
            &lt;&lt; cct-&gt;_conf-&gt;osd_max_object_name_len
            &lt;&lt; &quot; bytes&quot; &lt;&lt; dendl;
    osd-&gt;reply_op_error(op, -ENAMETOOLONG);
    return;
  }
  if (m-&gt;get_hobj().nspace.size() &gt; cct-&gt;_conf-&gt;osd_max_object_namespace_len)
  {
    dout(4) &lt;&lt; &quot;do_op namespace is longer than &quot;
            &lt;&lt; cct-&gt;_conf-&gt;osd_max_object_namespace_len
            &lt;&lt; &quot; bytes&quot; &lt;&lt; dendl;
    osd-&gt;reply_op_error(op, -ENAMETOOLONG);
    return;
  }
  if (m-&gt;get_hobj().oid.name.empty())
  {
    dout(4) &lt;&lt; &quot;do_op empty oid name is not allowed&quot; &lt;&lt; dendl;
    osd-&gt;reply_op_error(op, -EINVAL);
    return;
  }

  if (int r = osd-&gt;store-&gt;validate_hobject_key(head))
  {
    dout(4) &lt;&lt; &quot;do_op object &quot; &lt;&lt; head &lt;&lt; &quot; invalid for backing store: &quot;
            &lt;&lt; r &lt;&lt; dendl;
    osd-&gt;reply_op_error(op, r);
    return;
  }

  // 客户端被禁止访问
  // blocklisted?
  if (get_osdmap()-&gt;is_blocklisted(m-&gt;get_source_addr()))
  {
    dout(10) &lt;&lt; &quot;do_op &quot; &lt;&lt; m-&gt;get_source_addr() &lt;&lt; &quot; is blocklisted&quot; &lt;&lt; dendl;
    osd-&gt;reply_op_error(op, -EBLOCKLISTED);
    return;
  }

  // order this op as a write?
  bool write_ordered = op-&gt;rwordered();

  // 检查集群是否已被标记为 FULL，并检查 op 是否有携带 CEPH_OSD_FLAG_FULL_TRY 和 CEPH_OSD_FLAG_FULL_FORCE 标志
  // discard due to cluster full transition?  (we discard any op that
  // originates before the cluster or pool is marked full; the client
  // will resend after the full flag is removed or if they expect the
  // op to succeed despite being full).  The except is FULL_FORCE and
  // FULL_TRY ops, which there is no reason to discard because they
  // bypass all full checks anyway.  If this op isn't write or
  // read-ordered, we skip.
  // FIXME: we exclude mds writes for now.
  if (write_ordered &amp;&amp; !(m-&gt;get_source().is_mds() || m-&gt;has_flag(CEPH_OSD_FLAG_FULL_TRY) || m-&gt;has_flag(CEPH_OSD_FLAG_FULL_FORCE)) &amp;&amp;
      info.history.last_epoch_marked_full &gt; m-&gt;get_map_epoch())
  {
    dout(10) &lt;&lt; __func__ &lt;&lt; &quot; discarding op sent before full &quot; &lt;&lt; m &lt;&lt; &quot; &quot;
             &lt;&lt; *m &lt;&lt; dendl;
    return;
  }

  // 检查 PG 所在 OSD 可用存储空间情况
  // mds should have stopped writing before this point.
  // We can't allow OSD to become non-startable even if mds
  // could be writing as part of file removals.
  if (write_ordered &amp;&amp; osd-&gt;check_failsafe_full(get_dpp()) &amp;&amp;
      !m-&gt;has_flag(CEPH_OSD_FLAG_FULL_TRY))
  {
    dout(10) &lt;&lt; __func__ &lt;&lt; &quot; fail-safe full check failed, dropping request.&quot; &lt;&lt; dendl;
    return;
  }
  int64_t poolid = get_pgid().pool();
  
  // 判断 op 是否为写操作
  if (op-&gt;may_write())
  {
    // 获取对应的 pool 并检查
    const pg_pool_t *pi = get_osdmap()-&gt;get_pg_pool(poolid);
    if (!pi)
    {
      return;
    }

    // invalid?
    // 判断是否访问快照对象，若访问则报错，快照不允许写
    if (m-&gt;get_snapid() != CEPH_NOSNAP)
    {
      dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: write to clone not valid &quot; &lt;&lt; *m &lt;&lt; dendl;
      osd-&gt;reply_op_error(op, -EINVAL);
      return;
    }

    // too big?
    // 判断写入的数据大小并校验，osd_max_write_size
    if (cct-&gt;_conf-&gt;osd_max_write_size &amp;&amp;
        m-&gt;get_data_len() &gt; cct-&gt;_conf-&gt;osd_max_write_size &lt;&lt; 20)
    {
      // journal can't hold commit!
      derr &lt;&lt; &quot;do_op msg data len &quot; &lt;&lt; m-&gt;get_data_len()
           &lt;&lt; &quot; &gt; osd_max_write_size &quot; &lt;&lt; (cct-&gt;_conf-&gt;osd_max_write_size &lt;&lt; 20)
           &lt;&lt; &quot; on &quot; &lt;&lt; *m &lt;&lt; dendl;
      osd-&gt;reply_op_error(op, -OSD_WRITETOOBIG);
      return;
    }
  }

  dout(10) &lt;&lt; &quot;do_op &quot; &lt;&lt; *m
           &lt;&lt; (op-&gt;may_write() ? &quot; may_write&quot; : &quot;&quot;)
           &lt;&lt; (op-&gt;may_read() ? &quot; may_read&quot; : &quot;&quot;)
           &lt;&lt; (op-&gt;may_cache() ? &quot; may_cache&quot; : &quot;&quot;)
           &lt;&lt; &quot; -&gt; &quot; &lt;&lt; (write_ordered ? &quot;write-ordered&quot; : &quot;read-ordered&quot;)
           &lt;&lt; &quot; flags &quot; &lt;&lt; ceph_osd_flag_string(m-&gt;get_flags())
           &lt;&lt; dendl;

  // missing object?
  // 检查对象是否不可读，
  // 1. 如果对象在 missing 列表（恢复过程中检查 PGLog 构建的 missing 列表）中，不可读
  // 2. 数据修复过程中，在当前 acting set 对应的多个 OSD 上该对象不可读
  // bool is_unreadable_object(const hobject_t &amp;oid) const
  // {
  //   return is_missing_object(oid) ||
  //          !recovery_state.get_missing_loc().readable_with_acting(
  //              oid, get_actingset());
  // }
  if (is_unreadable_object(head))
  {
    // 不是主节点 报错
    if (!is_primary())
    {
      osd-&gt;reply_op_error(op, -EAGAIN);
      return;
    }

    // 是主节点相应地判断 OSD backoff 状态
    if (can_backoff &amp;&amp;
        (g_conf()-&gt;osd_backoff_on_degraded ||
         (g_conf()-&gt;osd_backoff_on_unfound &amp;&amp;
          recovery_state.get_missing_loc().is_unfound(head))))
    {
      add_backoff(session, head, head);
      maybe_kick_recovery(head);
    }
    else
    {
      // 等待对象恢复完成
      wait_for_unreadable_object(head, op);
    }
    return;
  }


  // 顺序写
  if (write_ordered)
  {
    // 对象处于降级状态（恢复状态）
    // degraded object?
    if (is_degraded_or_backfilling_object(head))
    {
      if (can_backoff &amp;&amp; g_conf()-&gt;osd_backoff_on_degraded)
      {
        // 尝试启动 recovery
        add_backoff(session, head, head);
        maybe_kick_recovery(head);
      }
      else
      {
        wait_for_degraded_object(head, op);
      }
      return;
    }

    // 对象正在被 scrub，加入相应的队列 waiting_for_scrub
    if (scrubber.is_chunky_scrub_active() &amp;&amp; write_blocked_by_scrub(head))
    {
      dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: waiting for scrub&quot; &lt;&lt; dendl;
      waiting_for_scrub.push_back(op);
      op-&gt;mark_delayed(&quot;waiting for scrub&quot;);
      return;
    }
    if (!check_laggy_requeue(op))
    {
      return;
    }

    // 对象被 snap
    // objects_blocked_on_degraded_snap 保存了 head 对象则需要等待
    // head 对象在 rollback 到某个版本的快照时，该版本的 snap 对象处于确实状态，则需要等待 snap 对象恢复
    // blocked on snap?
    if (auto blocked_iter = objects_blocked_on_degraded_snap.find(head);
        blocked_iter != std::end(objects_blocked_on_degraded_snap))
    {
      hobject_t to_wait_on(head);
      to_wait_on.snap = blocked_iter-&gt;second;
      wait_for_degraded_object(to_wait_on, op);
      return;
    }

    // objects_blocked_on_snap_promotion 里的对象表示 head 对象 rollback 到某个版本的快照时
    // 该版本的快照对象在 cache pool 层中没有，需要到 data pool 层获取
    if (auto blocked_snap_promote_iter = objects_blocked_on_snap_promotion.find(head);
        blocked_snap_promote_iter != std::end(objects_blocked_on_snap_promotion))
    {
      wait_for_blocked_object(blocked_snap_promote_iter-&gt;second-&gt;obs.oi.soid, op);
      return;
    }

    // objects_blocked_on_cache_full 该队列中的对象因为 cache pool 层空间满而阻塞了写操作
    if (objects_blocked_on_cache_full.count(head))
    {
      block_write_on_full_cache(head, op);
      return;
    }
  }

  // 检查 op 是否为重发
  // dup/resent?
  if (op-&gt;may_write() || op-&gt;may_cache())
  {
    // warning: we will get back *a* request for this reqid, but not
    // necessarily the most recent.  this happens with flush and
    // promote ops, but we can't possible have both in our log where
    // the original request is still not stable on disk, so for our
    // purposes here it doesn't matter which one we get.
    eversion_t version;
    version_t user_version;
    int return_code = 0;
    vector&lt;pg_log_op_return_item_t&gt; op_returns;
    bool got = check_in_progress_op(
        m-&gt;get_reqid(), &amp;version, &amp;user_version, &amp;return_code, &amp;op_returns);
    if (got)
    {
      dout(3) &lt;&lt; __func__ &lt;&lt; &quot; dup &quot; &lt;&lt; m-&gt;get_reqid()
              &lt;&lt; &quot; version &quot; &lt;&lt; version &lt;&lt; dendl;
      if (already_complete(version))
      {
        osd-&gt;reply_op_error(op, return_code, version, user_version, op_returns);
      }
      else
      {
        dout(10) &lt;&lt; &quot; waiting for &quot; &lt;&lt; version &lt;&lt; &quot; to commit&quot; &lt;&lt; dendl;
        // always queue ondisk waiters, so that we can requeue if needed
        waiting_for_ondisk[version].emplace_back(op, user_version, return_code,
                                                 op_returns);
        op-&gt;mark_delayed(&quot;waiting for ondisk&quot;);
      }
      return;
    }
  }

  ObjectContextRef obc;
  bool can_create = op-&gt;may_write();
  hobject_t missing_oid;

  // kludge around the fact that LIST_SNAPS sets CEPH_SNAPDIR for LIST_SNAPS
  const hobject_t &amp;oid =
      m-&gt;get_snapid() == CEPH_SNAPDIR ? head : m-&gt;get_hobj();

  // make sure LIST_SNAPS is on CEPH_SNAPDIR and nothing else
  for (vector&lt;OSDOp&gt;::iterator p = m-&gt;ops.begin(); p != m-&gt;ops.end(); ++p)
  {
    OSDOp &amp;osd_op = *p;

    if (osd_op.op.op == CEPH_OSD_OP_LIST_SNAPS)
    {
      if (m-&gt;get_snapid() != CEPH_SNAPDIR)
      {
        dout(10) &lt;&lt; &quot;LIST_SNAPS with incorrect context&quot; &lt;&lt; dendl;
        osd-&gt;reply_op_error(op, -EINVAL);
        return;
      }
    }
    else
    {
      if (m-&gt;get_snapid() == CEPH_SNAPDIR)
      {
        dout(10) &lt;&lt; &quot;non-LIST_SNAPS on snapdir&quot; &lt;&lt; dendl;
        osd-&gt;reply_op_error(op, -EINVAL);
        return;
      }
    }
  }

  // io blocked on obc?
  if (!m-&gt;has_flag(CEPH_OSD_FLAG_FLUSH) &amp;&amp;
      maybe_await_blocked_head(oid, op))
  {
    return;
  }


  // 当前节点不是主节点
  if (!is_primary())
  {
    // 判断当前状态下是否能处理副本节点的读请求
    if (!recovery_state.can_serve_replica_read(oid))
    {
      dout(20) &lt;&lt; __func__
               &lt;&lt; &quot;: unstable write on replica, bouncing to primary &quot;
               &lt;&lt; *m &lt;&lt; dendl;
      osd-&gt;reply_op_error(op, -EAGAIN);
      return;
    }
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: serving replica read on oid &quot; &lt;&lt; oid
             &lt;&lt; dendl;
  }

  int r = find_object_context(
      oid, &amp;obc, can_create,
      m-&gt;has_flag(CEPH_OSD_FLAG_MAP_SNAP_CLONE),
      &amp;missing_oid);

  // LIST_SNAPS needs the ssc too
  if (obc &amp;&amp;
      m-&gt;get_snapid() == CEPH_SNAPDIR &amp;&amp;
      !obc-&gt;ssc)
  {
    obc-&gt;ssc = get_snapset_context(oid, true);
  }

  if (r == -EAGAIN)
  {
    // If we're not the primary of this OSD, we just return -EAGAIN. Otherwise,
    // we have to wait for the object.
    if (is_primary())
    {
      // missing the specific snap we need; requeue and wait.
      ceph_assert(!op-&gt;may_write()); // only happens on a read/cache
      wait_for_unreadable_object(missing_oid, op);
      return;
    }
  }
  else if (r == 0)
  {
    // 检查 snapdir 对象是否可读
    if (is_unreadable_object(obc-&gt;obs.oi.soid))
    {
      dout(10) &lt;&lt; __func__ &lt;&lt; &quot;: clone &quot; &lt;&lt; obc-&gt;obs.oi.soid
               &lt;&lt; &quot; is unreadable, waiting&quot; &lt;&lt; dendl;
      wait_for_unreadable_object(obc-&gt;obs.oi.soid, op);
      return;
    }

    // 如果是写操作需要检查 snapdir 对象是否缺失
    // degraded object?  (the check above was for head; this could be a clone)
    if (write_ordered &amp;&amp;
        obc-&gt;obs.oi.soid.snap != CEPH_NOSNAP &amp;&amp;
        is_degraded_or_backfilling_object(obc-&gt;obs.oi.soid))
    {
      dout(10) &lt;&lt; __func__ &lt;&lt; &quot;: clone &quot; &lt;&lt; obc-&gt;obs.oi.soid
               &lt;&lt; &quot; is degraded, waiting&quot; &lt;&lt; dendl;
      wait_for_degraded_object(obc-&gt;obs.oi.soid, op);
      return;
    }
  }

  bool in_hit_set = false;

  // hitset 不为空，进入 cache tiering 流程
  if (hit_set)
  {
    if (obc.get())
    {
      if (obc-&gt;obs.oi.soid != hobject_t() &amp;&amp; hit_set-&gt;contains(obc-&gt;obs.oi.soid))
        in_hit_set = true;
    }
    else
    {
      if (missing_oid != hobject_t() &amp;&amp; hit_set-&gt;contains(missing_oid))
        in_hit_set = true;
    }
    if (!op-&gt;hitset_inserted)
    {
      hit_set-&gt;insert(oid);
      op-&gt;hitset_inserted = true;
      if (hit_set-&gt;is_full() ||
          hit_set_start_stamp + pool.info.hit_set_period &lt;= m-&gt;get_recv_stamp())
      {
        hit_set_persist();
      }
    }
  }

  if (agent_state)
  {
    if (agent_choose_mode(false, op))
      return;
  }

  if (obc.get() &amp;&amp; obc-&gt;obs.exists &amp;&amp; obc-&gt;obs.oi.has_manifest())
  {
    if (maybe_handle_manifest(op,
                              write_ordered,
                              obc))
      return;
  }

  if (maybe_handle_cache(op,
                         write_ordered,
                         obc,
                         r,
                         missing_oid,
                         false,
                         in_hit_set))
    return;

  if (r &amp;&amp; (r != -ENOENT || !obc))
  {
    // copy the reqids for copy get on ENOENT
    if (r == -ENOENT &amp;&amp;
        (m-&gt;ops[0].op.op == CEPH_OSD_OP_COPY_GET))
    {
      fill_in_copy_get_noent(op, oid, m-&gt;ops[0]);
      return;
    }
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: find_object_context got error &quot; &lt;&lt; r &lt;&lt; dendl;
    if (op-&gt;may_write() &amp;&amp;
        get_osdmap()-&gt;require_osd_release &gt;= ceph_release_t::kraken)
    {
      record_write_error(op, oid, nullptr, r);
    }
    else
    {
      osd-&gt;reply_op_error(op, r);
    }
    return;
  }

  // 验证 object_locator 和 msg 中的是否相同
  // make sure locator is consistent
  object_locator_t oloc(obc-&gt;obs.oi.soid);
  if (m-&gt;get_object_locator() != oloc)
  {
    dout(10) &lt;&lt; &quot; provided locator &quot; &lt;&lt; m-&gt;get_object_locator()
             &lt;&lt; &quot; != object's &quot; &lt;&lt; obc-&gt;obs.oi.soid &lt;&lt; dendl;
    osd-&gt;clog-&gt;warn() &lt;&lt; &quot;bad locator &quot; &lt;&lt; m-&gt;get_object_locator()
                      &lt;&lt; &quot; on object &quot; &lt;&lt; oloc
                      &lt;&lt; &quot; op &quot; &lt;&lt; *m;
  }

  // 检查该对象是否被阻塞
  // io blocked on obc?
  if (obc-&gt;is_blocked() &amp;&amp;
      !m-&gt;has_flag(CEPH_OSD_FLAG_FLUSH))
  {
    wait_for_blocked_object(obc-&gt;obs.oi.soid, op);
    return;
  }

  dout(25) &lt;&lt; __func__ &lt;&lt; &quot; oi &quot; &lt;&lt; obc-&gt;obs.oi &lt;&lt; dendl;



  // 获取对象上下文，创建 OpContext 对 op 进行跟踪
  OpContext *ctx = new OpContext(op, m-&gt;get_reqid(), &amp;m-&gt;ops, obc, this);

  // 根据对应的 flag 决定锁的处理方式
  if (m-&gt;has_flag(CEPH_OSD_FLAG_SKIPRWLOCKS))
  {
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: skipping rw locks&quot; &lt;&lt; dendl;
  }
  else if (m-&gt;get_flags() &amp; CEPH_OSD_FLAG_FLUSH)
  {
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: part of flush, will ignore write lock&quot; &lt;&lt; dendl;

    // verify there is in fact a flush in progress
    // FIXME: we could make this a stronger test.
    map&lt;hobject_t, FlushOpRef&gt;::iterator p = flush_ops.find(obc-&gt;obs.oi.soid);
    if (p == flush_ops.end())
    {
      dout(10) &lt;&lt; __func__ &lt;&lt; &quot; no flush in progress, aborting&quot; &lt;&lt; dendl;
      reply_ctx(ctx, -EINVAL);
      return;
    }
  }
  else if (!get_rw_locks(write_ordered, ctx))
  {
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot; waiting for rw locks &quot; &lt;&lt; dendl;
    op-&gt;mark_delayed(&quot;waiting for rw locks&quot;);
    close_op_ctx(ctx);
    return;
  }
  dout(20) &lt;&lt; __func__ &lt;&lt; &quot; obc &quot; &lt;&lt; *obc &lt;&lt; dendl;

  if (r)
  {
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot; returned an error: &quot; &lt;&lt; r &lt;&lt; dendl;
    if (op-&gt;may_write() &amp;&amp;
        get_osdmap()-&gt;require_osd_release &gt;= ceph_release_t::kraken)
    {
      record_write_error(op, oid, nullptr, r,
                         ctx-&gt;op-&gt;allows_returnvec() ? ctx : nullptr);
    }
    else
    {
      osd-&gt;reply_op_error(op, r);
    }
    close_op_ctx(ctx);
    return;
  }

  if (m-&gt;has_flag(CEPH_OSD_FLAG_IGNORE_CACHE))
  {
    ctx-&gt;ignore_cache = true;
  }

  if ((op-&gt;may_read()) &amp;&amp; (obc-&gt;obs.oi.is_lost()))
  {
    // This object is lost. Reading from it returns an error.
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot;: object &quot; &lt;&lt; obc-&gt;obs.oi.soid
             &lt;&lt; &quot; is lost&quot; &lt;&lt; dendl;
    reply_ctx(ctx, -ENFILE);
    return;
  }
  if (!op-&gt;may_write() &amp;&amp;
      !op-&gt;may_cache() &amp;&amp;
      (!obc-&gt;obs.exists ||
       ((m-&gt;get_snapid() != CEPH_SNAPDIR) &amp;&amp;
        obc-&gt;obs.oi.is_whiteout())))
  {
    // copy the reqids for copy get on ENOENT
    if (m-&gt;ops[0].op.op == CEPH_OSD_OP_COPY_GET)
    {
      fill_in_copy_get_noent(op, oid, m-&gt;ops[0]);
      close_op_ctx(ctx);
      return;
    }
    reply_ctx(ctx, -ENOENT);
    return;
  }

  op-&gt;mark_started();


  // 真正开始执行 op
  execute_ctx(ctx);
  utime_t prepare_latency = ceph_clock_now();
  prepare_latency -= op-&gt;get_dequeued_time();
  osd-&gt;logger-&gt;tinc(l_osd_op_prepare_lat, prepare_latency);
  if (op-&gt;may_read() &amp;&amp; op-&gt;may_write())
  {
    osd-&gt;logger-&gt;tinc(l_osd_op_rw_prepare_lat, prepare_latency);
  }
  else if (op-&gt;may_read())
  {
    osd-&gt;logger-&gt;tinc(l_osd_op_r_prepare_lat, prepare_latency);
  }
  else if (op-&gt;may_write() || op-&gt;may_cache())
  {
    osd-&gt;logger-&gt;tinc(l_osd_op_w_prepare_lat, prepare_latency);
  }

  // force recovery of the oldest missing object if too many logs
  maybe_force_recovery();
}
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200923165351.png" alt="20200923165351" loading="lazy"></figure>
<h2 id="execute_ctx">execute_ctx</h2>
<pre><code class="language-C++">void PrimaryLogPG::execute_ctx(OpContext *ctx)
{
  FUNCTRACE(cct);
  dout(10) &lt;&lt; __func__ &lt;&lt; &quot; &quot; &lt;&lt; ctx &lt;&lt; dendl;
  ctx-&gt;reset_obs(ctx-&gt;obc);
  ctx-&gt;update_log_only = false; // reset in case finish_copyfrom() is re-running execute_ctx
  OpRequestRef op = ctx-&gt;op;
  auto m = op-&gt;get_req&lt;MOSDOp&gt;();
  ObjectContextRef obc = ctx-&gt;obc;
  const hobject_t &amp;soid = obc-&gt;obs.oi.soid;

  // this method must be idempotent since we may call it several times
  // before we finally apply the resulting transaction.
  ctx-&gt;op_t.reset(new PGTransaction);

 
  // 写操作
  if (op-&gt;may_write() || op-&gt;may_cache())
  {
    // snap
    // 对于快照进行一些处理
    if (!(m-&gt;has_flag(CEPH_OSD_FLAG_ENFORCE_SNAPC)) &amp;&amp;
        pool.info.is_pool_snaps_mode())
    {
      // 更新 ctx-&gt;snapc，该值保存了该操作的客户端附带的快照相关信息
      // use pool's snapc
      ctx-&gt;snapc = pool.snapc;
    }
    else
    {
      // 用户特定快照，通常为 RBD 快照，此时设置为消息中携带的信息
      // client specified snapc
      ctx-&gt;snapc.seq = m-&gt;get_snap_seq();
      ctx-&gt;snapc.snaps = m-&gt;get_snaps();
      filter_snapc(ctx-&gt;snapc.snaps);
    }

    // 比较 SNAP_SEQ，如果客户端的更小则报错
    if ((m-&gt;has_flag(CEPH_OSD_FLAG_ORDERSNAP)) &amp;&amp;
        ctx-&gt;snapc.seq &lt; obc-&gt;ssc-&gt;snapset.seq)
    {
      dout(10) &lt;&lt; &quot; ORDERSNAP flag set and snapc seq &quot; &lt;&lt; ctx-&gt;snapc.seq
               &lt;&lt; &quot; &lt; snapset seq &quot; &lt;&lt; obc-&gt;ssc-&gt;snapset.seq
               &lt;&lt; &quot; on &quot; &lt;&lt; obc-&gt;obs.oi.soid &lt;&lt; dendl;
      reply_ctx(ctx, -EOLDSNAPC);
      return;
    }

    // 更新 OpContext 版本号
    // version
    ctx-&gt;at_version = get_next_version();
    ctx-&gt;mtime = m-&gt;get_mtime();

    dout(10) &lt;&lt; __func__ &lt;&lt; &quot; &quot; &lt;&lt; soid &lt;&lt; &quot; &quot; &lt;&lt; *ctx-&gt;ops
             &lt;&lt; &quot; ov &quot; &lt;&lt; obc-&gt;obs.oi.version &lt;&lt; &quot; av &quot; &lt;&lt; ctx-&gt;at_version
             &lt;&lt; &quot; snapc &quot; &lt;&lt; ctx-&gt;snapc
             &lt;&lt; &quot; snapset &quot; &lt;&lt; obc-&gt;ssc-&gt;snapset
             &lt;&lt; dendl;
  }
  else
  {
    dout(10) &lt;&lt; __func__ &lt;&lt; &quot; &quot; &lt;&lt; soid &lt;&lt; &quot; &quot; &lt;&lt; *ctx-&gt;ops
             &lt;&lt; &quot; ov &quot; &lt;&lt; obc-&gt;obs.oi.version
             &lt;&lt; dendl;
  }

  if (!ctx-&gt;user_at_version)
    ctx-&gt;user_at_version = obc-&gt;obs.oi.user_version;
  dout(30) &lt;&lt; __func__ &lt;&lt; &quot; user_at_version &quot; &lt;&lt; ctx-&gt;user_at_version &lt;&lt; dendl;

  {
#ifdef WITH_LTTNG
    osd_reqid_t reqid = ctx-&gt;op-&gt;get_reqid();
#endif
    tracepoint(osd, prepare_tx_enter, reqid.name._type,
               reqid.name._num, reqid.tid, reqid.inc);
  }

  // 准备事务
  // 1. 通过 do_osd_ops 生成原始 op 对应的 PG 事务
  // 2. 如果 op 针对 head 对象进行操作，通过 make_writable 检查是否需要预先执行克隆操作
  // 3. 通过 finish_ctx 检查是否需要创建或者删除 snapdir 对象，生成日志，并更新对象的 OI（object_info_t） 和 SS（SnapSet） 属性
  // 其中涉及了大量的对克隆和快照的处理
  int result = prepare_transaction(ctx);

  {
#ifdef WITH_LTTNG
    osd_reqid_t reqid = ctx-&gt;op-&gt;get_reqid();
#endif
    tracepoint(osd, prepare_tx_exit, reqid.name._type,
               reqid.name._num, reqid.tid, reqid.inc);
  }

  // 异步读则将 op 加入 in_progress_async_reads 队列，完成之后再向客户端应答
  bool pending_async_reads = !ctx-&gt;pending_async_reads.empty();
  if (result == -EINPROGRESS || pending_async_reads)
  {
    // come back later.
    if (pending_async_reads)
    {
      ceph_assert(pool.info.is_erasure());
      in_progress_async_reads.push_back(make_pair(op, ctx));
      // 完成异步读取
      ctx-&gt;start_async_reads(this);
    }
    return;
  }

  if (result == -EAGAIN)
  {
    // clean up after the ctx
    close_op_ctx(ctx);
    return;
  }

  bool ignore_out_data = false;
  if (!ctx-&gt;op_t-&gt;empty() &amp;&amp;
      op-&gt;may_write() &amp;&amp;
      result &gt;= 0)
  {
    // successful update
    if (ctx-&gt;op-&gt;allows_returnvec())
    {
      // enforce reasonable bound on the return buffer sizes
      for (auto &amp;i : *ctx-&gt;ops)
      {
        if (i.outdata.length() &gt; cct-&gt;_conf-&gt;osd_max_write_op_reply_len)
        {
          dout(10) &lt;&lt; __func__ &lt;&lt; &quot; op &quot; &lt;&lt; i &lt;&lt; &quot; outdata overflow&quot; &lt;&lt; dendl;
          result = -EOVERFLOW; // overall result is overflow
          i.rval = -EOVERFLOW;
          i.outdata.clear();
        }
      }
    }
    else
    {
      // legacy behavior -- zero result and return data etc.
      ignore_out_data = true;
      result = 0;
    }
  }

  // prepare the reply
  ctx-&gt;reply = new MOSDOpReply(m, result, get_osdmap_epoch(), 0,
                               ignore_out_data);
  dout(20) &lt;&lt; __func__ &lt;&lt; &quot; alloc reply &quot; &lt;&lt; ctx-&gt;reply
           &lt;&lt; &quot; result &quot; &lt;&lt; result &lt;&lt; dendl;

  // 只包含读操作或者 失败，是则向客户端发送应答
  // read or error?
  if ((ctx-&gt;op_t-&gt;empty() || result &lt; 0) &amp;&amp; !ctx-&gt;update_log_only)
  {
    // finish side-effects
    if (result &gt;= 0)
      do_osd_op_effects(ctx, m-&gt;get_connection());

    // 同步读取调用以下方法完成读操作
    complete_read_ctx(result, ctx);
    return;
  }

  ctx-&gt;reply-&gt;set_reply_versions(ctx-&gt;at_version, ctx-&gt;user_at_version);


  // 后续均为写操作
  ceph_assert(op-&gt;may_write() || op-&gt;may_cache());

  // trim log?
  // 将旧的日志进行 trim
  // calc_trim_to_aggressive()
  // calc_trim_to()
  recovery_state.update_trim_to();

  // verify that we are doing this in order?
  if (cct-&gt;_conf-&gt;osd_debug_op_order &amp;&amp; m-&gt;get_source().is_client() &amp;&amp;
      !pool.info.is_tier() &amp;&amp; !pool.info.has_tiers())
  {
    map&lt;client_t, ceph_tid_t&gt; &amp;cm = debug_op_order[obc-&gt;obs.oi.soid];
    ceph_tid_t t = m-&gt;get_tid();
    client_t n = m-&gt;get_source().num();
    map&lt;client_t, ceph_tid_t&gt;::iterator p = cm.find(n);
    if (p == cm.end())
    {
      dout(20) &lt;&lt; &quot; op order client.&quot; &lt;&lt; n &lt;&lt; &quot; tid &quot; &lt;&lt; t &lt;&lt; &quot; (first)&quot; &lt;&lt; dendl;
      cm[n] = t;
    }
    else
    {
      dout(20) &lt;&lt; &quot; op order client.&quot; &lt;&lt; n &lt;&lt; &quot; tid &quot; &lt;&lt; t &lt;&lt; &quot; last was &quot; &lt;&lt; p-&gt;second &lt;&lt; dendl;
      if (p-&gt;second &gt; t)
      {
        derr &lt;&lt; &quot;bad op order, already applied &quot; &lt;&lt; p-&gt;second &lt;&lt; &quot; &gt; this &quot; &lt;&lt; t &lt;&lt; dendl;
        ceph_abort_msg(&quot;out of order op&quot;);
      }
      p-&gt;second = t;
    }
  }

  if (ctx-&gt;update_log_only)
  {
    if (result &gt;= 0)
      do_osd_op_effects(ctx, m-&gt;get_connection());

    dout(20) &lt;&lt; __func__ &lt;&lt; &quot; update_log_only -- result=&quot; &lt;&lt; result &lt;&lt; dendl;
    // save just what we need from ctx
    MOSDOpReply *reply = ctx-&gt;reply;
    ctx-&gt;reply = nullptr;
    reply-&gt;get_header().data_off = (ctx-&gt;data_off ? *ctx-&gt;data_off : 0);

    if (result == -ENOENT)
    {
      reply-&gt;set_enoent_reply_versions(info.last_update,
                                       info.last_user_version);
    }
    reply-&gt;add_flags(CEPH_OSD_FLAG_ACK | CEPH_OSD_FLAG_ONDISK);
    // append to pg log for dup detection - don't save buffers for now
    record_write_error(op, soid, reply, result,
                       ctx-&gt;op-&gt;allows_returnvec() ? ctx : nullptr);
    close_op_ctx(ctx);
    return;
  }

  // 写操作则注册如下的回调函数：按照如下顺序要求
  // 1. on_commit: 执行时，向客户端发送写入完成应答
  // 2. on_success: 执行时，进行 Watch/Notify 相关的处理
  // 3. on_finish: 执行时，删除 OpContext
  // no need to capture PG ref, repop cancel will handle that
  // Can capture the ctx by pointer, it's owned by the repop
  ctx-&gt;register_on_commit(
      [m, ctx, this]() {
        if (ctx-&gt;op)
          log_op_stats(*ctx-&gt;op, ctx-&gt;bytes_written, ctx-&gt;bytes_read);

        if (m &amp;&amp; !ctx-&gt;sent_reply)
        {
          MOSDOpReply *reply = ctx-&gt;reply;
          ctx-&gt;reply = nullptr;
          reply-&gt;add_flags(CEPH_OSD_FLAG_ACK | CEPH_OSD_FLAG_ONDISK);
          dout(10) &lt;&lt; &quot; sending reply on &quot; &lt;&lt; *m &lt;&lt; &quot; &quot; &lt;&lt; reply &lt;&lt; dendl;
          osd-&gt;send_message_osd_client(reply, m-&gt;get_connection());
          ctx-&gt;sent_reply = true;
          ctx-&gt;op-&gt;mark_commit_sent();
        }
      });
  ctx-&gt;register_on_success(
      [ctx, this]() {
        do_osd_op_effects(
            ctx,
            ctx-&gt;op ? ctx-&gt;op-&gt;get_req()-&gt;get_connection() : ConnectionRef());
      });
  ctx-&gt;register_on_finish(
      [ctx]() {
        delete ctx;
      });

  // 事务准备完成，由 Primary 进行副本间的本地事务分发和整体同步
  // issue replica writes
  ceph_tid_t rep_tid = osd-&gt;get_tid();

  // 创建一个 RepGather
  RepGather *repop = new_repop(ctx, obc, rep_tid);

  // 将 RepGather 提交到 PGBackend，由 PGBackend 负责将 PG 事务转为每个副本的本地事务，然后分发
  // 即向各个副本发送同步操作请求
  issue_repop(repop, ctx);

  // 评估 RepGather 是否真正完成，真正完成后则依次执行 RepGather 中注册过的一系列回调函数，最后删除 RepGather
  // 检查各个副本的同步操作是否已经 reply 成功
  eval_repop(repop);
  repop-&gt;put();
}
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/zjs1224522500/PicGoImages/master//img/blog/20200924154633.png" alt="20200924154633" loading="lazy"></figure>
<h2 id="issue_repop">issue_repop</h2>
<ul>
<li>真正的分发逻辑，和 OSD 本地事务处理都封装在该方法中。回顾上述主流程中关于多副本写操作的处理：</li>
</ul>
<pre><code class="language-C++">
  // 写操作则注册如下的回调函数：按照如下顺序要求
  // 1. on_commit: 执行时，向客户端发送写入完成应答
  // 2. on_success: 执行时，进行 Watch/Notify 相关的处理
  // 3. on_finish: 执行时，删除 OpContext
  // no need to capture PG ref, repop cancel will handle that
  // Can capture the ctx by pointer, it's owned by the repop
  ctx-&gt;register_on_commit(
      [m, ctx, this]() {
        if (ctx-&gt;op)
          log_op_stats(*ctx-&gt;op, ctx-&gt;bytes_written, ctx-&gt;bytes_read);

        if (m &amp;&amp; !ctx-&gt;sent_reply)
        {
          MOSDOpReply *reply = ctx-&gt;reply;
          ctx-&gt;reply = nullptr;
          reply-&gt;add_flags(CEPH_OSD_FLAG_ACK | CEPH_OSD_FLAG_ONDISK);
          dout(10) &lt;&lt; &quot; sending reply on &quot; &lt;&lt; *m &lt;&lt; &quot; &quot; &lt;&lt; reply &lt;&lt; dendl;
          osd-&gt;send_message_osd_client(reply, m-&gt;get_connection());
          ctx-&gt;sent_reply = true;
          ctx-&gt;op-&gt;mark_commit_sent();
        }
      });
  ctx-&gt;register_on_success(
      [ctx, this]() {
        do_osd_op_effects(
            ctx,
            ctx-&gt;op ? ctx-&gt;op-&gt;get_req()-&gt;get_connection() : ConnectionRef());
      });
  ctx-&gt;register_on_finish(
      [ctx]() {
        delete ctx;
      });

  // 事务准备完成，由 Primary 进行副本间的本地事务分发和整体同步
  // issue replica writes
  ceph_tid_t rep_tid = osd-&gt;get_tid();

  // 创建一个 RepGather
  RepGather *repop = new_repop(ctx, obc, rep_tid);

  // 将 RepGather 提交到 PGBackend，由 PGBackend 负责将 PG 事务转为每个副本的本地事务，然后分发
  // 即向各个副本发送同步操作请求
  issue_repop(repop, ctx);

  // 评估 RepGather 是否真正完成，真正完成后则依次执行 RepGather 中注册过的一系列回调函数，最后删除 RepGather
  // 检查各个副本的同步操作是否已经 reply 成功
  eval_repop(repop);
  repop-&gt;put();
</code></pre>
<ul>
<li>其中 issue_repopn 主要是调用了 <code>submit_transaction</code> 让对应的 PGBackend 来执行事务</li>
</ul>
<pre><code class="language-C++">pgbackend-&gt;submit_transaction(
      soid,
      ctx-&gt;delta_stats,
      ctx-&gt;at_version,
      std::move(ctx-&gt;op_t),
      recovery_state.get_pg_trim_to(),
      recovery_state.get_min_last_complete_ondisk(),
      std::move(ctx-&gt;log),
      ctx-&gt;updated_hset_history,
      on_all_commit,
      repop-&gt;rep_tid,
      ctx-&gt;reqid,
      ctx-&gt;op);
}
</code></pre>
<h3 id="submit_transaction">submit_transaction</h3>
<ul>
<li>此处暂时只讨论 ReplicatedBackend，即多副本情况下的事务提交
<ul>
<li>副本方式：核心处理流程是把封装好的事务分发到该 PG 对应的其他从 OSD 上</li>
<li>纠删码方式：核心处理流程是为主 chunk 向各个分片 chunk 分发数据的过程</li>
</ul>
</li>
<li>通过 <code>issue_op</code> 分发消息到副本 OSD（异步），当前 OSD 相应地执行日志操作以及完成本地 OSD 请求的处理<code>queue_transactions</code>。</li>
</ul>
<pre><code class="language-C++">void ReplicatedBackend::submit_transaction(
    const hobject_t &amp;soid,
    const object_stat_sum_t &amp;delta_stats,
    const eversion_t &amp;at_version,
    PGTransactionUPtr &amp;&amp;_t,
    const eversion_t &amp;trim_to,
    const eversion_t &amp;min_last_complete_ondisk,
    vector&lt;pg_log_entry_t&gt; &amp;&amp;_log_entries,
    std::optional&lt;pg_hit_set_history_t&gt; &amp;hset_history,
    Context *on_all_commit,
    ceph_tid_t tid,
    osd_reqid_t reqid,
    OpRequestRef orig_op)
{
  parent-&gt;apply_stats(
      soid,
      delta_stats);

  vector&lt;pg_log_entry_t&gt; log_entries(_log_entries);
  ObjectStore::Transaction op_t;
  PGTransactionUPtr t(std::move(_t));
  set&lt;hobject_t&gt; added, removed;

  // 根据具体的操作类型生成相应的事务
  generate_transaction(
      t,
      coll,
      log_entries,
      &amp;op_t,
      &amp;added,
      &amp;removed,
      get_osdmap()-&gt;require_osd_release);
  ceph_assert(added.size() &lt;= 1);
  ceph_assert(removed.size() &lt;= 1);

  // 构建处理中的请求记录 in_progress_ops
  auto insert_res = in_progress_ops.insert(
      make_pair(
          tid,
          ceph::make_ref&lt;InProgressOp&gt;(
              tid, on_all_commit,
              orig_op, at_version)));
  ceph_assert(insert_res.second);
  InProgressOp &amp;op = *insert_res.first-&gt;second;

  // 统计 commit 的副本操作数量，等待副本操作完成回调时进行清除，使用该结构方便统计是不是所有的副本都完成了操作。
  op.waiting_for_commit.insert(
      parent-&gt;get_acting_recovery_backfill_shards().begin(),
      parent-&gt;get_acting_recovery_backfill_shards().end());

  // 把请求发送出去
  issue_op(
      soid,
      at_version,
      tid,
      reqid,
      trim_to,
      min_last_complete_ondisk,
      added.size() ? *(added.begin()) : hobject_t(),
      removed.size() ? *(removed.begin()) : hobject_t(),
      log_entries,
      hset_history,
      &amp;op,
      op_t);

  add_temp_objs(added);
  clear_temp_objs(removed);

  //进行日志操作，开始记录本端操作 object 的 log
  parent-&gt;log_operation(
      std::move(log_entries),
      hset_history,
      trim_to,
      at_version,
      min_last_complete_ondisk,
      true,
      op_t);

  // 开始注册本端的 commit 回调函数，这里回调后直接向上返回
  op_t.register_on_commit(
      parent-&gt;bless_context(
          new C_OSD_OnOpCommit(this, &amp;op)));

  vector&lt;ObjectStore::Transaction&gt; tls;
  tls.push_back(std::move(op_t));

  // 完成本地 OSD 的请求处理
  parent-&gt;queue_transactions(tls, op.op);
  if (at_version != eversion_t())
  {
    parent-&gt;op_applied(at_version);
  }
}
</code></pre>
<h3 id="issue_op">issue_op</h3>
<ul>
<li>该方法构造相应的写请求，以消息的方式发送到该主 OSD 对应的副本 OSD 上。</li>
</ul>
<pre><code class="language-C++">void ReplicatedBackend::issue_op(
    const hobject_t &amp;soid,
    const eversion_t &amp;at_version,
    ceph_tid_t tid,
    osd_reqid_t reqid,
    eversion_t pg_trim_to,
    eversion_t min_last_complete_ondisk,
    hobject_t new_temp_oid,
    hobject_t discard_temp_oid,
    const vector&lt;pg_log_entry_t&gt; &amp;log_entries,
    std::optional&lt;pg_hit_set_history_t&gt; &amp;hset_hist,
    InProgressOp *op,
    ObjectStore::Transaction &amp;op_t)
{
  // 副本节点数量 &gt; 1
  if (parent-&gt;get_acting_recovery_backfill_shards().size() &gt; 1)
  {
    if (op-&gt;op)
    {
      op-&gt;op-&gt;pg_trace.event(&quot;issue replication ops&quot;);
      ostringstream ss;
      set&lt;pg_shard_t&gt; replicas = parent-&gt;get_acting_recovery_backfill_shards();
      replicas.erase(parent-&gt;whoami_shard());
      ss &lt;&lt; &quot;waiting for subops from &quot; &lt;&lt; replicas;
      op-&gt;op-&gt;mark_sub_op_sent(ss.str());
    }

    // avoid doing the same work in generate_subop
    bufferlist logs;
    encode(log_entries, logs);

    // 遍历所有的 replica OSDs
    for (const auto &amp;shard : get_parent()-&gt;get_acting_recovery_backfill_shards())
    {
      // 如果该节点是主节点，跳过
      if (shard == parent-&gt;whoami_shard())
        continue;

      // 获取副本节点对应的 pg
      const pg_info_t &amp;pinfo = parent-&gt;get_shard_info().find(shard)-&gt;second;

      Message *wr;

      // 使用相应的参数构造 REPOP 请求
      wr = generate_subop(
          soid,
          at_version,
          tid,
          reqid,
          pg_trim_to,
          min_last_complete_ondisk,
          new_temp_oid,
          discard_temp_oid,
          logs,
          hset_hist,
          op_t,
          shard,
          pinfo);
      if (op-&gt;op &amp;&amp; op-&gt;op-&gt;pg_trace)
        wr-&gt;trace.init(&quot;replicated op&quot;, nullptr, &amp;op-&gt;op-&gt;pg_trace);

      // 将消息发送出去到整个集群
      // void OSDService::send_message_osd_cluster(int peer, Message *m, epoch_t from_epoch)
      // 写操作的消息发送给对应副本节点对应的 osd
      get_parent()-&gt;send_message_osd_cluster(
          shard.osd, wr, get_osdmap_epoch());
    }
  }
}
</code></pre>
<h3 id="do_repop">do_repop</h3>
<ul>
<li>相应的副本 OSD 收到消息时，继续上述流程，从头到尾，直到执行对应的 <code>do_request</code> 方法。在 <code>do_request</code> 方法中曾介绍有对部分请求的处理，截取如下：</li>
</ul>
<pre><code class="language-C++">  // 由 PGBackend 直接处理然后返回，此处只处理以下操作
  // 1. MSG_OSD_PG_RECOVERY_DELETE (Common)
  // 2. MSG_OSD_PG_RECOVERY_DELETE_REPLY (Common)
  // 3. MSG_OSD_PG_PUSH (副本)
  // 4. MSG_OSD_PG_PULL (副本)
  // 5. MSG_OSD_PG_PUSH_REPLY (副本)
  // 6. MSG_OSD_REPOP (副本)
  // 7. MSG_OSD_REPOPREPLY (副本)
  // 8. MSG_OSD_EC_WRITE (EC)
  // 9. MSG_OSD_EC_WRITE_REPLY (EC)
  // 10. MSG_OSD_EC_READ (EC)
  // 11. MSG_OSD_EC_READ_REPLY (EC)
  // 12. MSG_OSD_PG_PUSH (EC)
  // 13. MSG_OSD_PG_PUSH_REPLY (EC)
  if (pgbackend-&gt;handle_message(op))
    return;
</code></pre>
<ul>
<li>其中就包含 MSG_OSD_REPOP 和 MSG_OSD_REPOPREPLY 的处理（针对多副本）。又相应地调用了 <code>do_repop</code> 和 <code>do_repop_reply</code> 方法</li>
</ul>
<pre><code class="language-C++">bool ReplicatedBackend::_handle_message(
    OpRequestRef op)
{
  dout(10) &lt;&lt; __func__ &lt;&lt; &quot;: &quot; &lt;&lt; op &lt;&lt; dendl;
  switch (op-&gt;get_req()-&gt;get_type())
  {
  case MSG_OSD_PG_PUSH:
    do_push(op);
    return true;

  case MSG_OSD_PG_PULL:
    do_pull(op);
    return true;

  case MSG_OSD_PG_PUSH_REPLY:
    do_push_reply(op);
    return true;

  case MSG_OSD_REPOP:
  {
    do_repop(op);
    return true;
  }

  case MSG_OSD_REPOPREPLY:
  {
    do_repop_reply(op);
    return true;
  }

  default:
    break;
  }
  return false;
}
</code></pre>
<ul>
<li><code>do_repop</code> 用于处理 repop 类型的 msg，相应地检查参数和当前 OSD 对应的状态，记录日志，注册回调函数，并执行本地事务更新。</li>
</ul>
<pre><code class="language-C++">// sub op modify
void ReplicatedBackend::do_repop(OpRequestRef op)
{
  static_cast&lt;MOSDRepOp *&gt;(op-&gt;get_nonconst_req())-&gt;finish_decode();
  // 获取当前消息
  auto m = op-&gt;get_req&lt;MOSDRepOp&gt;();
  // 检查消息类型
  int msg_type = m-&gt;get_type();
  ceph_assert(MSG_OSD_REPOP == msg_type);

  const hobject_t &amp;soid = m-&gt;poid;

  dout(10) &lt;&lt; __func__ &lt;&lt; &quot; &quot; &lt;&lt; soid
           &lt;&lt; &quot; v &quot; &lt;&lt; m-&gt;version
           &lt;&lt; (m-&gt;logbl.length() ? &quot; (transaction)&quot; : &quot; (parallel exec&quot;)
           &lt;&lt; &quot; &quot; &lt;&lt; m-&gt;logbl.length()
           &lt;&lt; dendl;

  // 检查版本号和 interval
  // sanity checks
  ceph_assert(m-&gt;map_epoch &gt;= get_info().history.same_interval_since);

  // 检查该副本节点是否在进行 scrub 操作
  dout(30) &lt;&lt; __func__ &lt;&lt; &quot; missing before &quot; &lt;&lt; get_parent()-&gt;get_log().get_missing().get_items() &lt;&lt; dendl;
  parent-&gt;maybe_preempt_replica_scrub(soid);

  // 获取消息来源
  int ackerosd = m-&gt;get_source().num();

  // 标记当前操作开始，设置相关参数
  op-&gt;mark_started();

  RepModifyRef rm(std::make_shared&lt;RepModify&gt;());
  rm-&gt;op = op;
  rm-&gt;ackerosd = ackerosd;
  rm-&gt;last_complete = get_info().last_complete;
  rm-&gt;epoch_started = get_osdmap_epoch();

  ceph_assert(m-&gt;logbl.length());
  // shipped transaction and log entries
  vector&lt;pg_log_entry_t&gt; log;

  auto p = const_cast&lt;bufferlist &amp;&gt;(m-&gt;get_data()).cbegin();
  decode(rm-&gt;opt, p);

  if (m-&gt;new_temp_oid != hobject_t())
  {
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot; start tracking temp &quot; &lt;&lt; m-&gt;new_temp_oid &lt;&lt; dendl;
    add_temp_obj(m-&gt;new_temp_oid);
  }
  if (m-&gt;discard_temp_oid != hobject_t())
  {
    dout(20) &lt;&lt; __func__ &lt;&lt; &quot; stop tracking temp &quot; &lt;&lt; m-&gt;discard_temp_oid &lt;&lt; dendl;
    if (rm-&gt;opt.empty())
    {
      dout(10) &lt;&lt; __func__ &lt;&lt; &quot;: removing object &quot; &lt;&lt; m-&gt;discard_temp_oid
               &lt;&lt; &quot; since we won't get the transaction&quot; &lt;&lt; dendl;
      rm-&gt;localt.remove(coll, ghobject_t(m-&gt;discard_temp_oid));
    }
    clear_temp_obj(m-&gt;discard_temp_oid);
  }

  p = const_cast&lt;bufferlist &amp;&gt;(m-&gt;logbl).begin();
  decode(log, p);
  rm-&gt;opt.set_fadvise_flag(CEPH_OSD_OP_FLAG_FADVISE_DONTNEED);

  bool update_snaps = false;
  if (!rm-&gt;opt.empty())
  {
    // If the opt is non-empty, we infer we are before
    // last_backfill (according to the primary, not our
    // not-quite-accurate value), and should update the
    // collections now.  Otherwise, we do it later on push.
    update_snaps = true;
  }

  // flag set to true during async recovery
  bool async = false;
  pg_missing_tracker_t pmissing = get_parent()-&gt;get_local_missing();
  if (pmissing.is_missing(soid))
  {
    async = true;
    dout(30) &lt;&lt; __func__ &lt;&lt; &quot; is_missing &quot; &lt;&lt; pmissing.is_missing(soid) &lt;&lt; dendl;
    for (auto &amp;&amp;e : log)
    {
      dout(30) &lt;&lt; &quot; add_next_event entry &quot; &lt;&lt; e &lt;&lt; dendl;
      get_parent()-&gt;add_local_next_event(e);
      dout(30) &lt;&lt; &quot; entry is_delete &quot; &lt;&lt; e.is_delete() &lt;&lt; dendl;
    }
  }

  parent-&gt;update_stats(m-&gt;pg_stats);

  // 更新日志
  parent-&gt;log_operation(
      std::move(log),
      m-&gt;updated_hit_set_history,
      m-&gt;pg_trim_to,
      m-&gt;version, /* Replicated PGs don't have rollback info */
      m-&gt;min_last_complete_ondisk,
      update_snaps,
      rm-&gt;localt,
      async);

  // 注册回调函数 C_OSD_RepModifyCommit，回调完成后调用 pg-&gt;repop_commit(rm)
  // C_OSD_RepModifyCommit(ReplicatedBackend *pg, RepModifyRef r)
  //     : pg(pg), rm(r) {}
  // void finish(int r) override
  // {
  //   pg-&gt;repop_commit(rm);
  // }
  rm-&gt;opt.register_on_commit(
      parent-&gt;bless_context(
          new C_OSD_RepModifyCommit(this, rm)));
  vector&lt;ObjectStore::Transaction&gt; tls;
  tls.reserve(2);
  tls.push_back(std::move(rm-&gt;localt));
  tls.push_back(std::move(rm-&gt;opt));

  // 本地事务更新
  parent-&gt;queue_transactions(tls, op);
  // op is cleaned up by oncommit/onapply when both are executed
  dout(30) &lt;&lt; __func__ &lt;&lt; &quot; missing after&quot; &lt;&lt; get_parent()-&gt;get_log().get_missing().get_items() &lt;&lt; dendl;
}
</code></pre>
<h3 id="queue_transactions">queue_transactions</h3>
<ul>
<li>无论是一开始的主节点还是后面描述的副本节点执行写操作都调用了 <code>queue_transactions</code> 该方法，该方法是ObjectStore 层的统一入口，KVStore、MemStore、FileStore、BlueStore都相应的实现了这个接口。</li>
<li>该方法相应地创建事务上下文并进行保序，并执行事务状态机，事务提交后相应地执行上文注册的一系列回调函数。</li>
</ul>
<pre><code class="language-C++">// ---------------------------
// transactions

int BlueStore::queue_transactions(
    CollectionHandle &amp;ch,
    vector&lt;Transaction&gt; &amp;tls,
    TrackedOpRef op,
    ThreadPool::TPHandle *handle)
{
  FUNCTRACE(cct);

  // on_commoit: 事务提交完成之后的回调函数
  // on_applied_sync: 同步调用执行，事务应用完成之后的回调函数
  // on_applied: 在 Finisher 线程里异步调用执行，事务应用完成之后的回调函数
  list&lt;Context *&gt; on_applied, on_commit, on_applied_sync;
  ObjectStore::Transaction::collect_contexts(
      tls, &amp;on_applied, &amp;on_commit, &amp;on_applied_sync);

  // 计时开始
  auto start = mono_clock::now();

  Collection *c = static_cast&lt;Collection *&gt;(ch.get());

  // 获取操作序列号，用于保序。
  // 会判断 PG 是否已经关联 OpSeq，未关联则新建并关联 PG
  OpSequencer *osr = c-&gt;osr.get();
  dout(10) &lt;&lt; __func__ &lt;&lt; &quot; ch &quot; &lt;&lt; c &lt;&lt; &quot; &quot; &lt;&lt; c-&gt;cid &lt;&lt; dendl;

  // 创建 TransContext，并关联回调函数 on_commit
  // prepare
  TransContext *txc = _txc_create(static_cast&lt;Collection *&gt;(ch.get()), osr,
                                  &amp;on_commit, op);

  // With HM-SMR drives (and ZNS SSDs) we want the I/O allocation and I/O
  // submission to happen atomically because if I/O submission happens in a
  // different order than I/O allocation, we end up issuing non-sequential
  // writes to the drive.  This is a temporary solution until ZONE APPEND
  // support matures in the kernel.  For more information please see:
  // https://www.usenix.org/conference/vault20/presentation/bjorling
  if (bdev-&gt;is_smr())
  {
    atomic_alloc_and_submit_lock.lock();
  }

  // 将所有的写操作添加到 TransContext，并记录操作字节数
  for (vector&lt;Transaction&gt;::iterator p = tls.begin(); p != tls.end(); ++p)
  {
    txc-&gt;bytes += (*p).get_num_bytes();
    _txc_add_transaction(txc, &amp;(*p));
  }

  // 计算开销
  _txc_calc_cost(txc);

  // 更新 ONodes， shared_blobs
  _txc_write_nodes(txc, txc-&gt;t);

  // journal deferred items
  if (txc-&gt;deferred_txn)
  {
    txc-&gt;deferred_txn-&gt;seq = ++deferred_seq;
    bufferlist bl;
    encode(*txc-&gt;deferred_txn, bl);
    string key;
    get_deferred_key(txc-&gt;deferred_txn-&gt;seq, &amp;key);
    txc-&gt;t-&gt;set(PREFIX_DEFERRED, key, bl);
  }

  _txc_finalize_kv(txc, txc-&gt;t);

#ifdef WITH_BLKIN
  if (txc-&gt;trace)
  {
    txc-&gt;trace.event(&quot;txc encode finished&quot;);
  }
#endif

  if (handle)
    handle-&gt;suspend_tp_timeout();

  // 记录 throttle 开始的时间
  auto tstart = mono_clock::now();

  // 事务提交到 Throttle (内部流控机制)
  if (!throttle.try_start_transaction(
          *db,
          *txc,
          tstart))
  {
    // ensure we do not block here because of deferred writes
    dout(10) &lt;&lt; __func__ &lt;&lt; &quot; failed get throttle_deferred_bytes, aggressive&quot;
             &lt;&lt; dendl;
    ++deferred_aggressive;
    deferred_try_submit();
    {
      // wake up any previously finished deferred events
      std::lock_guard l(kv_lock);
      if (!kv_sync_in_progress)
      {
        kv_sync_in_progress = true;
        kv_cond.notify_one();
      }
    }
    throttle.finish_start_transaction(*db, *txc, tstart);
    --deferred_aggressive;
  }

  // 记录 throttle 完成时间
  auto tend = mono_clock::now();

  if (handle)
    handle-&gt;reset_tp_timeout();

  logger-&gt;inc(l_bluestore_txc);

  // 处理事务状态，执行状态机，将 IO 请求交给块设备执行
  // 该方法中为一系列事务状态机的转换，最终写操作完成后会执行 oncommit 的回调
  // execute (start)
  _txc_state_proc(txc);

  if (bdev-&gt;is_smr())
  {
    atomic_alloc_and_submit_lock.unlock();
  }

  // 针对写完日志之后的回调操作，也就是所谓的 on_readable
  // BliueStore 只会产生少量 WAL 到 RocksDB，所以写日志先于写数据完成
  // we're immediately readable (unlike FileStore)
  for (auto c : on_applied_sync)
  {
    c-&gt;complete(0);
  }
  if (!on_applied.empty())
  {
    if (c-&gt;commit_queue)
    {
      c-&gt;commit_queue-&gt;queue(on_applied);
    }
    else
    {
      finisher.queue(on_applied);
    }
  }

#ifdef WITH_BLKIN
  if (txc-&gt;trace)
  {
    txc-&gt;trace.event(&quot;txc applied&quot;);
  }
#endif

  log_latency(&quot;submit_transact&quot;,
              l_bluestore_submit_lat,
              mono_clock::now() - start,
              cct-&gt;_conf-&gt;bluestore_log_op_age);
  log_latency(&quot;throttle_transact&quot;,
              l_bluestore_throttle_lat,
              tend - tstart,
              cct-&gt;_conf-&gt;bluestore_log_op_age);
  return 0;
}
</code></pre>
<h3 id="repop_commit">repop_commit</h3>
<ul>
<li>在写完成后的回调函数中对应地执行 <code>repop_commit</code>，相应地构造 MOSDRepOpReply，再发送到集群。</li>
</ul>
<pre><code class="language-C++">void ReplicatedBackend::repop_commit(RepModifyRef rm)
{
  rm-&gt;op-&gt;mark_commit_sent();
  rm-&gt;op-&gt;pg_trace.event(&quot;sup_op_commit&quot;);
  rm-&gt;committed = true;

  // send commit.
  auto m = rm-&gt;op-&gt;get_req&lt;MOSDRepOp&gt;();
  ceph_assert(m-&gt;get_type() == MSG_OSD_REPOP);
  dout(10) &lt;&lt; __func__ &lt;&lt; &quot; on op &quot; &lt;&lt; *m
           &lt;&lt; &quot;, sending commit to osd.&quot; &lt;&lt; rm-&gt;ackerosd
           &lt;&lt; dendl;
  ceph_assert(get_osdmap()-&gt;is_up(rm-&gt;ackerosd));

  get_parent()-&gt;update_last_complete_ondisk(rm-&gt;last_complete);

  MOSDRepOpReply *reply = new MOSDRepOpReply(
      m,
      get_parent()-&gt;whoami_shard(),
      0, get_osdmap_epoch(), m-&gt;get_min_epoch(), CEPH_OSD_FLAG_ONDISK);
  reply-&gt;set_last_complete_ondisk(rm-&gt;last_complete);
  reply-&gt;set_priority(CEPH_MSG_PRIO_HIGH); // this better match ack priority!
  reply-&gt;trace = rm-&gt;op-&gt;pg_trace;
  get_parent()-&gt;send_message_osd_cluster(
      rm-&gt;ackerosd, reply, get_osdmap_epoch());

  log_subop_stats(get_parent()-&gt;get_logger(), rm-&gt;op, l_osd_sop_w);
}
</code></pre>
<h3 id="do_repop_reply">do_repop_reply</h3>
<ul>
<li>MSG_OSD_REPOPREPLY 消息发送到了集群，又开始从头到尾的消息处理逻辑，在 _handle_message 中对该类型的消息进行处理，相应地执行 <code>do_repop_reply</code></li>
</ul>
<pre><code class="language-C++">void ReplicatedBackend::do_repop_reply(OpRequestRef op)
{
  static_cast&lt;MOSDRepOpReply *&gt;(op-&gt;get_nonconst_req())-&gt;finish_decode();

  // 获取上文构造的 Reply Msg
  auto r = op-&gt;get_req&lt;MOSDRepOpReply&gt;();
  ceph_assert(r-&gt;get_header().type == MSG_OSD_REPOPREPLY);

  op-&gt;mark_started();

  // must be replication.
  ceph_tid_t rep_tid = r-&gt;get_tid();
  pg_shard_t from = r-&gt;from;

  auto iter = in_progress_ops.find(rep_tid);
  if (iter != in_progress_ops.end())
  {
    // 获取副本节点上正在处理的 op InProgressOp
    InProgressOp &amp;ip_op = *iter-&gt;second;
    const MOSDOp *m = nullptr;
    if (ip_op.op)
      m = ip_op.op-&gt;get_req&lt;MOSDOp&gt;();

    if (m)
      dout(7) &lt;&lt; __func__ &lt;&lt; &quot;: tid &quot; &lt;&lt; ip_op.tid &lt;&lt; &quot; op &quot; //&lt;&lt; *m
              &lt;&lt; &quot; ack_type &quot; &lt;&lt; (int)r-&gt;ack_type
              &lt;&lt; &quot; from &quot; &lt;&lt; from
              &lt;&lt; dendl;
    else
      dout(7) &lt;&lt; __func__ &lt;&lt; &quot;: tid &quot; &lt;&lt; ip_op.tid &lt;&lt; &quot; (no op) &quot;
              &lt;&lt; &quot; ack_type &quot; &lt;&lt; (int)r-&gt;ack_type
              &lt;&lt; &quot; from &quot; &lt;&lt; from
              &lt;&lt; dendl;

    // oh, good.
    // 检查响应消息中的 ACK 类型
    if (r-&gt;ack_type &amp; CEPH_OSD_FLAG_ONDISK)
    {
      ceph_assert(ip_op.waiting_for_commit.count(from));
      ip_op.waiting_for_commit.erase(from);
      if (ip_op.op)
      {
        ip_op.op-&gt;mark_event(&quot;sub_op_commit_rec&quot;);
        ip_op.op-&gt;pg_trace.event(&quot;sub_op_commit_rec&quot;);
      }
    }
    else
    {
      // legacy peer; ignore
    }

    parent-&gt;update_peer_last_complete_ondisk(
        from,
        r-&gt;get_last_complete_ondisk());

    // 检查 waiting_for_commit 是否为空
    // 如果为空，继续向上回调。C_OSD_RepopCommit
//   C_OSD_RepopCommit(PrimaryLogPG *pg, PrimaryLogPG::RepGather *repop)
//       : pg(pg), repop(repop) {}
//   void finish(int) override
//   {
//     pg-&gt;repop_all_committed(repop.get());
//   }
// };
    if (ip_op.waiting_for_commit.empty() &amp;&amp;
        ip_op.on_commit)
    {
      ip_op.on_commit-&gt;complete(0);
      ip_op.on_commit = 0;
      in_progress_ops.erase(iter);
    }
  }
}
</code></pre>
<h3 id="repop_all_committed">repop_all_committed</h3>
<ul>
<li><code>PrimaryLogPG::repop_all_committed</code> 准备于客户端进行交互，调用 <code>eval_repop</code></li>
</ul>
<pre><code class="language-C++">void PrimaryLogPG::repop_all_committed(RepGather *repop)
{
  dout(10) &lt;&lt; __func__ &lt;&lt; &quot;: repop tid &quot; &lt;&lt; repop-&gt;rep_tid &lt;&lt; &quot; all committed &quot;
           &lt;&lt; dendl;
  repop-&gt;all_committed = true;
  if (!repop-&gt;rep_aborted)
  {
    if (repop-&gt;v != eversion_t())
    {
      recovery_state.complete_write(repop-&gt;v, repop-&gt;pg_local_last_complete);
    }
    eval_repop(repop);
  }
}
</code></pre>
<h3 id="eval_repop">eval_repop</h3>
<ul>
<li>通过执行在 <code>execute_ctx</code> 函数中注册的 commit 回调，从而向客户端发送应答消息。</li>
</ul>
<pre><code class="language-C++">void PrimaryLogPG::eval_repop(RepGather *repop)
{
  dout(10) &lt;&lt; &quot;eval_repop &quot; &lt;&lt; *repop
           &lt;&lt; (repop-&gt;op &amp;&amp; repop-&gt;op-&gt;get_req&lt;MOSDOp&gt;() ? &quot;&quot; : &quot; (no op)&quot;) &lt;&lt; dendl;

  // 所有副本应答写入磁盘完成
  // ondisk?
  if (repop-&gt;all_committed)
  {
    dout(10) &lt;&lt; &quot; commit: &quot; &lt;&lt; *repop &lt;&lt; dendl;
    for (auto p = repop-&gt;on_committed.begin();
         p != repop-&gt;on_committed.end();
         repop-&gt;on_committed.erase(p++))
    {
      // 执行回调
      // ctx-&gt;register_on_commit(
      // [m, ctx, this]() {
      //   if (ctx-&gt;op)
      //     log_op_stats(*ctx-&gt;op, ctx-&gt;bytes_written, ctx-&gt;bytes_read);

      //   if (m &amp;&amp; !ctx-&gt;sent_reply)
      //   {
      //     MOSDOpReply *reply = ctx-&gt;reply;
      //     ctx-&gt;reply = nullptr;
      //     reply-&gt;add_flags(CEPH_OSD_FLAG_ACK | CEPH_OSD_FLAG_ONDISK);
      //     dout(10) &lt;&lt; &quot; sending reply on &quot; &lt;&lt; *m &lt;&lt; &quot; &quot; &lt;&lt; reply &lt;&lt; dendl;
      //     osd-&gt;send_message_osd_client(reply, m-&gt;get_connection());
      //     ctx-&gt;sent_reply = true;
      //     ctx-&gt;op-&gt;mark_commit_sent();
      //   }
      // });
      (*p)();
    }
    // send dup commits, in order
    auto it = waiting_for_ondisk.find(repop-&gt;v);
    if (it != waiting_for_ondisk.end())
    {
      ceph_assert(waiting_for_ondisk.begin()-&gt;first == repop-&gt;v);
      for (auto &amp;i : it-&gt;second)
      {
        int return_code = repop-&gt;r;
        if (return_code &gt;= 0)
        {
          return_code = std::get&lt;2&gt;(i);
        }
        osd-&gt;reply_op_error(std::get&lt;0&gt;(i), return_code, repop-&gt;v,
                            std::get&lt;1&gt;(i), std::get&lt;3&gt;(i));
      }
      waiting_for_ondisk.erase(it);
    }

    publish_stats_to_osd();

    dout(10) &lt;&lt; &quot; removing &quot; &lt;&lt; *repop &lt;&lt; dendl;
    ceph_assert(!repop_queue.empty());
    dout(20) &lt;&lt; &quot;   q front is &quot; &lt;&lt; *repop_queue.front() &lt;&lt; dendl;
    if (repop_queue.front() == repop)
    {
      RepGather *to_remove = nullptr;
      while (!repop_queue.empty() &amp;&amp;
             (to_remove = repop_queue.front())-&gt;all_committed)
      {
        repop_queue.pop_front();
        for (auto p = to_remove-&gt;on_success.begin();
             p != to_remove-&gt;on_success.end();
             to_remove-&gt;on_success.erase(p++))
        {
          (*p)();
        }
        remove_repop(to_remove);
      }
    }
  }
}
</code></pre>
]]></content>
    </entry>
</feed>